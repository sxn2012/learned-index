{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learned_index_multiple_numbers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or3_4oUD6Xfo"
      },
      "source": [
        "# Read Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7afa8m-9Qxl"
      },
      "source": [
        "### read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBnrN1m15Vdw",
        "outputId": "25bd1c5f-2def-44b7-cd88-ebe85a9040dc"
      },
      "source": [
        "import codecs\n",
        "import os\n",
        "minkey=1000\n",
        "maxkey=9999\n",
        "keynum=3000\n",
        "current_path=os.path.abspath(os.curdir)\n",
        "f=codecs.open(os.path.join(current_path,\"data.csv\"), \"r\", \"utf-8\")\n",
        "strlist=f.read().split(\"\\n\")\n",
        "f.close()\n",
        "trainkeys=[]\n",
        "trainres=[]\n",
        "for ele in strlist:\n",
        "    temp=ele.split(\",\")\n",
        "    if len(temp)<2:\n",
        "        continue\n",
        "    trainkeys.append([float(temp[i]) for i in range(0,len(temp)-1)])\n",
        "    trainres.append(int(temp[len(temp)-1]))\n",
        "\n",
        "f=codecs.open(os.path.join(current_path,\"data_test.csv\"), \"r\", \"utf-8\")\n",
        "strlist=f.read().split(\"\\n\")\n",
        "f.close()\n",
        "testkeys=[]\n",
        "testres=[]\n",
        "for ele in strlist:\n",
        "    temp=ele.split(\",\")\n",
        "    if len(temp)<2:\n",
        "        continue\n",
        "    testkeys.append([float(temp[i]) for i in range(0,len(temp)-1)])\n",
        "    testres.append(int(temp[len(temp)-1]))\n",
        "\n",
        "\n",
        "\n",
        "print(\"training data size:\",len(trainkeys))\n",
        "\n",
        "print(\"testing data size:\",len(testkeys))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data size: 13611\n",
            "testing data size: 4537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU5ZS7_a9TBv"
      },
      "source": [
        "### data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYqLQ3sy9UoI"
      },
      "source": [
        "trainpages=[]\n",
        "for ele in trainres:\n",
        "  trainpages.append(int(ele)//100)\n",
        "testpages=[]\n",
        "for ele in testres:\n",
        "  testpages.append(int(ele)//100)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T2X_GIe9cdM"
      },
      "source": [
        "import numpy as np\n",
        "X_train=np.array(trainkeys)\n",
        "Y_train=np.array(trainres).reshape(-1,1)\n",
        "Z_train=np.array(trainpages).reshape(-1,1)\n",
        "X_test=np.array(testkeys)\n",
        "Y_test=np.array(testres).reshape(-1,1)\n",
        "Z_test=np.array(testpages).reshape(-1,1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnY57H1K9gMZ"
      },
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKN_59zi94tP"
      },
      "source": [
        "# Build Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIs8SChJ_Zvg"
      },
      "source": [
        "## B-Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHVL1yJ8_bhT",
        "outputId": "f29e9e15-a384-4e30-9a31-efe6a28cf930"
      },
      "source": [
        "import time\n",
        "# ref: https://peefy.github.io/blog/2018/06/10/Python-BTree/\n",
        "class BTreeNode:\n",
        "    '''\n",
        "    B树结点\n",
        "    '''\n",
        "    def __init__(self, n = 0, isleaf = True):\n",
        "        '''\n",
        "        B树结点\n",
        "\n",
        "        Args\n",
        "        ===\n",
        "        `n` : 结点包含关键字的数量\n",
        "\n",
        "        `isleaf` : 是否是叶子节点\n",
        "\n",
        "        '''\n",
        "        # 结点包含关键字的数量\n",
        "        self.n = n\n",
        "        # 关键字的值数组\n",
        "        self.keys = []\n",
        "        # 子结点数组\n",
        "        self.children = []\n",
        "        # 是否是叶子节点\n",
        "        self.isleaf = isleaf\n",
        "\n",
        "    def __str__(self):\n",
        "\n",
        "        returnStr = 'keys:['\n",
        "        for i in range(self.n):\n",
        "            returnStr += str(self.keys[i]) + ' '\n",
        "        returnStr += '];childrens:['\n",
        "        for child in self.children:\n",
        "            returnStr += str(child) + ';'\n",
        "        returnStr += ']\\r\\n'\n",
        "        return returnStr\n",
        "\n",
        "    def diskread(self):\n",
        "        '''\n",
        "        磁盘读\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def diskwrite(self):\n",
        "        '''\n",
        "        磁盘写\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def allocate_node(self, key_max):\n",
        "        '''\n",
        "        在O(1)时间内为一个新结点分配一个磁盘页\n",
        "\n",
        "        假定由ALLOCATE-NODE所创建的结点无需做DISK-READ，因为磁盘上还没有关于该结点的有用信息\n",
        "\n",
        "        Return\n",
        "        ===\n",
        "        `btreenode` : 分配的B树结点\n",
        "\n",
        "        Example\n",
        "        ===\n",
        "        ```python\n",
        "        btreenode = BTreeNode.allocate_node()\n",
        "        ```\n",
        "        '''\n",
        "        node = BTreeNode()\n",
        "        child_max = key_max + 1\n",
        "        for i in range(key_max):\n",
        "            node.keys.append(None)\n",
        "        for i in range(child_max):\n",
        "            node.children.append(None)\n",
        "        return node\n",
        "\n",
        "class BTree:\n",
        "    '''\n",
        "    B树\n",
        "    '''\n",
        "    def __init__(self, m = 3):\n",
        "        '''\n",
        "        B树的定义\n",
        "        '''\n",
        "        # B树的最小度数\n",
        "        self.M = m\n",
        "        # 节点包含关键字的最大个数\n",
        "        self.KEY_MAX = 2 * self.M - 1\n",
        "        # 非根结点包含关键字的最小个数\n",
        "        self.KEY_MIN = self.M - 1\n",
        "        # 子结点的最大个数\n",
        "        self.CHILD_MAX = self.KEY_MAX + 1\n",
        "        # 子结点的最小个数\n",
        "        self.CHILD_MIN = self.KEY_MIN + 1\n",
        "        # 根结点\n",
        "        self.root: BTreeNode = None\n",
        "\n",
        "    def __new_node(self):\n",
        "        '''\n",
        "        创建新的B树结点\n",
        "        '''\n",
        "        return BTreeNode.allocate_node(self.KEY_MAX)\n",
        "\n",
        "    def insert(self, key):\n",
        "        '''\n",
        "        向B树中插入新结点`key`  \n",
        "        '''\n",
        "        # 检查关键字是否存在\n",
        "        if self.contain(key) == True:\n",
        "            return False\n",
        "        else:\n",
        "            # 检查是否为空树\n",
        "            if self.root is None:\n",
        "                node = self.__new_node()\n",
        "                node.diskwrite()\n",
        "                self.root = node    \n",
        "            # 检查根结点是否已满      \n",
        "            if self.root.n == self.KEY_MAX:\n",
        "                # 创建新的根结点\n",
        "                pNode = self.__new_node()\n",
        "                pNode.isleaf = False\n",
        "                pNode.children[0] = self.root\n",
        "                self.__split_child(pNode, 0, self.root)\n",
        "                # 更新结点指针\n",
        "                self.root = pNode\n",
        "            self.__insert_non_full(self.root, key)\n",
        "            return True\n",
        "\n",
        "    def remove(self, key): \n",
        "        '''\n",
        "        从B中删除结点`key`\n",
        "        '''      \n",
        "        # 如果关键字不存在\n",
        "        if not self.search(self.root, key):\n",
        "            return False\n",
        "        # 特殊情况处理\n",
        "        if self.root.n == 1:\n",
        "            if self.root.isleaf == True:\n",
        "                self.clear()\n",
        "            else:\n",
        "                pChild1 = self.root.children[0]\n",
        "                pChild2 = self.root.children[1]\n",
        "                if pChild1.n == self.KEY_MIN and pChild2.n == self.KEY_MIN:\n",
        "                    self.__merge_child(self.root, 0)\n",
        "                    self.__delete_node(self.root)\n",
        "                    self.root = pChild1\n",
        "        self.__recursive_remove(self.root, key)\n",
        "        return True\n",
        "    \n",
        "    def display(self):\n",
        "        '''\n",
        "        打印树的关键字  \n",
        "        '''\n",
        "        self.__display_in_concavo(self.root, self.KEY_MAX * 10)\n",
        "\n",
        "    def contain(self, key):\n",
        "        '''\n",
        "        检查该`key`是否存在于B树中  \n",
        "        '''\n",
        "        self.__search(self.root, key)\n",
        "\n",
        "    def clear(self):\n",
        "        '''\n",
        "        清空B树  \n",
        "        '''\n",
        "        self.__recursive_clear(self.root)\n",
        "        self.root = None\n",
        "\n",
        "    def __recursive_clear(self, pNode : BTreeNode):\n",
        "        '''\n",
        "        删除树  \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            if not pNode.isleaf:\n",
        "                for i in range(pNode.n):\n",
        "                    self.__recursive_clear(pNode.children[i])\n",
        "            self.__delete_node(pNode)\n",
        "\n",
        "    def __delete_node(self, pNode : BTreeNode):\n",
        "        '''\n",
        "        删除节点 \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            pNode = None\n",
        "    \n",
        "    def __search(self, pNode : BTreeNode, key):\n",
        "        '''\n",
        "        查找关键字  \n",
        "        '''\n",
        "        # 检测结点是否为空，或者该结点是否为叶子节点\n",
        "        if pNode is None:\n",
        "            return False\n",
        "        else:\n",
        "            i = 0\n",
        "            # 找到使key < pNode.keys[i]成立的最小下标\n",
        "            while i < pNode.n and key > pNode.keys[i]:\n",
        "                i += 1\n",
        "            if i < pNode.n and key == pNode.keys[i]:\n",
        "                return True\n",
        "            else:\n",
        "                # 检查该结点是否为叶子节点\n",
        "                if pNode.isleaf == True:\n",
        "                    return False\n",
        "                else:\n",
        "                    return self.__search(pNode.children[i], key)\n",
        "\n",
        "    def __split_child(self, pParent : BTreeNode, nChildIndex, pChild : BTreeNode):\n",
        "        '''\n",
        "        分裂子节点\n",
        "        '''\n",
        "        # 将pChild分裂成pLeftChild和pChild两个结点\n",
        "        pRightNode = self.__new_node()  # 分裂后的右结点\n",
        "        pRightNode.isleaf = pChild.isleaf\n",
        "        pRightNode.n = self.KEY_MIN\n",
        "        # 拷贝关键字的值\n",
        "        for i in range(self.KEY_MIN):\n",
        "            pRightNode.keys[i] = pChild.keys[i + self.CHILD_MIN]\n",
        "        # 如果不是叶子结点，就拷贝孩子结点指针\n",
        "        if not pChild.isleaf:\n",
        "            for i in range(self.CHILD_MIN):\n",
        "                pRightNode.children[i] = pChild.children[i + self.CHILD_MIN]\n",
        "        # 更新左子树的关键字个数\n",
        "        pChild.n = self.KEY_MIN\n",
        "        # 将父结点中的pChildIndex后的所有关键字的值和子树指针向后移动一位\n",
        "        for i in range(nChildIndex, pParent.n):\n",
        "            j = pParent.n + nChildIndex - i\n",
        "            pParent.children[j + 1] = pParent.children[j]\n",
        "            pParent.keys[j] = pParent.keys[j - 1]\n",
        "        # 更新父结点的关键字个数\n",
        "        pParent.n += 1\n",
        "        # 存储右子树指针\n",
        "        pParent.children[nChildIndex + 1] = pRightNode\n",
        "        # 把结点的中间值提到父结点\n",
        "        pParent.keys[nChildIndex] = pChild.keys[self.KEY_MIN]\n",
        "        pChild.diskwrite()\n",
        "        pRightNode.diskwrite()\n",
        "        pParent.diskwrite()\n",
        "    \n",
        "    def __insert_non_full(self, pNode: BTreeNode, key):\n",
        "        '''\n",
        "        在非满节点中插入关键字\n",
        "        '''\n",
        "        # 获取结点内关键字个数\n",
        "        i = pNode.n\n",
        "        # 如果pNode是叶子结点\n",
        "        if pNode.isleaf == True:\n",
        "            # 从后往前 查找关键字的插入位置\n",
        "            while i > 0 and key < pNode.keys[i - 1]:\n",
        "                # 向后移位\n",
        "                pNode.keys[i] = pNode.keys[i - 1]\n",
        "                i -= 1\n",
        "            # 插入关键字的值\n",
        "            pNode.keys[i] = key\n",
        "            # 更新结点关键字的个数\n",
        "            pNode.n += 1\n",
        "            pNode.diskwrite()\n",
        "        # pnode是内结点\n",
        "        else:\n",
        "            # 从后往前 查找关键字的插入的子树\n",
        "            while i > 0 and key < pNode.keys[i - 1]:\n",
        "                i -= 1\n",
        "            # 目标子树结点指针\n",
        "            pChild = pNode.children[i]\n",
        "            pNode.children[i].diskread()\n",
        "            # 子树结点已经满了\n",
        "            if pChild.n == self.KEY_MAX:\n",
        "                # 分裂子树结点\n",
        "                self.__split_child(pNode, i, pChild)\n",
        "                # 确定目标子树\n",
        "                if key > pNode.keys[i]:\n",
        "                    pChild = pNode.children[i + 1]\n",
        "            # 插入关键字到目标子树结点\n",
        "            self.__insert_non_full(pChild, key)\n",
        "\n",
        "    def __display_in_concavo(self, pNode: BTreeNode, count):\n",
        "        '''\n",
        "        用括号打印树 \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            i = 0\n",
        "            j = 0\n",
        "            for i in range(pNode.n):\n",
        "                if not pNode.isleaf:\n",
        "                    self.__display_in_concavo(pNode.children[i], count - 2)\n",
        "                for j in range(-1, count):\n",
        "                    k = count - j - 1\n",
        "                    print('-', end='')\n",
        "                print(pNode.keys[i])\n",
        "            if not pNode.isleaf:\n",
        "                self.__display_in_concavo(pNode.children[i], count - 2)\n",
        "\n",
        "    def __merge_child(self, pParent: BTreeNode, index):\n",
        "        '''\n",
        "        合并两个子结点\n",
        "        '''\n",
        "        pChild1 = pParent.children[index]\n",
        "        pChild2 = pParent.children[index + 1]\n",
        "        # 将pChild2数据合并到pChild1\n",
        "        pChild1.n = self.KEY_MAX\n",
        "        # 将父结点index的值下移\n",
        "        pChild1.keys[self.KEY_MIN] = pParent.keys[index]\n",
        "        for i in range(self.KEY_MIN):\n",
        "            pChild1.keys[i + self.KEY_MIN + 1] = pChild2.keys[i]\n",
        "        if not pChild1.isleaf:\n",
        "            for i in range(self.CHILD_MIN):\n",
        "                pChild1.children[i + self.CHILD_MIN] = pChild2.children[i]\n",
        "        # 父结点删除index的key，index后的往前移一位\n",
        "        pParent.n -= 1\n",
        "        for i in range(index, pParent.n):\n",
        "            pParent.keys[i] = pParent.keys[i + 1]\n",
        "            pParent.children[i + 1] = pParent.children[i + 2]\n",
        "        # 删除pChild2\n",
        "        self.__delete_node(pChild2)\n",
        "\n",
        "    def __recursive_remove(self, pNode: BTreeNode, key):\n",
        "        '''\n",
        "        递归的删除关键字`key`  \n",
        "        '''\n",
        "        i = 0\n",
        "        while i < pNode.n and key > pNode.keys[i]:\n",
        "            i += 1\n",
        "        # 关键字key在结点pNode\n",
        "        if i < pNode.n and key == pNode.keys[i]:\n",
        "            # pNode是个叶结点\n",
        "            if pNode.isleaf == True:\n",
        "                # 从pNode中删除k\n",
        "                for j in range(i, pNode.n):\n",
        "                    pNode.keys[j] = pNode.keys[j + 1]\n",
        "                return\n",
        "            # pNode是个内结点\n",
        "            else:\n",
        "                # 结点pNode中前于key的子结点\n",
        "                pChildPrev = pNode.children[i]\n",
        "                # 结点pNode中后于key的子结点\n",
        "                pChildNext = pNode.children[i + 1]\n",
        "                if pChildPrev.n >= self.CHILD_MIN:\n",
        "                    # 获取key的前驱关键字\n",
        "                    prevKey = self.predecessor(pChildPrev)\n",
        "                    self.__recursive_remove(pChildPrev, prevKey)\n",
        "                    # 替换成key的前驱关键字\n",
        "                    pNode.keys[i] = prevKey\n",
        "                    return\n",
        "                # 结点pChildNext中至少包含CHILD_MIN个关键字\n",
        "                elif pChildNext.n >= self.CHILD_MIN:\n",
        "                    # 获取key的后继关键字\n",
        "                    nextKey = self.successor(pChildNext)\n",
        "                    self.__recursive_remove(pChildNext, nextKey)\n",
        "                    # 替换成key的后继关键字\n",
        "                    pNode.keys[i] = nextKey\n",
        "                    return\n",
        "                # 结点pChildPrev和pChildNext中都只包含CHILD_MIN-1个关键字\n",
        "                else:\n",
        "                    self.__merge_child(pNode, i)\n",
        "                    self.__recursive_remove(pChildPrev, key)\n",
        "        # 关键字key不在结点pNode中\n",
        "        else:\n",
        "            # 包含key的子树根结点\n",
        "            pChildNode = pNode.children[i]\n",
        "            # 只有t-1个关键字\n",
        "            if pChildNode.n == self.KEY_MAX:\n",
        "                # 左兄弟结点\n",
        "                pLeft = None\n",
        "                # 右兄弟结点\n",
        "                pRight = None\n",
        "                # 左兄弟结点\n",
        "                if i > 0:\n",
        "                    pLeft = pNode.children[i - 1]\n",
        "                # 右兄弟结点\n",
        "                if i < pNode.n:\n",
        "                    pRight = pNode.children[i + 1]\n",
        "                j = 0\n",
        "                if pLeft is not None and pLeft.n >= self.CHILD_MIN:\n",
        "                    # 父结点中i-1的关键字下移至pChildNode中\n",
        "                    for j in range(pChildNode.n):\n",
        "                        k = pChildNode.n - j\n",
        "                        pChildNode.keys[k] = pChildNode.keys[k - 1]\n",
        "                    pChildNode.keys[0] = pNode.keys[i - 1]\n",
        "                    if not pLeft.isleaf:\n",
        "                        # pLeft结点中合适的子女指针移到pChildNode中\n",
        "                        for j in range(pChildNode.n + 1):\n",
        "                            k = pChildNode.n + 1 - j\n",
        "                            pChildNode.children[k] = pChildNode.children[k - 1]\n",
        "                        pChildNode.children[0] = pLeft.children[pLeft.n]\n",
        "                    pChildNode.n += 1\n",
        "                    pNode.keys[i] = pLeft.keys[pLeft.n - 1]\n",
        "                    pLeft.n -= 1\n",
        "                # 右兄弟结点至少有CHILD_MIN个关键字\n",
        "                elif pRight is not None and pRight.n >= self.CHILD_MIN:\n",
        "                    # 父结点中i的关键字下移至pChildNode中\n",
        "                    pChildNode.keys[pChildNode.n] = pNode.keys[i]\n",
        "                    pChildNode.n += 1\n",
        "                    # pRight结点中的最小关键字上升到pNode中\n",
        "                    pNode.keys[i] = pRight.keys[0]\n",
        "                    pRight.n -= 1\n",
        "                    for j in range(pRight.n):\n",
        "                        pRight.keys[j] = pRight.keys[j + 1]\n",
        "                    if not pRight.isleaf:\n",
        "                        # pRight结点中合适的子女指针移动到pChildNode中\n",
        "                        pChildNode.children[pChildNode.n] = pRight.children[0]\n",
        "                        for j in range(pRight.n):\n",
        "                            pRight.children[j] = pRight.children[j + 1]\n",
        "                # 左右兄弟结点都只包含CHILD_MIN-1个结点\n",
        "                elif pLeft is not None:\n",
        "                    self.__merge_child(pNode, i - 1)\n",
        "                    pChildNode = pLeft\n",
        "                # 与右兄弟合并\n",
        "                elif pRight is not None:\n",
        "                    self.__merge_child(pNode, i)\n",
        "            self.__recursive_remove(pChildNode, key)\n",
        "\n",
        "    def predecessor(self, pNode: BTreeNode):\n",
        "        '''\n",
        "        前驱关键字\n",
        "        '''\n",
        "        while not pNode.isleaf:\n",
        "            pNode = pNode.children[pNode.n]\n",
        "        return pNode.keys[pNode.n - 1]\n",
        "\n",
        "    def successor(self, pNode: BTreeNode):\n",
        "        '''\n",
        "        后继关键字\n",
        "        '''\n",
        "        while not pNode.isleaf:\n",
        "            pNode = pNode.children[0]\n",
        "        return pNode.keys[0]\n",
        "\n",
        "def test():\n",
        "    '''\n",
        "    test class `BTree` and class `BTreeNode`\n",
        "    '''\n",
        "    tree = BTree(10)\n",
        "    \n",
        "    t1=time.time()\n",
        "    for i in range(0,len(trainkeys)):\n",
        "        tree.insert(trainkeys[i])\n",
        "    t2=time.time()\n",
        "    time_interval=t2-t1\n",
        "    print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "    ret1=time_interval*1000\n",
        "    t1=time.time()\n",
        "    # testpre=[]\n",
        "    for i in range(0,len(testkeys)):\n",
        "        tree.contain(testkeys[i])\n",
        "    t2=time.time()\n",
        "    time_interval=t2-t1\n",
        "    print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "    print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "    ret2=time_interval*1000\n",
        "    ret3=time_interval/len(testkeys)*1000\n",
        "    return (ret1,ret2,ret3)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    avg_a=0.0\n",
        "    avg_b=0.0\n",
        "    avg_c=0.0\n",
        "    counting=20\n",
        "    for i in range(0,20):\n",
        "        (a,b,c)=test()\n",
        "        avg_a+=a\n",
        "        avg_b+=b\n",
        "        avg_c+=c\n",
        "    avg_a=avg_a/counting\n",
        "    avg_b=avg_b/counting\n",
        "    avg_c=avg_c/counting\n",
        "    print(\"average times (ms):\",avg_a,avg_b,avg_c)\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:182.09505081176758 ms\n",
            "time interval for indexing data :39.42608833312988 ms\n",
            "average time interval for indexing data :0.008689902652221707 ms\n",
            "time interval for building model:180.21178245544434 ms\n",
            "time interval for indexing data :39.62230682373047 ms\n",
            "average time interval for indexing data :0.008733151162382735 ms\n",
            "time interval for building model:182.8458309173584 ms\n",
            "time interval for indexing data :38.35463523864746 ms\n",
            "average time interval for indexing data :0.008453743715813856 ms\n",
            "time interval for building model:189.12792205810547 ms\n",
            "time interval for indexing data :47.209739685058594 ms\n",
            "average time interval for indexing data :0.010405496955049281 ms\n",
            "time interval for building model:176.97954177856445 ms\n",
            "time interval for indexing data :49.8201847076416 ms\n",
            "average time interval for indexing data :0.010980865044664228 ms\n",
            "time interval for building model:181.51330947875977 ms\n",
            "time interval for indexing data :47.65915870666504 ms\n",
            "average time interval for indexing data :0.010504553384761965 ms\n",
            "time interval for building model:197.15046882629395 ms\n",
            "time interval for indexing data :38.4821891784668 ms\n",
            "average time interval for indexing data :0.008481857874910029 ms\n",
            "time interval for building model:182.5239658355713 ms\n",
            "time interval for indexing data :45.00412940979004 ms\n",
            "average time interval for indexing data :0.009919358476920881 ms\n",
            "time interval for building model:180.57703971862793 ms\n",
            "time interval for indexing data :48.22945594787598 ms\n",
            "average time interval for indexing data :0.010630252578328406 ms\n",
            "time interval for building model:187.5467300415039 ms\n",
            "time interval for indexing data :46.01287841796875 ms\n",
            "average time interval for indexing data :0.010141696808016035 ms\n",
            "time interval for building model:191.98966026306152 ms\n",
            "time interval for indexing data :44.39663887023926 ms\n",
            "average time interval for indexing data :0.009785461509860977 ms\n",
            "time interval for building model:179.25786972045898 ms\n",
            "time interval for indexing data :44.362545013427734 ms\n",
            "average time interval for indexing data :0.009777946884158636 ms\n",
            "time interval for building model:182.53326416015625 ms\n",
            "time interval for indexing data :42.68670082092285 ms\n",
            "average time interval for indexing data :0.009408574128482004 ms\n",
            "time interval for building model:188.5244846343994 ms\n",
            "time interval for indexing data :43.18046569824219 ms\n",
            "average time interval for indexing data :0.009517404826590739 ms\n",
            "time interval for building model:189.9571418762207 ms\n",
            "time interval for indexing data :46.509742736816406 ms\n",
            "average time interval for indexing data :0.010251210653915894 ms\n",
            "time interval for building model:176.93710327148438 ms\n",
            "time interval for indexing data :45.55988311767578 ms\n",
            "average time interval for indexing data :0.010041852130852057 ms\n",
            "time interval for building model:309.006929397583 ms\n",
            "time interval for indexing data :44.07954216003418 ms\n",
            "average time interval for indexing data :0.009715570235846193 ms\n",
            "time interval for building model:188.11297416687012 ms\n",
            "time interval for indexing data :51.833391189575195 ms\n",
            "average time interval for indexing data :0.011424595809912981 ms\n",
            "time interval for building model:181.97274208068848 ms\n",
            "time interval for indexing data :45.76444625854492 ms\n",
            "average time interval for indexing data :0.010086939885066105 ms\n",
            "time interval for building model:177.78444290161133 ms\n",
            "time interval for indexing data :39.890289306640625 ms\n",
            "average time interval for indexing data :0.008792217171399741 ms\n",
            "average times (ms): 190.33241271972656 44.40422058105469 0.009787132594457723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efcjj-Yo99fF"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YsWZ-GG97GL",
        "outputId": "5f2f2442-8b17-4ea4-8e93-614f6081bba6"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error \n",
        "import math\n",
        "import time\n",
        "# print(\"Linear Regression Model\")\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(X_train,Y_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  # devpre=reg.predict(np.array(devkeys).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
        "  # for i in range(0,len(devpre)):\n",
        "  #     devpre[i]=abs(int(devpre[i]))\n",
        "  # mse_LR=mean_squared_error(devres,devpre)\n",
        "  # print(\"MSE dev: \",mse_LR)\n",
        "  t1=time.time()\n",
        "  testpre=reg.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  for i in range(0,len(testpre)):\n",
        "    testpre[i]=abs(int(testpre[i]))\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  # print(\"log MSE test: \",round(math.log(1+mean_squared_error(testres,testpre),2),3))\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_loc=testpre[i]\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "      finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "      finding_res=trainres[0]\n",
        "    else:\n",
        "      finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "    # i=begin\n",
        "    # while i<=end:\n",
        "    #   # print(i,end)\n",
        "    #   if finding_res==trainkeys[i]:\n",
        "    #     break\n",
        "    #   else:\n",
        "    #     i=i+1\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:8.05354118347168 ms\n",
            "time interval for indexing data :7.041454315185547 ms\n",
            "average time interval for indexing data :0.0015520066817689105 ms\n",
            "time interval for error correction :76.53546333312988 ms\n",
            "average time interval for error correction :0.016876618155045178 ms\n",
            "time interval for building model:6.5822601318359375 ms\n",
            "time interval for indexing data :2.4700164794921875 ms\n",
            "average time interval for indexing data :0.0005444162396941124 ms\n",
            "time interval for error correction :43.48611831665039 ms\n",
            "average time interval for error correction :0.00958900073134518 ms\n",
            "time interval for building model:6.543159484863281 ms\n",
            "time interval for indexing data :2.5758743286132812 ms\n",
            "average time interval for indexing data :0.0005677483642524314 ms\n",
            "time interval for error correction :50.99153518676758 ms\n",
            "average time interval for error correction :0.011243998938647757 ms\n",
            "time interval for building model:6.748437881469727 ms\n",
            "time interval for indexing data :2.516508102416992 ms\n",
            "average time interval for indexing data :0.0005546634565609416 ms\n",
            "time interval for error correction :52.454233169555664 ms\n",
            "average time interval for error correction :0.011566534326252627 ms\n",
            "time interval for building model:6.666898727416992 ms\n",
            "time interval for indexing data :2.4900436401367188 ms\n",
            "average time interval for indexing data :0.0005488304254213618 ms\n",
            "time interval for error correction :49.1337776184082 ms\n",
            "average time interval for error correction :0.010834350081236649 ms\n",
            "time interval for building model:6.7653656005859375 ms\n",
            "time interval for indexing data :2.529144287109375 ms\n",
            "average time interval for indexing data :0.0005574485975555158 ms\n",
            "time interval for error correction :49.4840145111084 ms\n",
            "average time interval for error correction :0.010911579826043748 ms\n",
            "time interval for building model:6.950855255126953 ms\n",
            "time interval for indexing data :2.6040077209472656 ms\n",
            "average time interval for indexing data :0.0005739492442026153 ms\n",
            "time interval for error correction :54.848670959472656 ms\n",
            "average time interval for error correction :0.012094525018626826 ms\n",
            "time interval for building model:6.5937042236328125 ms\n",
            "time interval for indexing data :2.5365352630615234 ms\n",
            "average time interval for indexing data :0.0005590776422881912 ms\n",
            "time interval for error correction :63.555240631103516 ms\n",
            "average time interval for error correction :0.014014386026704193 ms\n",
            "time interval for building model:11.931896209716797 ms\n",
            "time interval for indexing data :2.6738643646240234 ms\n",
            "average time interval for indexing data :0.0005893463444179024 ms\n",
            "time interval for error correction :55.25708198547363 ms\n",
            "average time interval for error correction :0.01218458257673068 ms\n",
            "time interval for building model:6.651401519775391 ms\n",
            "time interval for indexing data :2.5794506072998047 ms\n",
            "average time interval for indexing data :0.000568536611703726 ms\n",
            "time interval for error correction :55.14359474182129 ms\n",
            "average time interval for error correction :0.012159557826200946 ms\n",
            "time interval for building model:10.654449462890625 ms\n",
            "time interval for indexing data :4.47845458984375 ms\n",
            "average time interval for indexing data :0.0009870960083411394 ms\n",
            "time interval for error correction :88.05394172668457 ms\n",
            "average time interval for error correction :0.019416525187802552 ms\n",
            "time interval for building model:6.439685821533203 ms\n",
            "time interval for indexing data :2.4919509887695312 ms\n",
            "average time interval for indexing data :0.0005492508240620523 ms\n",
            "time interval for error correction :62.65854835510254 ms\n",
            "average time interval for error correction :0.013816658953716107 ms\n",
            "time interval for building model:4.942893981933594 ms\n",
            "time interval for indexing data :1.832723617553711 ms\n",
            "average time interval for indexing data :0.00040395054387342094 ms\n",
            "time interval for error correction :40.47203063964844 ms\n",
            "average time interval for error correction :0.00892437279815842 ms\n",
            "time interval for building model:6.734371185302734 ms\n",
            "time interval for indexing data :2.560138702392578 ms\n",
            "average time interval for indexing data :0.0005642800754667353 ms\n",
            "time interval for error correction :86.66491508483887 ms\n",
            "average time interval for error correction :0.019110234858839885 ms\n",
            "time interval for building model:10.634422302246094 ms\n",
            "time interval for indexing data :4.211664199829102 ms\n",
            "average time interval for indexing data :0.000928292748474565 ms\n",
            "time interval for error correction :114.37845230102539 ms\n",
            "average time interval for error correction :0.025221268423599865 ms\n",
            "time interval for building model:5.825042724609375 ms\n",
            "time interval for indexing data :2.5849342346191406 ms\n",
            "average time interval for indexing data :0.000569745257795711 ms\n",
            "time interval for error correction :50.698280334472656 ms\n",
            "average time interval for error correction :0.01117933414211084 ms\n",
            "time interval for building model:6.643772125244141 ms\n",
            "time interval for indexing data :2.5169849395751953 ms\n",
            "average time interval for indexing data :0.0005547685562211143 ms\n",
            "time interval for error correction :62.83116340637207 ms\n",
            "average time interval for error correction :0.013854721809563852 ms\n",
            "time interval for building model:6.969213485717773 ms\n",
            "time interval for indexing data :2.643585205078125 ms\n",
            "average time interval for indexing data :0.0005826725159969418 ms\n",
            "time interval for error correction :43.936967849731445 ms\n",
            "average time interval for error correction :0.009688416284395027 ms\n",
            "time interval for building model:7.07554817199707 ms\n",
            "time interval for indexing data :2.6662349700927734 ms\n",
            "average time interval for indexing data :0.0005876647498551407 ms\n",
            "time interval for error correction :50.39787292480469 ms\n",
            "average time interval for error correction :0.011113092155414485 ms\n",
            "time interval for building model:6.597280502319336 ms\n",
            "time interval for indexing data :2.553224563598633 ms\n",
            "average time interval for indexing data :0.0005627561303942325 ms\n",
            "time interval for error correction :54.9774169921875 ms\n",
            "average time interval for error correction :0.012122914441496694 ms\n",
            "average times (ms): 7.300209999084473 2.927839756011963 0.0006453250509173382 60.29796600341797 0.01329027242746704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aauKLxpT-C72"
      },
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TB92NvO-EsH",
        "outputId": "5b490aa3-207c-4a06-ba49-1fd9d850fdc5"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error \n",
        "import math\n",
        "import time\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  reg = Ridge(alpha=0.1)\n",
        "  reg.fit(X_train,Y_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  # devpre=reg.predict(np.array(devkeys).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
        "  # for i in range(0,len(devpre)):\n",
        "  #     devpre[i]=abs(int(devpre[i]))\n",
        "  # mse_LR=mean_squared_error(devres,devpre)\n",
        "  # print(\"MSE dev: \",mse_LR)\n",
        "  t1=time.time()\n",
        "  testpre=reg.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  for i in range(0,len(testpre)):\n",
        "    testpre[i]=abs(int(testpre[i]))\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  # print(\"log MSE test: \",round(math.log(1+mean_squared_error(testres,testpre),2),3))\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_loc=testpre[i]\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "      finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "      finding_res=trainres[0]\n",
        "    else:\n",
        "      finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "    # i=begin\n",
        "    # while i<=end:\n",
        "    #   # print(i,end)\n",
        "    #   if finding_res==trainkeys[i]:\n",
        "    #     break\n",
        "    #   else:\n",
        "    #     i=i+1\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/count_error*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:3.411531448364258 ms\n",
            "time interval for indexing data :3.724813461303711 ms\n",
            "average time interval for indexing data :0.0008209859954383317 ms\n",
            "time interval for error correction :51.87702178955078 ms\n",
            "average time interval for error correction :0.011434212428818775 ms\n",
            "time interval for building model:3.5953521728515625 ms\n",
            "time interval for indexing data :3.3681392669677734 ms\n",
            "average time interval for indexing data :0.0007423714496292205 ms\n",
            "time interval for error correction :54.032325744628906 ms\n",
            "average time interval for error correction :0.011909262892798965 ms\n",
            "time interval for building model:3.6787986755371094 ms\n",
            "time interval for indexing data :3.3736228942871094 ms\n",
            "average time interval for indexing data :0.0007435800957212056 ms\n",
            "time interval for error correction :52.93536186218262 ms\n",
            "average time interval for error correction :0.01166748112457188 ms\n",
            "time interval for building model:3.24249267578125 ms\n",
            "time interval for indexing data :3.393411636352539 ms\n",
            "average time interval for indexing data :0.0007479417316183688 ms\n",
            "time interval for error correction :56.43153190612793 ms\n",
            "average time interval for error correction :0.012438071832957446 ms\n",
            "time interval for building model:3.475189208984375 ms\n",
            "time interval for indexing data :2.7391910552978516 ms\n",
            "average time interval for indexing data :0.0006037449978615498 ms\n",
            "time interval for error correction :58.58159065246582 ms\n",
            "average time interval for error correction :0.012911966200675737 ms\n",
            "time interval for building model:4.514932632446289 ms\n",
            "time interval for indexing data :2.8247833251953125 ms\n",
            "average time interval for indexing data :0.0006226103868625331 ms\n",
            "time interval for error correction :54.2910099029541 ms\n",
            "average time interval for error correction :0.011966279458442605 ms\n",
            "time interval for building model:5.09333610534668 ms\n",
            "time interval for indexing data :2.796649932861328 ms\n",
            "average time interval for indexing data :0.0006164095069123492 ms\n",
            "time interval for error correction :47.38140106201172 ms\n",
            "average time interval for error correction :0.01044333283271142 ms\n",
            "time interval for building model:4.522800445556641 ms\n",
            "time interval for indexing data :2.3956298828125 ms\n",
            "average time interval for indexing data :0.0005280206927071854 ms\n",
            "time interval for error correction :57.89637565612793 ms\n",
            "average time interval for error correction :0.012760937989007699 ms\n",
            "time interval for building model:4.914522171020508 ms\n",
            "time interval for indexing data :2.889871597290039 ms\n",
            "average time interval for indexing data :0.0006369564904760941 ms\n",
            "time interval for error correction :52.37102508544922 ms\n",
            "average time interval for error correction :0.011543095676757598 ms\n",
            "time interval for building model:4.4422149658203125 ms\n",
            "time interval for indexing data :4.330158233642578 ms\n",
            "average time interval for indexing data :0.0009544100140274583 ms\n",
            "time interval for error correction :61.71274185180664 ms\n",
            "average time interval for error correction :0.013602103119199172 ms\n",
            "time interval for building model:3.6313533782958984 ms\n",
            "time interval for indexing data :3.3991336822509766 ms\n",
            "average time interval for indexing data :0.00074920292754044 ms\n",
            "time interval for error correction :57.5103759765625 ms\n",
            "average time interval for error correction :0.01267585981409797 ms\n",
            "time interval for building model:9.324789047241211 ms\n",
            "time interval for indexing data :4.715681076049805 ms\n",
            "average time interval for indexing data :0.0010393830892770123 ms\n",
            "time interval for error correction :70.40882110595703 ms\n",
            "average time interval for error correction :0.015518805621767034 ms\n",
            "time interval for building model:4.164218902587891 ms\n",
            "time interval for indexing data :2.9859542846679688 ms\n",
            "average time interval for indexing data :0.0006581340720008747 ms\n",
            "time interval for error correction :52.08778381347656 ms\n",
            "average time interval for error correction :0.011480666478615068 ms\n",
            "time interval for building model:3.6377906799316406 ms\n",
            "time interval for indexing data :2.780914306640625 ms\n",
            "average time interval for indexing data :0.000612941218126653 ms\n",
            "time interval for error correction :58.670997619628906 ms\n",
            "average time interval for error correction :0.012931672386958101 ms\n",
            "time interval for building model:8.213996887207031 ms\n",
            "time interval for indexing data :6.814002990722656 ms\n",
            "average time interval for indexing data :0.0015018741438665763 ms\n",
            "time interval for error correction :52.88124084472656 ms\n",
            "average time interval for error correction :0.011655552313142288 ms\n",
            "time interval for building model:3.6520957946777344 ms\n",
            "time interval for indexing data :3.348112106323242 ms\n",
            "average time interval for indexing data :0.0007379572639019709 ms\n",
            "time interval for error correction :52.790164947509766 ms\n",
            "average time interval for error correction :0.011635478278049319 ms\n",
            "time interval for building model:3.2706260681152344 ms\n",
            "time interval for indexing data :3.3674240112304688 ms\n",
            "average time interval for indexing data :0.0007422138001389616 ms\n",
            "time interval for error correction :55.045366287231445 ms\n",
            "average time interval for error correction :0.012132547120835672 ms\n",
            "time interval for building model:3.733396530151367 ms\n",
            "time interval for indexing data :2.7382373809814453 ms\n",
            "average time interval for indexing data :0.0006035347985412047 ms\n",
            "time interval for error correction :60.576438903808594 ms\n",
            "average time interval for error correction :0.013351650629007845 ms\n",
            "time interval for building model:6.044626235961914 ms\n",
            "time interval for indexing data :3.5278797149658203 ms\n",
            "average time interval for indexing data :0.0007775798357870444 ms\n",
            "time interval for error correction :60.515642166137695 ms\n",
            "average time interval for error correction :0.013338250422335838 ms\n",
            "time interval for building model:3.3168792724609375 ms\n",
            "time interval for indexing data :3.388643264770508 ms\n",
            "average time interval for indexing data :0.0007468907350166427 ms\n",
            "time interval for error correction :53.82871627807617 ms\n",
            "average time interval for error correction :0.011864385337905261 ms\n",
            "average times (ms): 4.494047164916992 3.445112705230713 0.0007593371622725838 56.091296672821045 0.012363080597932782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGZzmGF2-HMu"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4xOmcqM-JY3",
        "outputId": "3ed237be-f70e-45f8-cdad-649d2727bf5b"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  NB = GaussianNB()\n",
        "  NB.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=NB.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=NB.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:22.747278213500977 ms\n",
            "time interval for indexing data :82.57627487182617 ms\n",
            "average time interval for indexing data :0.018200633650391488 ms\n",
            "time interval for error correction :33.92648696899414 ms\n",
            "average time interval for error correction :0.00753754431659501 ms\n",
            "time interval for building model:20.09868621826172 ms\n",
            "time interval for indexing data :79.6358585357666 ms\n",
            "average time interval for indexing data :0.017552536595937095 ms\n",
            "time interval for error correction :35.079002380371094 ms\n",
            "average time interval for error correction :0.007793601950760074 ms\n",
            "time interval for building model:21.559715270996094 ms\n",
            "time interval for indexing data :80.596923828125 ms\n",
            "average time interval for indexing data :0.017764364961014988 ms\n",
            "time interval for error correction :34.96980667114258 ms\n",
            "average time interval for error correction :0.007769341628780843 ms\n",
            "time interval for building model:21.83675765991211 ms\n",
            "time interval for indexing data :81.6497802734375 ms\n",
            "average time interval for indexing data :0.017996425010676106 ms\n",
            "time interval for error correction :31.65721893310547 ms\n",
            "average time interval for error correction :0.007033374568563757 ms\n",
            "time interval for building model:21.792173385620117 ms\n",
            "time interval for indexing data :82.16977119445801 ms\n",
            "average time interval for indexing data :0.018111036190094337 ms\n",
            "time interval for error correction :33.350467681884766 ms\n",
            "average time interval for error correction :0.007409568469647804 ms\n",
            "time interval for building model:23.647069931030273 ms\n",
            "time interval for indexing data :73.79841804504395 ms\n",
            "average time interval for indexing data :0.01626590655610402 ms\n",
            "time interval for error correction :31.567096710205078 ms\n",
            "average time interval for error correction :0.007013351857410593 ms\n",
            "time interval for building model:19.520282745361328 ms\n",
            "time interval for indexing data :86.2112045288086 ms\n",
            "average time interval for indexing data :0.01900180835988728 ms\n",
            "time interval for error correction :34.5458984375 ms\n",
            "average time interval for error correction :0.007675160728171517 ms\n",
            "time interval for building model:23.012399673461914 ms\n",
            "time interval for indexing data :87.42308616638184 ms\n",
            "average time interval for indexing data :0.019268919146215965 ms\n",
            "time interval for error correction :35.549163818359375 ms\n",
            "average time interval for error correction :0.007898059057622612 ms\n",
            "time interval for building model:20.873308181762695 ms\n",
            "time interval for indexing data :81.8779468536377 ms\n",
            "average time interval for indexing data :0.018046715198068698 ms\n",
            "time interval for error correction :26.989459991455078 ms\n",
            "average time interval for error correction :0.005996325259154649 ms\n",
            "time interval for building model:23.726463317871094 ms\n",
            "time interval for indexing data :88.58847618103027 ms\n",
            "average time interval for indexing data :0.01952578271567782 ms\n",
            "time interval for error correction :32.515764236450195 ms\n",
            "average time interval for error correction :0.007224120025872072 ms\n",
            "time interval for building model:21.65389060974121 ms\n",
            "time interval for indexing data :87.00847625732422 ms\n",
            "average time interval for indexing data :0.01917753499169588 ms\n",
            "time interval for error correction :32.71007537841797 ms\n",
            "average time interval for error correction :0.007267290686162624 ms\n",
            "time interval for building model:21.270036697387695 ms\n",
            "time interval for indexing data :85.2961540222168 ms\n",
            "average time interval for indexing data :0.018800122112016045 ms\n",
            "time interval for error correction :33.14614295959473 ms\n",
            "average time interval for error correction :0.007364173063673567 ms\n",
            "time interval for building model:21.53778076171875 ms\n",
            "time interval for indexing data :81.93135261535645 ms\n",
            "average time interval for indexing data :0.018058486360008032 ms\n",
            "time interval for error correction :34.53564643859863 ms\n",
            "average time interval for error correction :0.007672883012352506 ms\n",
            "time interval for building model:20.330190658569336 ms\n",
            "time interval for indexing data :84.9618911743164 ms\n",
            "average time interval for indexing data :0.018726447250235048 ms\n",
            "time interval for error correction :32.79471397399902 ms\n",
            "average time interval for error correction :0.007286095084203293 ms\n",
            "time interval for building model:21.01755142211914 ms\n",
            "time interval for indexing data :79.44965362548828 ms\n",
            "average time interval for indexing data :0.017511495178639692 ms\n",
            "time interval for error correction :32.5472354888916 ms\n",
            "average time interval for error correction :0.007231112083735082 ms\n",
            "time interval for building model:21.715641021728516 ms\n",
            "time interval for indexing data :84.11574363708496 ms\n",
            "average time interval for indexing data :0.018539947903258754 ms\n",
            "time interval for error correction :30.0750732421875 ms\n",
            "average time interval for error correction :0.006681864750541546 ms\n",
            "time interval for building model:20.099163055419922 ms\n",
            "time interval for indexing data :83.06741714477539 ms\n",
            "average time interval for indexing data :0.01830888630036927 ms\n",
            "time interval for error correction :34.630537033081055 ms\n",
            "average time interval for error correction :0.007693965126212187 ms\n",
            "time interval for building model:22.555112838745117 ms\n",
            "time interval for indexing data :84.92898941040039 ms\n",
            "average time interval for indexing data :0.018719195373683134 ms\n",
            "time interval for error correction :33.06317329406738 ms\n",
            "average time interval for error correction :0.007345739456580179 ms\n",
            "time interval for building model:21.694660186767578 ms\n",
            "time interval for indexing data :80.67941665649414 ms\n",
            "average time interval for indexing data :0.01778254720222485 ms\n",
            "time interval for error correction :33.38122367858887 ms\n",
            "average time interval for error correction :0.0074164016171048355 ms\n",
            "time interval for building model:23.82183074951172 ms\n",
            "time interval for indexing data :80.40404319763184 ms\n",
            "average time interval for indexing data :0.01772185214847517 ms\n",
            "time interval for error correction :39.86334800720215 ms\n",
            "average time interval for error correction :0.008856553656343512 ms\n",
            "average times (ms): 21.725499629974365 82.81854391098022 0.018254032160233684 33.344876766204834 0.00734954303861689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-KHvKKN-Qga"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnx99u5_-Rpe",
        "outputId": "80d3008d-1dff-4da7-ff9f-2c7829058236"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  neigh = KNeighborsClassifier(n_neighbors=9)\n",
        "  neigh.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=neigh.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=neigh.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  # print(testpre)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:33.306121826171875 ms\n",
            "time interval for indexing data :153.80549430847168 ms\n",
            "average time interval for indexing data :0.03390026323748549 ms\n",
            "time interval for error correction :7.293462753295898 ms\n",
            "average time interval for error correction :0.0016075518521701342 ms\n",
            "time interval for building model:31.209945678710938 ms\n",
            "time interval for indexing data :167.9399013519287 ms\n",
            "average time interval for indexing data :0.03701562736432196 ms\n",
            "time interval for error correction :7.184028625488281 ms\n",
            "average time interval for error correction :0.0015834314801605204 ms\n",
            "time interval for building model:31.68487548828125 ms\n",
            "time interval for indexing data :186.42878532409668 ms\n",
            "average time interval for indexing data :0.04109076158785468 ms\n",
            "time interval for error correction :7.391214370727539 ms\n",
            "average time interval for error correction :0.001629097282505519 ms\n",
            "time interval for building model:31.752347946166992 ms\n",
            "time interval for indexing data :197.56102561950684 ms\n",
            "average time interval for indexing data :0.0435444182542444 ms\n",
            "time interval for error correction :7.2193145751953125 ms\n",
            "average time interval for error correction :0.0015912088550132934 ms\n",
            "time interval for building model:31.995773315429688 ms\n",
            "time interval for indexing data :178.7097454071045 ms\n",
            "average time interval for indexing data :0.03938940828898049 ms\n",
            "time interval for error correction :7.184743881225586 ms\n",
            "average time interval for error correction :0.0015835891296507795 ms\n",
            "time interval for building model:33.76460075378418 ms\n",
            "time interval for indexing data :154.88576889038086 ms\n",
            "average time interval for indexing data :0.03413836651760654 ms\n",
            "time interval for error correction :10.626554489135742 ms\n",
            "average time interval for error correction :0.002342198476776668 ms\n",
            "time interval for building model:41.858673095703125 ms\n",
            "time interval for indexing data :174.15428161621094 ms\n",
            "average time interval for indexing data :0.03838533868552148 ms\n",
            "time interval for error correction :7.266998291015625 ms\n",
            "average time interval for error correction :0.0016017188210305543 ms\n",
            "time interval for building model:32.691001892089844 ms\n",
            "time interval for indexing data :164.56222534179688 ms\n",
            "average time interval for indexing data :0.03627115392148928 ms\n",
            "time interval for error correction :10.080099105834961 ms\n",
            "average time interval for error correction :0.0022217542662188584 ms\n",
            "time interval for building model:32.41229057312012 ms\n",
            "time interval for indexing data :158.70404243469238 ms\n",
            "average time interval for indexing data :0.0349799520464387 ms\n",
            "time interval for error correction :7.700681686401367 ms\n",
            "average time interval for error correction :0.0016973069619575418 ms\n",
            "time interval for building model:37.387847900390625 ms\n",
            "time interval for indexing data :161.72099113464355 ms\n",
            "average time interval for indexing data :0.03564491759635079 ms\n",
            "time interval for error correction :7.948875427246094 ms\n",
            "average time interval for error correction :0.0017520113350773846 ms\n",
            "time interval for building model:36.44752502441406 ms\n",
            "time interval for indexing data :164.36505317687988 ms\n",
            "average time interval for indexing data :0.03622769521200791 ms\n",
            "time interval for error correction :8.339166641235352 ms\n",
            "average time interval for error correction :0.0018380354069286646 ms\n",
            "time interval for building model:35.66241264343262 ms\n",
            "time interval for indexing data :165.53044319152832 ms\n",
            "average time interval for indexing data :0.036484558781469764 ms\n",
            "time interval for error correction :7.588863372802734 ms\n",
            "average time interval for error correction :0.0016726610916470651 ms\n",
            "time interval for building model:32.13357925415039 ms\n",
            "time interval for indexing data :164.2594337463379 ms\n",
            "average time interval for indexing data :0.03620441563727968 ms\n",
            "time interval for error correction :7.117033004760742 ms\n",
            "average time interval for error correction :0.001568664977906269 ms\n",
            "time interval for building model:30.779123306274414 ms\n",
            "time interval for indexing data :164.13021087646484 ms\n",
            "average time interval for indexing data :0.0361759336293729 ms\n",
            "time interval for error correction :7.331132888793945 ms\n",
            "average time interval for error correction :0.0016158547253237701 ms\n",
            "time interval for building model:34.72185134887695 ms\n",
            "time interval for indexing data :160.75682640075684 ms\n",
            "average time interval for indexing data :0.03543240608348178 ms\n",
            "time interval for error correction :10.827064514160156 ms\n",
            "average time interval for error correction :0.0023863928838792495 ms\n",
            "time interval for building model:31.562328338623047 ms\n",
            "time interval for indexing data :164.29710388183594 ms\n",
            "average time interval for indexing data :0.03621271851043331 ms\n",
            "time interval for error correction :7.196903228759766 ms\n",
            "average time interval for error correction :0.0015862691709851808 ms\n",
            "time interval for building model:38.120269775390625 ms\n",
            "time interval for indexing data :159.2428684234619 ms\n",
            "average time interval for indexing data :0.03509871466243374 ms\n",
            "time interval for error correction :7.875680923461914 ms\n",
            "average time interval for error correction :0.001735878537240889 ms\n",
            "time interval for building model:31.10980987548828 ms\n",
            "time interval for indexing data :164.79015350341797 ms\n",
            "average time interval for indexing data :0.03632139155905179 ms\n",
            "time interval for error correction :7.084846496582031 ms\n",
            "average time interval for error correction :0.0015615707508446178 ms\n",
            "time interval for building model:33.45799446105957 ms\n",
            "time interval for indexing data :174.97682571411133 ms\n",
            "average time interval for indexing data :0.03856663559931923 ms\n",
            "time interval for error correction :7.715702056884766 ms\n",
            "average time interval for error correction :0.001700617601252979 ms\n",
            "time interval for building model:31.255245208740234 ms\n",
            "time interval for indexing data :156.72779083251953 ms\n",
            "average time interval for indexing data :0.03454436650485332 ms\n",
            "time interval for error correction :7.504701614379883 ms\n",
            "average time interval for error correction :0.0016541110016265997 ms\n",
            "average times (ms): 33.66568088531494 166.87744855880737 0.03678145218399986 7.923853397369385 0.0017464962304098272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu2dnJWH-V3_"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-PP35du-XjD",
        "outputId": "0856274f-324d-41da-e9f9-468ea3a09351"
      },
      "source": [
        "from sklearn import tree\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  dtree = tree.DecisionTreeClassifier(max_depth=12)\n",
        "  dtree.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=tree.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=dtree.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:3.7889480590820312 ms\n",
            "time interval for indexing data :1.3091564178466797 ms\n",
            "average time interval for indexing data :0.005365395155109343 ms\n",
            "time interval for error correction :1.024007797241211 ms\n",
            "average time interval for error correction :0.004214023856959716 ms\n",
            "time interval for building model:7.482051849365234 ms\n",
            "time interval for indexing data :1.2998580932617188 ms\n",
            "average time interval for indexing data :0.005327287267466061 ms\n",
            "time interval for error correction :1.0647773742675781 ms\n",
            "average time interval for error correction :0.00438179989410526 ms\n",
            "time interval for building model:5.9528350830078125 ms\n",
            "time interval for indexing data :0.9620189666748047 ms\n",
            "average time interval for indexing data :0.003942700683093462 ms\n",
            "time interval for error correction :1.0631084442138672 ms\n",
            "average time interval for error correction :0.004374931869192869 ms\n",
            "time interval for building model:9.424924850463867 ms\n",
            "time interval for indexing data :0.9551048278808594 ms\n",
            "average time interval for indexing data :0.003914364048692046 ms\n",
            "time interval for error correction :1.0704994201660156 ms\n",
            "average time interval for error correction :0.0044053474080906 ms\n",
            "time interval for building model:5.855321884155273 ms\n",
            "time interval for indexing data :1.001596450805664 ms\n",
            "average time interval for indexing data :0.00410490348690846 ms\n",
            "time interval for error correction :1.6336441040039062 ms\n",
            "average time interval for error correction :0.006722815242814429 ms\n",
            "time interval for building model:5.984067916870117 ms\n",
            "time interval for indexing data :0.9582042694091797 ms\n",
            "average time interval for indexing data :0.003927066677906475 ms\n",
            "time interval for error correction :1.0616779327392578 ms\n",
            "average time interval for error correction :0.004369044990696534 ms\n",
            "time interval for building model:4.169702529907227 ms\n",
            "time interval for indexing data :0.8244514465332031 ms\n",
            "average time interval for indexing data :0.003378899371037718 ms\n",
            "time interval for error correction :1.0852813720703125 ms\n",
            "average time interval for error correction :0.004466178485886059 ms\n",
            "time interval for building model:4.446983337402344 ms\n",
            "time interval for indexing data :0.6210803985595703 ms\n",
            "average time interval for indexing data :0.002545411469506436 ms\n",
            "time interval for error correction :1.2736320495605469 ms\n",
            "average time interval for error correction :0.0052412841545701515 ms\n",
            "time interval for building model:9.372949600219727 ms\n",
            "time interval for indexing data :0.9667873382568359 ms\n",
            "average time interval for indexing data :0.003962243189577197 ms\n",
            "time interval for error correction :1.0576248168945312 ms\n",
            "average time interval for error correction :0.004352365501623586 ms\n",
            "time interval for building model:5.282402038574219 ms\n",
            "time interval for indexing data :0.9679794311523438 ms\n",
            "average time interval for indexing data :0.00396712881619813 ms\n",
            "time interval for error correction :1.054525375366211 ms\n",
            "average time interval for error correction :0.004339610598214859 ms\n",
            "time interval for building model:6.567955017089844 ms\n",
            "time interval for indexing data :1.2750625610351562 ms\n",
            "average time interval for indexing data :0.00522566623375064 ms\n",
            "time interval for error correction :1.0752677917480469 ms\n",
            "average time interval for error correction :0.004424970336411716 ms\n",
            "time interval for building model:4.981756210327148 ms\n",
            "time interval for indexing data :0.8895397186279297 ms\n",
            "average time interval for indexing data :0.0036456545845406957 ms\n",
            "time interval for error correction :1.2428760528564453 ms\n",
            "average time interval for error correction :0.005114716266898952 ms\n",
            "time interval for building model:4.122495651245117 ms\n",
            "time interval for indexing data :0.6420612335205078 ms\n",
            "average time interval for indexing data :0.002631398498034868 ms\n",
            "time interval for error correction :1.2197494506835938 ms\n",
            "average time interval for error correction :0.005019545064541538 ms\n",
            "time interval for building model:6.798744201660156 ms\n",
            "time interval for indexing data :1.1949539184570312 ms\n",
            "average time interval for indexing data :0.004897352124823898 ms\n",
            "time interval for error correction :1.150369644165039 ms\n",
            "average time interval for error correction :0.0047340314574692965 ms\n",
            "time interval for building model:6.127119064331055 ms\n",
            "time interval for indexing data :3.7374496459960938 ms\n",
            "average time interval for indexing data :0.015317416581951205 ms\n",
            "time interval for error correction :1.7309188842773438 ms\n",
            "average time interval for error correction :0.007123122980565201 ms\n",
            "time interval for building model:6.653070449829102 ms\n",
            "time interval for indexing data :1.0004043579101562 ms\n",
            "average time interval for indexing data :0.004100017860287526 ms\n",
            "time interval for error correction :1.0633468627929688 ms\n",
            "average time interval for error correction :0.004375913015608924 ms\n",
            "time interval for building model:5.557775497436523 ms\n",
            "time interval for indexing data :1.5192031860351562 ms\n",
            "average time interval for indexing data :0.0062262425657178535 ms\n",
            "time interval for error correction :1.445770263671875 ms\n",
            "average time interval for error correction :0.005949671866962448 ms\n",
            "time interval for building model:5.125999450683594 ms\n",
            "time interval for indexing data :2.025604248046875 ms\n",
            "average time interval for indexing data :0.008301656754290471 ms\n",
            "time interval for error correction :1.2192726135253906 ms\n",
            "average time interval for error correction :0.005017582771709427 ms\n",
            "time interval for building model:6.05463981628418 ms\n",
            "time interval for indexing data :0.9357929229736328 ms\n",
            "average time interval for indexing data :0.003835216897432921 ms\n",
            "time interval for error correction :1.1219978332519531 ms\n",
            "average time interval for error correction :0.004617275033958655 ms\n",
            "time interval for building model:5.366325378417969 ms\n",
            "time interval for indexing data :0.8802413940429688 ms\n",
            "average time interval for indexing data :0.003607546696897413 ms\n",
            "time interval for error correction :1.0631084442138672 ms\n",
            "average time interval for error correction :0.004374931869192869 ms\n",
            "average times (ms): 5.955803394317627 1.1983275413513184 0.004911178448161142 1.186072826385498 0.004860954206497943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkR3II6I-cLu"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB31jCHj-eQU",
        "outputId": "625c0e09-1f91-4e25-b705-1cafa4e71c19"
      },
      "source": [
        "import numpy as np\n",
        "temp=Z_train.reshape(1,-1)\n",
        "T_train=np.zeros((temp.size, temp.max()+1))\n",
        "T_train[np.arange(temp.size),temp] = 1\n",
        "print(T_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWxoZmX1-gXE",
        "outputId": "094d1aa9-c829-460a-ced6-eb3e0f271b98"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(115, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p02yahFF-g7j",
        "outputId": "9b08031d-7b66-4431-d76e-88d55fd7ed93"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api\n",
        "from keras import models as md\n",
        "from keras import layers as lr\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  model = md.Sequential()\n",
        "  model.add(lr.Dense(X_train.shape[1],activation=\"relu\"))\n",
        "  # model.add(lr.Dense(4,activation=\"relu\"))\n",
        "  model.add(lr.Dense(128,activation=\"relu\"))\n",
        "  # model.add(lr.Dropout(0.2))\n",
        "  model.add(lr.Dense(temp.max()+1,activation=\"softmax\"))\n",
        "  model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])#compile the model\n",
        "  model.fit(X_train, T_train, epochs=16, batch_size=32)#fit the model\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=tree.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=model.predict(X_test)#.reshape(1,-1).tolist()[0]\n",
        "  testpre=np.argmax(testpre,axis=1)\n",
        "  # print(testpre)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  # return\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 22.6195 - accuracy: 0.2078\n",
            "Epoch 2/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.8302 - accuracy: 0.6873\n",
            "Epoch 3/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.3182 - accuracy: 0.8496\n",
            "Epoch 4/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 6.6829 - accuracy: 0.8704\n",
            "Epoch 5/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.7142 - accuracy: 0.8610\n",
            "Epoch 6/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.5718 - accuracy: 0.8829\n",
            "Epoch 7/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.5223 - accuracy: 0.8558\n",
            "Epoch 8/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.6340 - accuracy: 0.8558\n",
            "Epoch 9/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7635 - accuracy: 0.8252\n",
            "Epoch 10/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6594 - accuracy: 0.5618\n",
            "Epoch 11/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.6694 - accuracy: 0.6567\n",
            "Epoch 12/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2900 - accuracy: 0.8336\n",
            "Epoch 13/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8402 - accuracy: 0.8294\n",
            "Epoch 14/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.8131\n",
            "Epoch 15/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0505 - accuracy: 0.7161\n",
            "Epoch 16/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8920 - accuracy: 0.7081\n",
            "time interval for building model:1604.7098636627197 ms\n",
            "time interval for indexing data :140.669584274292 ms\n",
            "average time interval for indexing data :3.701831165112947 ms\n",
            "time interval for error correction :0.47898292541503906 ms\n",
            "average time interval for error correction :0.012945484470676732 ms\n",
            "Epoch 1/16\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 1.6893 - accuracy: 0.7863\n",
            "Epoch 2/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7005 - accuracy: 0.8200\n",
            "Epoch 3/16\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.2520 - accuracy: 0.8534\n",
            "Epoch 4/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.9169 - accuracy: 0.8652\n",
            "Epoch 5/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1619 - accuracy: 0.8610\n",
            "Epoch 6/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4046 - accuracy: 0.7037\n",
            "Epoch 7/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3862 - accuracy: 0.8662\n",
            "Epoch 8/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0185 - accuracy: 0.8436\n",
            "Epoch 9/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7766 - accuracy: 0.7742\n",
            "Epoch 10/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1058 - accuracy: 0.8388\n",
            "Epoch 11/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.8579\n",
            "Epoch 12/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7967\n",
            "Epoch 13/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.8089\n",
            "Epoch 14/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3850 - accuracy: 0.8318\n",
            "Epoch 15/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2161 - accuracy: 0.8621\n",
            "Epoch 16/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.1508 - accuracy: 0.6599\n",
            "time interval for building model:986.1316680908203 ms\n",
            "time interval for indexing data :90.29769897460938 ms\n",
            "average time interval for indexing data :2.376255236173931 ms\n",
            "time interval for error correction :0.34308433532714844 ms\n",
            "average time interval for error correction :0.009272549603436445 ms\n",
            "Epoch 1/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 3.2629 - accuracy: 0.5383\n",
            "Epoch 2/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2814 - accuracy: 0.8662\n",
            "Epoch 3/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6884 - accuracy: 0.8579\n",
            "Epoch 4/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6184 - accuracy: 0.8058\n",
            "Epoch 5/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2523 - accuracy: 0.6390\n",
            "Epoch 6/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1057 - accuracy: 0.8610\n",
            "Epoch 7/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8460 - accuracy: 0.8485\n",
            "Epoch 8/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.8732\n",
            "Epoch 9/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7569 - accuracy: 0.7651\n",
            "Epoch 10/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.8725\n",
            "Epoch 11/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.8436\n",
            "Epoch 12/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.8315\n",
            "Epoch 13/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.8829\n",
            "Epoch 14/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.8454\n",
            "Epoch 15/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5858 - accuracy: 0.8621\n",
            "Epoch 16/16\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5087 - accuracy: 0.8315\n",
            "time interval for building model:838.7997150421143 ms\n",
            "time interval for indexing data :89.40339088439941 ms\n",
            "average time interval for indexing data :2.352720812747353 ms\n",
            "time interval for error correction :0.43010711669921875 ms\n",
            "average time interval for error correction :0.011624516667546454 ms\n",
            "Epoch 1/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 6.8360 - accuracy: 0.2478\n",
            "Epoch 2/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3288 - accuracy: 0.7123\n",
            "Epoch 3/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2591 - accuracy: 0.8693\n",
            "Epoch 4/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8823 - accuracy: 0.8871\n",
            "Epoch 5/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.4942 - accuracy: 0.8829\n",
            "Epoch 6/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5991 - accuracy: 0.8589\n",
            "Epoch 7/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.3838 - accuracy: 0.8287\n",
            "Epoch 8/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0186 - accuracy: 0.8280\n",
            "Epoch 9/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.8002\n",
            "Epoch 10/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.8388\n",
            "Epoch 11/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.8527\n",
            "Epoch 12/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8287\n",
            "Epoch 13/16\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.8370\n",
            "Epoch 14/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7780\n",
            "Epoch 15/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.8707\n",
            "Epoch 16/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8530\n",
            "time interval for building model:805.9942722320557 ms\n",
            "time interval for indexing data :95.23773193359375 ms\n",
            "average time interval for indexing data :2.506256103515625 ms\n",
            "time interval for error correction :0.34046173095703125 ms\n",
            "average time interval for error correction :0.009201668404244088 ms\n",
            "Epoch 1/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9028 - accuracy: 0.8610\n",
            "Epoch 2/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.6939\n",
            "Epoch 3/16\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7913 - accuracy: 0.8589\n",
            "Epoch 4/16\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7206 - accuracy: 0.7255\n",
            "Epoch 5/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.8579\n",
            "Epoch 6/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9652 - accuracy: 0.8496\n",
            "Epoch 7/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8652\n",
            "Epoch 8/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.6817\n",
            "Epoch 9/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5495 - accuracy: 0.8568\n",
            "Epoch 10/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.8339\n",
            "Epoch 11/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4566 - accuracy: 0.8923\n",
            "Epoch 12/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5166 - accuracy: 0.8124\n",
            "Epoch 13/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5104 - accuracy: 0.8537\n",
            "Epoch 14/16\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6003 - accuracy: 0.8527\n",
            "Epoch 15/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7863\n",
            "Epoch 16/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8725\n",
            "time interval for building model:812.0172023773193 ms\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffb638eaf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "time interval for indexing data :97.75257110595703 ms\n",
            "average time interval for indexing data :2.5724360817357117 ms\n",
            "time interval for error correction :0.29659271240234375 ms\n",
            "average time interval for error correction :0.008016019254117398 ms\n",
            "Epoch 1/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 8.9416 - accuracy: 0.2645\n",
            "Epoch 2/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.9597 - accuracy: 0.8700\n",
            "Epoch 3/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 4.2704 - accuracy: 0.8339\n",
            "Epoch 4/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 3.1149 - accuracy: 0.8454\n",
            "Epoch 5/16\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.5070 - accuracy: 0.8693\n",
            "Epoch 6/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0876 - accuracy: 0.7932\n",
            "Epoch 7/16\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0501 - accuracy: 0.5882\n",
            "Epoch 8/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.9937 - accuracy: 0.7926\n",
            "Epoch 9/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.3299 - accuracy: 0.8443\n",
            "Epoch 10/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.2891 - accuracy: 0.8277\n",
            "Epoch 11/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7212 - accuracy: 0.7405\n",
            "Epoch 12/16\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.8579\n",
            "Epoch 13/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.8461\n",
            "Epoch 14/16\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6339 - accuracy: 0.8579\n",
            "Epoch 15/16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8805 - accuracy: 0.8346\n",
            "Epoch 16/16\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8589\n",
            "time interval for building model:876.9447803497314 ms\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffb627a4d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "time interval for indexing data :100.90351104736328 ms\n",
            "average time interval for indexing data :2.655355553877981 ms\n",
            "time interval for error correction :0.28014183044433594 ms\n",
            "average time interval for error correction :0.00757140082281989 ms\n",
            "Epoch 1/16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-256f8662c760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mcounting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0mavg_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mavg_b\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-256f8662c760>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mtime_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}