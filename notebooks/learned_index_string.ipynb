{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learned_index_string.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQSDJ5IOYXq6"
      },
      "source": [
        "# Test pretrained model to make sure it works correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjXqE-SZVrA2",
        "outputId": "d08793ef-8786-462a-c8e4-78006fc82b09"
      },
      "source": [
        "!python3 -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.1)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp37-none-any.whl size=98051305 sha256=7fc3b24bdaf584fbeba9b9b266a88feb25782b6cbc7b5fcc9d8fb47bffc1edfe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8sbgu31w/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91RhLfVweP87",
        "outputId": "66a55b12-05bf-4447-c56f-2c159ef82295"
      },
      "source": [
        "!pip install keras-word-char-embd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-word-char-embd\n",
            "  Downloading https://files.pythonhosted.org/packages/15/5d/f6a418b22a27133251fbb260c2375c1893ae70698a097d77c4701acd19a4/keras-word-char-embd-0.21.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-word-char-embd) (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-word-char-embd) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-word-char-embd) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-word-char-embd) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-word-char-embd) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-word-char-embd) (1.15.0)\n",
            "Building wheels for collected packages: keras-word-char-embd\n",
            "  Building wheel for keras-word-char-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-word-char-embd: filename=keras_word_char_embd-0.21.0-cp37-none-any.whl size=8520 sha256=440705abfbcf29d3a77fba0b83028fb4d81ed983a70647721ea14a3704ad70ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/e1/10/a68e424326745b9ac1c0695c3da541fe6d051b129230e7456a\n",
            "Successfully built keras-word-char-embd\n",
            "Installing collected packages: keras-word-char-embd\n",
            "Successfully installed keras-word-char-embd-0.21.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOVEpe9JhgS3",
        "outputId": "3970ce9b-e3f6-44e9-b836-64c6704550a3"
      },
      "source": [
        "!pip install chars2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chars2vec\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/0a/8c327aae23e0532d239ec7b30446aca765eb5d9547b4c4b09cdd82e49797/chars2vec-0.1.7.tar.gz (8.1MB)\n",
            "\u001b[K     |████████████████████████████████| 8.1MB 8.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: chars2vec\n",
            "  Building wheel for chars2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chars2vec: filename=chars2vec-0.1.7-cp37-none-any.whl size=8111096 sha256=546f6edc50f55a3f9585fceadca09e79fff72c2d5e65347fc3d88b94e6e9b812\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/b6/65/d7e778ef1213ec77d315aea0f536068b96e36cc94c02abbfde\n",
            "Successfully built chars2vec\n",
            "Installing collected packages: chars2vec\n",
            "Successfully installed chars2vec-0.1.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b3UTfSbifEY",
        "outputId": "45820784-61d8-42a4-a91a-b28b54d4bca6"
      },
      "source": [
        "import spacy\n",
        "# Load the spacy model that you have installed\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "# process a sentence using the model\n",
        "doc = nlp(\"https://colab.research.google.com/drive/1QhLsbeYiJSr838LQkCDRT_cayGEnBabU#scrollTo=5b3UTfSbifEY\")\n",
        "# nlp(\"This is some text that I am processing with Spacy\")\n",
        "# It's that simple - all of the vectors and words are assigned after this point\n",
        "# Get the vector for 'text':\n",
        "# doc[3].vector\n",
        "# Get the mean vector for the entire sentence (useful for sentence classification etc.)\n",
        "doc.vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC4rYzdAeZMn"
      },
      "source": [
        "from keras_wc_embd import get_dicts_generator\n",
        "\n",
        "sentences = [\n",
        "    ['All', 'work', 'and', 'no', 'play'],\n",
        "    ['makes', 'Jack', 'a', 'dull', 'boy', '.'],\n",
        "]\n",
        "dict_generator = get_dicts_generator(\n",
        "    word_min_freq=2,\n",
        "    char_min_freq=2,\n",
        "    word_ignore_case=False,\n",
        "    char_ignore_case=False,\n",
        ")\n",
        "for sentence in sentences:\n",
        "    dict_generator(sentence)\n",
        "\n",
        "word_dict, char_dict, max_word_len = dict_generator(return_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XS0rr-wShV4T"
      },
      "source": [
        "import chars2vec\n",
        "import sklearn.decomposition\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Inutition Engineering pretrained model\n",
        "# Models names: 'eng_50', 'eng_100', 'eng_150' 'eng_200', 'eng_300'\n",
        "c2v_model = chars2vec.load_model('eng_300')\n",
        "\n",
        "words = ['Natural', 'Language', 'Understanding',\n",
        "         'Naturael', 'Longuge', 'Updderctundjing',\n",
        "         'Motural', 'Lamnguoge', 'Understaating',\n",
        "         'Naturrow', 'Laguage', 'Unddertandink',\n",
        "         'Nattural', 'Languagge', 'Umderstoneding',\"123000\"]\n",
        "\n",
        "# Create word embeddings\n",
        "word_embeddings = c2v_model.vectorize_words(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU8yXDjTho9o",
        "outputId": "eafc8d09-0230-4d39-81b4-c320525f2fe7"
      },
      "source": [
        "word_embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.8996639e-02, -5.5493730e-01,  4.3063503e-02, ...,\n",
              "         2.4411604e-02, -1.2669989e-03, -2.0515472e-01],\n",
              "       [-2.4114407e-03, -3.2915655e-01, -3.4444924e-02, ...,\n",
              "         7.7875555e-01, -8.0235877e-05, -6.8429059e-01],\n",
              "       [-7.5301612e-03, -1.9805689e-01, -9.6027501e-04, ...,\n",
              "         2.4984172e-01,  3.1621861e-03, -8.9784861e-01],\n",
              "       ...,\n",
              "       [-1.5706113e-03, -3.4123987e-01, -2.6190478e-02, ...,\n",
              "         8.7753838e-01, -6.0943438e-04, -6.7963564e-01],\n",
              "       [-1.5157115e-02,  1.4041942e-01, -6.9368817e-04, ...,\n",
              "         8.0368020e-02, -1.2572456e-04, -6.0570872e-01],\n",
              "       [ 9.9682738e-04,  1.6417782e-01, -2.3899348e-02, ...,\n",
              "         2.1699288e-01,  2.1775067e-02,  1.0698439e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SZv-bLZaoHl"
      },
      "source": [
        "# Read dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFwScz_2auJ8"
      },
      "source": [
        "## read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRxT1GASatcm",
        "outputId": "3295d7c2-4760-431b-bef0-47e33e111933"
      },
      "source": [
        "import codecs\n",
        "import os\n",
        "minkey=1000\n",
        "maxkey=9999\n",
        "keynum=3000\n",
        "current_path=os.path.abspath(os.curdir)\n",
        "f=codecs.open(os.path.join(current_path,\"data.csv\"), \"r\", \"utf-8\")\n",
        "strlist=f.read().split(\"\\n\")\n",
        "f.close()\n",
        "trainkeys=[]\n",
        "trainres=[]\n",
        "for ele in strlist:\n",
        "    temp=ele.split(\",\")\n",
        "    if len(temp)!=2:\n",
        "        continue\n",
        "    trainkeys.append(temp[0])\n",
        "    trainres.append(int(temp[1]))\n",
        "# f=codecs.open(os.path.join(current_path,\"data_dev.csv\"), \"r\", \"utf-8\")\n",
        "# strlist=f.read().split(\"\\n\")\n",
        "# f.close()\n",
        "# devkeys=[]\n",
        "# devres=[]\n",
        "# for ele in strlist:\n",
        "#     temp=ele.split(\",\")\n",
        "#     if len(temp)!=2:\n",
        "#         continue\n",
        "#     devkeys.append(int(temp[0]))\n",
        "#     devres.append(int(temp[1]))\n",
        "f=codecs.open(os.path.join(current_path,\"data_test.csv\"), \"r\", \"utf-8\")\n",
        "strlist=f.read().split(\"\\n\")\n",
        "f.close()\n",
        "testkeys=[]\n",
        "testres=[]\n",
        "for ele in strlist:\n",
        "    temp=ele.split(\",\")\n",
        "    if len(temp)!=2:\n",
        "        continue\n",
        "    testkeys.append(temp[0])\n",
        "    testres.append(int(temp[1]))\n",
        "\n",
        "# It is very time and space consuming to build models based on the entire dataset\n",
        "# Instead, we divide the dataset into 3 parts (training, dev, testing)\n",
        "# We build and train models based on training set, and give index predictions based on testing set\n",
        "\n",
        "# trainkeys.extend(devkeys)\n",
        "# trainres.extend(devres)\n",
        "# trainkeys.extend(testkeys)\n",
        "# trainres.extend(testres)\n",
        "\n",
        "print(\"training data size:\",len(trainkeys))\n",
        "# print(\"development data size:\",len(devkeys))\n",
        "print(\"testing data size:\",len(testkeys))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data size: 61543\n",
            "testing data size: 20514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW48FI0xa3wh"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6d48abH-LbN"
      },
      "source": [
        "import spacy\n",
        "# Load the spacy model that you have installed\n",
        "pretrain = spacy.load('en_core_web_md')\n",
        "trainkeys_emb=[]\n",
        "# process a sentence using the model\n",
        "for ele in trainkeys:\n",
        "  trainkeys_emb.append(pretrain(ele).vector)\n",
        "testkeys_emb=[]\n",
        "for ele in testkeys:\n",
        "  testkeys_emb.append(pretrain(ele).vector)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQYIycB4aY6D"
      },
      "source": [
        "import chars2vec\n",
        "pretrain = chars2vec.load_model('eng_300')\n",
        "trainkeys_emb = pretrain.vectorize_words(trainkeys)\n",
        "testkeys_emb = pretrain.vectorize_words(testkeys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCGFGNA5a5e9"
      },
      "source": [
        "trainpages=[]\n",
        "for ele in trainres:\n",
        "  trainpages.append(int(ele)//100)\n",
        "testpages=[]\n",
        "for ele in testres:\n",
        "  testpages.append(int(ele)//100)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiK_EuBTa8Ny"
      },
      "source": [
        "import numpy as np\n",
        "R_train=np.array(trainkeys)\n",
        "X_train=np.array(trainkeys_emb)\n",
        "Y_train=np.array(trainres).reshape(-1,1)\n",
        "Z_train=np.array(trainpages).reshape(-1,1)\n",
        "R_test=np.array(testkeys)\n",
        "X_test=np.array(testkeys_emb)\n",
        "Y_test=np.array(testres).reshape(-1,1)\n",
        "Z_test=np.array(testpages).reshape(-1,1)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2afCGS2ibAUN"
      },
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnWSSG9yBABQ"
      },
      "source": [
        "# Build Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6kL8YtnxqPJ"
      },
      "source": [
        "## B-Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCEZkcL-xn7l",
        "outputId": "9239003a-59f0-4589-ede3-7d8bceccb525"
      },
      "source": [
        "import time\n",
        "# ref: https://peefy.github.io/blog/2018/06/10/Python-BTree/\n",
        "class BTreeNode:\n",
        "    '''\n",
        "    B树结点\n",
        "    '''\n",
        "    def __init__(self, n = 0, isleaf = True):\n",
        "        '''\n",
        "        B树结点\n",
        "\n",
        "        Args\n",
        "        ===\n",
        "        `n` : 结点包含关键字的数量\n",
        "\n",
        "        `isleaf` : 是否是叶子节点\n",
        "\n",
        "        '''\n",
        "        # 结点包含关键字的数量\n",
        "        self.n = n\n",
        "        # 关键字的值数组\n",
        "        self.keys = []\n",
        "        # 子结点数组\n",
        "        self.children = []\n",
        "        # 是否是叶子节点\n",
        "        self.isleaf = isleaf\n",
        "\n",
        "    def __str__(self):\n",
        "\n",
        "        returnStr = 'keys:['\n",
        "        for i in range(self.n):\n",
        "            returnStr += str(self.keys[i]) + ' '\n",
        "        returnStr += '];childrens:['\n",
        "        for child in self.children:\n",
        "            returnStr += str(child) + ';'\n",
        "        returnStr += ']\\r\\n'\n",
        "        return returnStr\n",
        "\n",
        "    def diskread(self):\n",
        "        '''\n",
        "        磁盘读\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def diskwrite(self):\n",
        "        '''\n",
        "        磁盘写\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def allocate_node(self, key_max):\n",
        "        '''\n",
        "        在O(1)时间内为一个新结点分配一个磁盘页\n",
        "\n",
        "        假定由ALLOCATE-NODE所创建的结点无需做DISK-READ，因为磁盘上还没有关于该结点的有用信息\n",
        "\n",
        "        Return\n",
        "        ===\n",
        "        `btreenode` : 分配的B树结点\n",
        "\n",
        "        Example\n",
        "        ===\n",
        "        ```python\n",
        "        btreenode = BTreeNode.allocate_node()\n",
        "        ```\n",
        "        '''\n",
        "        node = BTreeNode()\n",
        "        child_max = key_max + 1\n",
        "        for i in range(key_max):\n",
        "            node.keys.append(None)\n",
        "        for i in range(child_max):\n",
        "            node.children.append(None)\n",
        "        return node\n",
        "\n",
        "class BTree:\n",
        "    '''\n",
        "    B树\n",
        "    '''\n",
        "    def __init__(self, m = 3):\n",
        "        '''\n",
        "        B树的定义\n",
        "        '''\n",
        "        # B树的最小度数\n",
        "        self.M = m\n",
        "        # 节点包含关键字的最大个数\n",
        "        self.KEY_MAX = 2 * self.M - 1\n",
        "        # 非根结点包含关键字的最小个数\n",
        "        self.KEY_MIN = self.M - 1\n",
        "        # 子结点的最大个数\n",
        "        self.CHILD_MAX = self.KEY_MAX + 1\n",
        "        # 子结点的最小个数\n",
        "        self.CHILD_MIN = self.KEY_MIN + 1\n",
        "        # 根结点\n",
        "        self.root: BTreeNode = None\n",
        "\n",
        "    def __new_node(self):\n",
        "        '''\n",
        "        创建新的B树结点\n",
        "        '''\n",
        "        return BTreeNode.allocate_node(self.KEY_MAX)\n",
        "\n",
        "    def insert(self, key):\n",
        "        '''\n",
        "        向B树中插入新结点`key`  \n",
        "        '''\n",
        "        # 检查关键字是否存在\n",
        "        if self.contain(key) == True:\n",
        "            return False\n",
        "        else:\n",
        "            # 检查是否为空树\n",
        "            if self.root is None:\n",
        "                node = self.__new_node()\n",
        "                node.diskwrite()\n",
        "                self.root = node    \n",
        "            # 检查根结点是否已满      \n",
        "            if self.root.n == self.KEY_MAX:\n",
        "                # 创建新的根结点\n",
        "                pNode = self.__new_node()\n",
        "                pNode.isleaf = False\n",
        "                pNode.children[0] = self.root\n",
        "                self.__split_child(pNode, 0, self.root)\n",
        "                # 更新结点指针\n",
        "                self.root = pNode\n",
        "            self.__insert_non_full(self.root, key)\n",
        "            return True\n",
        "\n",
        "    def remove(self, key): \n",
        "        '''\n",
        "        从B中删除结点`key`\n",
        "        '''      \n",
        "        # 如果关键字不存在\n",
        "        if not self.search(self.root, key):\n",
        "            return False\n",
        "        # 特殊情况处理\n",
        "        if self.root.n == 1:\n",
        "            if self.root.isleaf == True:\n",
        "                self.clear()\n",
        "            else:\n",
        "                pChild1 = self.root.children[0]\n",
        "                pChild2 = self.root.children[1]\n",
        "                if pChild1.n == self.KEY_MIN and pChild2.n == self.KEY_MIN:\n",
        "                    self.__merge_child(self.root, 0)\n",
        "                    self.__delete_node(self.root)\n",
        "                    self.root = pChild1\n",
        "        self.__recursive_remove(self.root, key)\n",
        "        return True\n",
        "    \n",
        "    def display(self):\n",
        "        '''\n",
        "        打印树的关键字  \n",
        "        '''\n",
        "        self.__display_in_concavo(self.root, self.KEY_MAX * 10)\n",
        "\n",
        "    def contain(self, key):\n",
        "        '''\n",
        "        检查该`key`是否存在于B树中  \n",
        "        '''\n",
        "        self.__search(self.root, key)\n",
        "\n",
        "    def clear(self):\n",
        "        '''\n",
        "        清空B树  \n",
        "        '''\n",
        "        self.__recursive_clear(self.root)\n",
        "        self.root = None\n",
        "\n",
        "    def __recursive_clear(self, pNode : BTreeNode):\n",
        "        '''\n",
        "        删除树  \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            if not pNode.isleaf:\n",
        "                for i in range(pNode.n):\n",
        "                    self.__recursive_clear(pNode.children[i])\n",
        "            self.__delete_node(pNode)\n",
        "\n",
        "    def __delete_node(self, pNode : BTreeNode):\n",
        "        '''\n",
        "        删除节点 \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            pNode = None\n",
        "    \n",
        "    def __search(self, pNode : BTreeNode, key):\n",
        "        '''\n",
        "        查找关键字  \n",
        "        '''\n",
        "        # 检测结点是否为空，或者该结点是否为叶子节点\n",
        "        if pNode is None:\n",
        "            return False\n",
        "        else:\n",
        "            i = 0\n",
        "            # 找到使key < pNode.keys[i]成立的最小下标\n",
        "            while i < pNode.n and key > pNode.keys[i]:\n",
        "                i += 1\n",
        "            if i < pNode.n and key == pNode.keys[i]:\n",
        "                return True\n",
        "            else:\n",
        "                # 检查该结点是否为叶子节点\n",
        "                if pNode.isleaf == True:\n",
        "                    return False\n",
        "                else:\n",
        "                    return self.__search(pNode.children[i], key)\n",
        "\n",
        "    def __split_child(self, pParent : BTreeNode, nChildIndex, pChild : BTreeNode):\n",
        "        '''\n",
        "        分裂子节点\n",
        "        '''\n",
        "        # 将pChild分裂成pLeftChild和pChild两个结点\n",
        "        pRightNode = self.__new_node()  # 分裂后的右结点\n",
        "        pRightNode.isleaf = pChild.isleaf\n",
        "        pRightNode.n = self.KEY_MIN\n",
        "        # 拷贝关键字的值\n",
        "        for i in range(self.KEY_MIN):\n",
        "            pRightNode.keys[i] = pChild.keys[i + self.CHILD_MIN]\n",
        "        # 如果不是叶子结点，就拷贝孩子结点指针\n",
        "        if not pChild.isleaf:\n",
        "            for i in range(self.CHILD_MIN):\n",
        "                pRightNode.children[i] = pChild.children[i + self.CHILD_MIN]\n",
        "        # 更新左子树的关键字个数\n",
        "        pChild.n = self.KEY_MIN\n",
        "        # 将父结点中的pChildIndex后的所有关键字的值和子树指针向后移动一位\n",
        "        for i in range(nChildIndex, pParent.n):\n",
        "            j = pParent.n + nChildIndex - i\n",
        "            pParent.children[j + 1] = pParent.children[j]\n",
        "            pParent.keys[j] = pParent.keys[j - 1]\n",
        "        # 更新父结点的关键字个数\n",
        "        pParent.n += 1\n",
        "        # 存储右子树指针\n",
        "        pParent.children[nChildIndex + 1] = pRightNode\n",
        "        # 把结点的中间值提到父结点\n",
        "        pParent.keys[nChildIndex] = pChild.keys[self.KEY_MIN]\n",
        "        pChild.diskwrite()\n",
        "        pRightNode.diskwrite()\n",
        "        pParent.diskwrite()\n",
        "    \n",
        "    def __insert_non_full(self, pNode: BTreeNode, key):\n",
        "        '''\n",
        "        在非满节点中插入关键字\n",
        "        '''\n",
        "        # 获取结点内关键字个数\n",
        "        i = pNode.n\n",
        "        # 如果pNode是叶子结点\n",
        "        if pNode.isleaf == True:\n",
        "            # 从后往前 查找关键字的插入位置\n",
        "            while i > 0 and key < pNode.keys[i - 1]:\n",
        "                # 向后移位\n",
        "                pNode.keys[i] = pNode.keys[i - 1]\n",
        "                i -= 1\n",
        "            # 插入关键字的值\n",
        "            pNode.keys[i] = key\n",
        "            # 更新结点关键字的个数\n",
        "            pNode.n += 1\n",
        "            pNode.diskwrite()\n",
        "        # pnode是内结点\n",
        "        else:\n",
        "            # 从后往前 查找关键字的插入的子树\n",
        "            while i > 0 and key < pNode.keys[i - 1]:\n",
        "                i -= 1\n",
        "            # 目标子树结点指针\n",
        "            pChild = pNode.children[i]\n",
        "            pNode.children[i].diskread()\n",
        "            # 子树结点已经满了\n",
        "            if pChild.n == self.KEY_MAX:\n",
        "                # 分裂子树结点\n",
        "                self.__split_child(pNode, i, pChild)\n",
        "                # 确定目标子树\n",
        "                if key > pNode.keys[i]:\n",
        "                    pChild = pNode.children[i + 1]\n",
        "            # 插入关键字到目标子树结点\n",
        "            self.__insert_non_full(pChild, key)\n",
        "\n",
        "    def __display_in_concavo(self, pNode: BTreeNode, count):\n",
        "        '''\n",
        "        用括号打印树 \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            i = 0\n",
        "            j = 0\n",
        "            for i in range(pNode.n):\n",
        "                if not pNode.isleaf:\n",
        "                    self.__display_in_concavo(pNode.children[i], count - 2)\n",
        "                for j in range(-1, count):\n",
        "                    k = count - j - 1\n",
        "                    print('-', end='')\n",
        "                print(pNode.keys[i])\n",
        "            if not pNode.isleaf:\n",
        "                self.__display_in_concavo(pNode.children[i], count - 2)\n",
        "\n",
        "    def __merge_child(self, pParent: BTreeNode, index):\n",
        "        '''\n",
        "        合并两个子结点\n",
        "        '''\n",
        "        pChild1 = pParent.children[index]\n",
        "        pChild2 = pParent.children[index + 1]\n",
        "        # 将pChild2数据合并到pChild1\n",
        "        pChild1.n = self.KEY_MAX\n",
        "        # 将父结点index的值下移\n",
        "        pChild1.keys[self.KEY_MIN] = pParent.keys[index]\n",
        "        for i in range(self.KEY_MIN):\n",
        "            pChild1.keys[i + self.KEY_MIN + 1] = pChild2.keys[i]\n",
        "        if not pChild1.isleaf:\n",
        "            for i in range(self.CHILD_MIN):\n",
        "                pChild1.children[i + self.CHILD_MIN] = pChild2.children[i]\n",
        "        # 父结点删除index的key，index后的往前移一位\n",
        "        pParent.n -= 1\n",
        "        for i in range(index, pParent.n):\n",
        "            pParent.keys[i] = pParent.keys[i + 1]\n",
        "            pParent.children[i + 1] = pParent.children[i + 2]\n",
        "        # 删除pChild2\n",
        "        self.__delete_node(pChild2)\n",
        "\n",
        "    def __recursive_remove(self, pNode: BTreeNode, key):\n",
        "        '''\n",
        "        递归的删除关键字`key`  \n",
        "        '''\n",
        "        i = 0\n",
        "        while i < pNode.n and key > pNode.keys[i]:\n",
        "            i += 1\n",
        "        # 关键字key在结点pNode\n",
        "        if i < pNode.n and key == pNode.keys[i]:\n",
        "            # pNode是个叶结点\n",
        "            if pNode.isleaf == True:\n",
        "                # 从pNode中删除k\n",
        "                for j in range(i, pNode.n):\n",
        "                    pNode.keys[j] = pNode.keys[j + 1]\n",
        "                return\n",
        "            # pNode是个内结点\n",
        "            else:\n",
        "                # 结点pNode中前于key的子结点\n",
        "                pChildPrev = pNode.children[i]\n",
        "                # 结点pNode中后于key的子结点\n",
        "                pChildNext = pNode.children[i + 1]\n",
        "                if pChildPrev.n >= self.CHILD_MIN:\n",
        "                    # 获取key的前驱关键字\n",
        "                    prevKey = self.predecessor(pChildPrev)\n",
        "                    self.__recursive_remove(pChildPrev, prevKey)\n",
        "                    # 替换成key的前驱关键字\n",
        "                    pNode.keys[i] = prevKey\n",
        "                    return\n",
        "                # 结点pChildNext中至少包含CHILD_MIN个关键字\n",
        "                elif pChildNext.n >= self.CHILD_MIN:\n",
        "                    # 获取key的后继关键字\n",
        "                    nextKey = self.successor(pChildNext)\n",
        "                    self.__recursive_remove(pChildNext, nextKey)\n",
        "                    # 替换成key的后继关键字\n",
        "                    pNode.keys[i] = nextKey\n",
        "                    return\n",
        "                # 结点pChildPrev和pChildNext中都只包含CHILD_MIN-1个关键字\n",
        "                else:\n",
        "                    self.__merge_child(pNode, i)\n",
        "                    self.__recursive_remove(pChildPrev, key)\n",
        "        # 关键字key不在结点pNode中\n",
        "        else:\n",
        "            # 包含key的子树根结点\n",
        "            pChildNode = pNode.children[i]\n",
        "            # 只有t-1个关键字\n",
        "            if pChildNode.n == self.KEY_MAX:\n",
        "                # 左兄弟结点\n",
        "                pLeft = None\n",
        "                # 右兄弟结点\n",
        "                pRight = None\n",
        "                # 左兄弟结点\n",
        "                if i > 0:\n",
        "                    pLeft = pNode.children[i - 1]\n",
        "                # 右兄弟结点\n",
        "                if i < pNode.n:\n",
        "                    pRight = pNode.children[i + 1]\n",
        "                j = 0\n",
        "                if pLeft is not None and pLeft.n >= self.CHILD_MIN:\n",
        "                    # 父结点中i-1的关键字下移至pChildNode中\n",
        "                    for j in range(pChildNode.n):\n",
        "                        k = pChildNode.n - j\n",
        "                        pChildNode.keys[k] = pChildNode.keys[k - 1]\n",
        "                    pChildNode.keys[0] = pNode.keys[i - 1]\n",
        "                    if not pLeft.isleaf:\n",
        "                        # pLeft结点中合适的子女指针移到pChildNode中\n",
        "                        for j in range(pChildNode.n + 1):\n",
        "                            k = pChildNode.n + 1 - j\n",
        "                            pChildNode.children[k] = pChildNode.children[k - 1]\n",
        "                        pChildNode.children[0] = pLeft.children[pLeft.n]\n",
        "                    pChildNode.n += 1\n",
        "                    pNode.keys[i] = pLeft.keys[pLeft.n - 1]\n",
        "                    pLeft.n -= 1\n",
        "                # 右兄弟结点至少有CHILD_MIN个关键字\n",
        "                elif pRight is not None and pRight.n >= self.CHILD_MIN:\n",
        "                    # 父结点中i的关键字下移至pChildNode中\n",
        "                    pChildNode.keys[pChildNode.n] = pNode.keys[i]\n",
        "                    pChildNode.n += 1\n",
        "                    # pRight结点中的最小关键字上升到pNode中\n",
        "                    pNode.keys[i] = pRight.keys[0]\n",
        "                    pRight.n -= 1\n",
        "                    for j in range(pRight.n):\n",
        "                        pRight.keys[j] = pRight.keys[j + 1]\n",
        "                    if not pRight.isleaf:\n",
        "                        # pRight结点中合适的子女指针移动到pChildNode中\n",
        "                        pChildNode.children[pChildNode.n] = pRight.children[0]\n",
        "                        for j in range(pRight.n):\n",
        "                            pRight.children[j] = pRight.children[j + 1]\n",
        "                # 左右兄弟结点都只包含CHILD_MIN-1个结点\n",
        "                elif pLeft is not None:\n",
        "                    self.__merge_child(pNode, i - 1)\n",
        "                    pChildNode = pLeft\n",
        "                # 与右兄弟合并\n",
        "                elif pRight is not None:\n",
        "                    self.__merge_child(pNode, i)\n",
        "            self.__recursive_remove(pChildNode, key)\n",
        "\n",
        "    def predecessor(self, pNode: BTreeNode):\n",
        "        '''\n",
        "        前驱关键字\n",
        "        '''\n",
        "        while not pNode.isleaf:\n",
        "            pNode = pNode.children[pNode.n]\n",
        "        return pNode.keys[pNode.n - 1]\n",
        "\n",
        "    def successor(self, pNode: BTreeNode):\n",
        "        '''\n",
        "        后继关键字\n",
        "        '''\n",
        "        while not pNode.isleaf:\n",
        "            pNode = pNode.children[0]\n",
        "        return pNode.keys[0]\n",
        "\n",
        "def test():\n",
        "    '''\n",
        "    test class `BTree` and class `BTreeNode`\n",
        "    '''\n",
        "    tree = BTree(10)\n",
        "    \n",
        "    t1=time.time()\n",
        "    for i in range(0,len(trainkeys)):\n",
        "        tree.insert(trainkeys[i])\n",
        "    t2=time.time()\n",
        "    time_interval=t2-t1\n",
        "    print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "    ret1=time_interval*1000\n",
        "    t1=time.time()\n",
        "    # testpre=[]\n",
        "    for i in range(0,len(testkeys)):\n",
        "        tree.contain(testkeys[i])\n",
        "    t2=time.time()\n",
        "    time_interval=t2-t1\n",
        "    print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "    print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "    ret2=time_interval*1000\n",
        "    ret3=time_interval/len(testkeys)*1000\n",
        "    return (ret1,ret2,ret3)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    avg_a=0.0\n",
        "    avg_b=0.0\n",
        "    avg_c=0.0\n",
        "    counting=20\n",
        "    for i in range(0,20):\n",
        "        (a,b,c)=test()\n",
        "        avg_a+=a\n",
        "        avg_b+=b\n",
        "        avg_c+=c\n",
        "    avg_a=avg_a/counting\n",
        "    avg_b=avg_b/counting\n",
        "    avg_c=avg_c/counting\n",
        "    print(\"average times (ms):\",avg_a,avg_b,avg_c)\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:2.9621124267578125 ms\n",
            "time interval for indexing data :0.39005279541015625 ms\n",
            "average time interval for indexing data :0.0033337845761551815 ms\n",
            "time interval for building model:2.9451847076416016 ms\n",
            "time interval for indexing data :0.3731250762939453 ms\n",
            "average time interval for indexing data :0.003189103216187567 ms\n",
            "time interval for building model:2.9282569885253906 ms\n",
            "time interval for indexing data :0.3666877746582031 ms\n",
            "average time interval for indexing data :0.003134083544087206 ms\n",
            "time interval for building model:2.9573440551757812 ms\n",
            "time interval for indexing data :0.3724098205566406 ms\n",
            "average time interval for indexing data :0.003182989919287527 ms\n",
            "time interval for building model:2.953052520751953 ms\n",
            "time interval for indexing data :0.3695487976074219 ms\n",
            "average time interval for indexing data :0.003158536731687366 ms\n",
            "time interval for building model:2.9256343841552734 ms\n",
            "time interval for indexing data :0.3685951232910156 ms\n",
            "average time interval for indexing data :0.0031503856691539795 ms\n",
            "time interval for building model:2.9592514038085938 ms\n",
            "time interval for indexing data :0.3707408905029297 ms\n",
            "average time interval for indexing data :0.0031687255598541 ms\n",
            "time interval for building model:2.927541732788086 ms\n",
            "time interval for indexing data :0.3647804260253906 ms\n",
            "average time interval for indexing data :0.0031177814190204325 ms\n",
            "time interval for building model:2.928495407104492 ms\n",
            "time interval for indexing data :0.370025634765625 ms\n",
            "average time interval for indexing data :0.00316261226295406 ms\n",
            "time interval for building model:2.927064895629883 ms\n",
            "time interval for indexing data :0.3731250762939453 ms\n",
            "average time interval for indexing data :0.003189103216187567 ms\n",
            "time interval for building model:3.000497817993164 ms\n",
            "time interval for indexing data :0.3876686096191406 ms\n",
            "average time interval for indexing data :0.003313406919821715 ms\n",
            "time interval for building model:2.9489994049072266 ms\n",
            "time interval for indexing data :0.37598609924316406 ms\n",
            "average time interval for indexing data :0.003213556403787727 ms\n",
            "time interval for building model:2.9327869415283203 ms\n",
            "time interval for indexing data :0.3788471221923828 ms\n",
            "average time interval for indexing data :0.003238009591387887 ms\n",
            "time interval for building model:2.9039382934570312 ms\n",
            "time interval for indexing data :0.3762245178222656 ms\n",
            "average time interval for indexing data :0.0032155941694210735 ms\n",
            "time interval for building model:2.923727035522461 ms\n",
            "time interval for indexing data :0.3681182861328125 ms\n",
            "average time interval for indexing data :0.003146310137887286 ms\n",
            "time interval for building model:2.9125213623046875 ms\n",
            "time interval for indexing data :0.3676414489746094 ms\n",
            "average time interval for indexing data :0.003142234606620593 ms\n",
            "time interval for building model:2.9108524322509766 ms\n",
            "time interval for indexing data :0.37550926208496094 ms\n",
            "average time interval for indexing data :0.0032094808725210335 ms\n",
            "time interval for building model:2.908468246459961 ms\n",
            "time interval for indexing data :0.37097930908203125 ms\n",
            "average time interval for indexing data :0.003170763325487447 ms\n",
            "time interval for building model:2.926349639892578 ms\n",
            "time interval for indexing data :0.3762245178222656 ms\n",
            "average time interval for indexing data :0.0032155941694210735 ms\n",
            "time interval for building model:2.9103755950927734 ms\n",
            "time interval for indexing data :0.3650188446044922 ms\n",
            "average time interval for indexing data :0.0031198191846537795 ms\n",
            "average times (ms): 2.9346227645874023 0.3730654716491699 0.003188593774779231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWMUmsqICZJ3"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kel0Wb1PCdUY",
        "outputId": "70fa87d3-ef62-4c43-a9ab-9ae86abde80b"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error \n",
        "import math\n",
        "import time\n",
        "# print(\"Linear Regression Model\")\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(X_train,Y_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  # devpre=reg.predict(np.array(devkeys).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
        "  # for i in range(0,len(devpre)):\n",
        "  #     devpre[i]=abs(int(devpre[i]))\n",
        "  # mse_LR=mean_squared_error(devres,devpre)\n",
        "  # print(\"MSE dev: \",mse_LR)\n",
        "  t1=time.time()\n",
        "  testpre=reg.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  for i in range(0,len(testpre)):\n",
        "    testpre[i]=abs(int(testpre[i]))\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  # print(\"log MSE test: \",round(math.log(1+mean_squared_error(testres,testpre),2),3))\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_loc=testpre[i]\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "      finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "      finding_res=trainres[0]\n",
        "    else:\n",
        "      finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "    # i=begin\n",
        "    # while i<=end:\n",
        "    #   # print(i,end)\n",
        "    #   if finding_res==trainkeys[i]:\n",
        "    #     break\n",
        "    #   else:\n",
        "    #     i=i+1\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:1049.2267608642578 ms\n",
            "time interval for indexing data :36.37194633483887 ms\n",
            "average time interval for indexing data :0.0017730304345734069 ms\n",
            "time interval for error correction :205.9347629547119 ms\n",
            "average time interval for error correction :0.01003874246635039 ms\n",
            "time interval for building model:898.2834815979004 ms\n",
            "time interval for indexing data :33.67328643798828 ms\n",
            "average time interval for indexing data :0.00164147832884802 ms\n",
            "time interval for error correction :202.90517807006836 ms\n",
            "average time interval for error correction :0.009891058695040868 ms\n",
            "time interval for building model:922.3644733428955 ms\n",
            "time interval for indexing data :20.761489868164062 ms\n",
            "average time interval for indexing data :0.0010120644373678494 ms\n",
            "time interval for error correction :196.3937282562256 ms\n",
            "average time interval for error correction :0.00957364376797434 ms\n",
            "time interval for building model:894.1891193389893 ms\n",
            "time interval for indexing data :20.762205123901367 ms\n",
            "average time interval for indexing data :0.001012099304080207 ms\n",
            "time interval for error correction :210.76035499572754 ms\n",
            "average time interval for error correction :0.010273976552389954 ms\n",
            "time interval for building model:888.6833190917969 ms\n",
            "time interval for indexing data :20.500659942626953 ms\n",
            "average time interval for indexing data :0.0009993497095947624 ms\n",
            "time interval for error correction :212.63742446899414 ms\n",
            "average time interval for error correction :0.010365478427853863 ms\n",
            "time interval for building model:905.1017761230469 ms\n",
            "time interval for indexing data :33.95581245422363 ms\n",
            "average time interval for indexing data :0.001655250680229289 ms\n",
            "time interval for error correction :221.5561866760254 ms\n",
            "average time interval for error correction :0.010800243086478764 ms\n",
            "time interval for building model:904.2246341705322 ms\n",
            "time interval for indexing data :34.003257751464844 ms\n",
            "average time interval for indexing data :0.001657563505482346 ms\n",
            "time interval for error correction :208.55402946472168 ms\n",
            "average time interval for error correction :0.010166424367004078 ms\n",
            "time interval for building model:905.7719707489014 ms\n",
            "time interval for indexing data :20.380496978759766 ms\n",
            "average time interval for indexing data :0.0009934921019186783 ms\n",
            "time interval for error correction :203.74393463134766 ms\n",
            "average time interval for error correction :0.00993194572639893 ms\n",
            "time interval for building model:907.6650142669678 ms\n",
            "time interval for indexing data :20.443201065063477 ms\n",
            "average time interval for indexing data :0.0009965487503686983 ms\n",
            "time interval for error correction :209.10382270812988 ms\n",
            "average time interval for error correction :0.010193225246569654 ms\n",
            "time interval for building model:908.7815284729004 ms\n",
            "time interval for indexing data :20.730257034301758 ms\n",
            "average time interval for indexing data :0.0010105419242615657 ms\n",
            "time interval for error correction :204.1451930999756 ms\n",
            "average time interval for error correction :0.009951505952031568 ms\n",
            "time interval for building model:897.6342678070068 ms\n",
            "time interval for indexing data :20.327091217041016 ms\n",
            "average time interval for indexing data :0.0009908887207293075 ms\n",
            "time interval for error correction :203.6745548248291 ms\n",
            "average time interval for error correction :0.009928563655300239 ms\n",
            "time interval for building model:897.3357677459717 ms\n",
            "time interval for indexing data :23.528337478637695 ms\n",
            "average time interval for indexing data :0.0011469405030046648 ms\n",
            "time interval for error correction :231.06813430786133 ms\n",
            "average time interval for error correction :0.011263923871885606 ms\n",
            "time interval for building model:892.2426700592041 ms\n",
            "time interval for indexing data :20.262718200683594 ms\n",
            "average time interval for indexing data :0.0009877507166171197 ms\n",
            "time interval for error correction :216.98784828186035 ms\n",
            "average time interval for error correction :0.0105775493946505 ms\n",
            "time interval for building model:934.4465732574463 ms\n",
            "time interval for indexing data :20.77484130859375 ms\n",
            "average time interval for indexing data :0.0010127152826651922 ms\n",
            "time interval for error correction :203.75418663024902 ms\n",
            "average time interval for error correction :0.00993244548260939 ms\n",
            "time interval for building model:891.8521404266357 ms\n",
            "time interval for indexing data :20.929574966430664 ms\n",
            "average time interval for indexing data :0.0010202581147718956 ms\n",
            "time interval for error correction :212.27359771728516 ms\n",
            "average time interval for error correction :0.010347742893501275 ms\n",
            "time interval for building model:893.897533416748 ms\n",
            "time interval for indexing data :20.24102210998535 ms\n",
            "average time interval for indexing data :0.0009866930930089379 ms\n",
            "time interval for error correction :204.2689323425293 ms\n",
            "average time interval for error correction :0.00995753789326944 ms\n",
            "time interval for building model:897.2856998443604 ms\n",
            "time interval for indexing data :20.291566848754883 ms\n",
            "average time interval for indexing data :0.000989157007348878 ms\n",
            "time interval for error correction :203.6139965057373 ms\n",
            "average time interval for error correction :0.009925611606987291 ms\n",
            "time interval for building model:898.2627391815186 ms\n",
            "time interval for indexing data :20.391225814819336 ms\n",
            "average time interval for indexing data :0.0009940151026040429 ms\n",
            "time interval for error correction :199.64075088500977 ms\n",
            "average time interval for error correction :0.009731927019840585 ms\n",
            "time interval for building model:894.6406841278076 ms\n",
            "time interval for indexing data :20.228862762451172 ms\n",
            "average time interval for indexing data :0.000986100358898858 ms\n",
            "time interval for error correction :204.46372032165527 ms\n",
            "average time interval for error correction :0.009967033261268172 ms\n",
            "time interval for building model:876.7917156219482 ms\n",
            "time interval for indexing data :20.282745361328125 ms\n",
            "average time interval for indexing data :0.0009887269845631338 ms\n",
            "time interval for error correction :203.17745208740234 ms\n",
            "average time interval for error correction :0.009904331290211678 ms\n",
            "average times (ms): 907.9340934753418 23.44202995300293 0.0011427332530468428 207.93288946151733 0.010136145532880825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qRKIicBCoBf"
      },
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJGC6c6mCnxd",
        "outputId": "9241c1d9-4a0a-440a-bcfb-9db501973e4d"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error \n",
        "import math\n",
        "import time\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  reg = Ridge(alpha=1.0)\n",
        "  reg.fit(X_train,Y_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  # devpre=reg.predict(np.array(devkeys).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
        "  # for i in range(0,len(devpre)):\n",
        "  #     devpre[i]=abs(int(devpre[i]))\n",
        "  # mse_LR=mean_squared_error(devres,devpre)\n",
        "  # print(\"MSE dev: \",mse_LR)\n",
        "  t1=time.time()\n",
        "  testpre=reg.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  for i in range(0,len(testpre)):\n",
        "    testpre[i]=abs(int(testpre[i]))\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  # print(\"log MSE test: \",round(math.log(1+mean_squared_error(testres,testpre),2),3))\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_loc=testpre[i]\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "      finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "      finding_res=trainres[0]\n",
        "    else:\n",
        "      finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "    # i=begin\n",
        "    # while i<=end:\n",
        "    #   # print(i,end)\n",
        "    #   if finding_res==trainkeys[i]:\n",
        "    #     break\n",
        "    #   else:\n",
        "    #     i=i+1\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/count_error*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:182.4188232421875 ms\n",
            "time interval for indexing data :20.914077758789062 ms\n",
            "average time interval for indexing data :0.00101950266933748 ms\n",
            "time interval for error correction :206.11977577209473 ms\n",
            "average time interval for error correction :0.010047761322613568 ms\n",
            "time interval for building model:183.81714820861816 ms\n",
            "time interval for indexing data :25.65312385559082 ms\n",
            "average time interval for indexing data :0.0012505178831817695 ms\n",
            "time interval for error correction :239.50910568237305 ms\n",
            "average time interval for error correction :0.011675397566655603 ms\n",
            "time interval for building model:185.95552444458008 ms\n",
            "time interval for indexing data :27.712345123291016 ms\n",
            "average time interval for indexing data :0.0013508991480594235 ms\n",
            "time interval for error correction :202.65722274780273 ms\n",
            "average time interval for error correction :0.009878971568090218 ms\n",
            "time interval for building model:183.91036987304688 ms\n",
            "time interval for indexing data :22.320270538330078 ms\n",
            "average time interval for indexing data :0.001088050625832606 ms\n",
            "time interval for error correction :213.3653163909912 ms\n",
            "average time interval for error correction :0.01040096111879649 ms\n",
            "time interval for building model:189.19801712036133 ms\n",
            "time interval for indexing data :29.819965362548828 ms\n",
            "average time interval for indexing data :0.0014536397271399449 ms\n",
            "time interval for error correction :192.5508975982666 ms\n",
            "average time interval for error correction :0.009386316544714175 ms\n",
            "time interval for building model:200.29854774475098 ms\n",
            "time interval for indexing data :20.688295364379883 ms\n",
            "average time interval for indexing data :0.0010084964104699172 ms\n",
            "time interval for error correction :211.67755126953125 ms\n",
            "average time interval for error correction :0.010318687299869905 ms\n",
            "time interval for building model:190.52886962890625 ms\n",
            "time interval for indexing data :40.07720947265625 ms\n",
            "average time interval for indexing data :0.0019536516268234497 ms\n",
            "time interval for error correction :194.2605972290039 ms\n",
            "average time interval for error correction :0.009469659609486395 ms\n",
            "time interval for building model:188.5385513305664 ms\n",
            "time interval for indexing data :20.930051803588867 ms\n",
            "average time interval for indexing data :0.0010202813592468008 ms\n",
            "time interval for error correction :222.23353385925293 ms\n",
            "average time interval for error correction :0.010833261863081454 ms\n",
            "time interval for building model:184.34453010559082 ms\n",
            "time interval for indexing data :34.84654426574707 ms\n",
            "average time interval for indexing data :0.0016986713593520068 ms\n",
            "time interval for error correction :197.30806350708008 ms\n",
            "average time interval for error correction :0.009618215048604859 ms\n",
            "time interval for building model:195.19901275634766 ms\n",
            "time interval for indexing data :20.48492431640625 ms\n",
            "average time interval for indexing data :0.0009985826419228942 ms\n",
            "time interval for error correction :207.1983814239502 ms\n",
            "average time interval for error correction :0.010100340324848894 ms\n",
            "time interval for building model:190.85335731506348 ms\n",
            "time interval for indexing data :27.78005599975586 ms\n",
            "average time interval for indexing data :0.001354199863495947 ms\n",
            "time interval for error correction :194.488525390625 ms\n",
            "average time interval for error correction :0.00948077046849103 ms\n",
            "time interval for building model:193.30096244812012 ms\n",
            "time interval for indexing data :20.583629608154297 ms\n",
            "average time interval for indexing data :0.0010033942482282488 ms\n",
            "time interval for error correction :205.71136474609375 ms\n",
            "average time interval for error correction :0.010027852429857353 ms\n",
            "time interval for building model:196.4881420135498 ms\n",
            "time interval for indexing data :32.3023796081543 ms\n",
            "average time interval for indexing data :0.001574650463495871 ms\n",
            "time interval for error correction :213.0146026611328 ms\n",
            "average time interval for error correction :0.010383864807503794 ms\n",
            "time interval for building model:188.39621543884277 ms\n",
            "time interval for indexing data :22.028446197509766 ms\n",
            "average time interval for indexing data :0.0010738250071906875 ms\n",
            "time interval for error correction :198.74143600463867 ms\n",
            "average time interval for error correction :0.009688087940169576 ms\n",
            "time interval for building model:193.4986114501953 ms\n",
            "time interval for indexing data :20.534753799438477 ms\n",
            "average time interval for indexing data :0.0010010116895504766 ms\n",
            "time interval for error correction :214.14518356323242 ms\n",
            "average time interval for error correction :0.010438977457503773 ms\n",
            "time interval for building model:180.7537078857422 ms\n",
            "time interval for indexing data :20.53976058959961 ms\n",
            "average time interval for indexing data :0.00100125575653698 ms\n",
            "time interval for error correction :194.88763809204102 ms\n",
            "average time interval for error correction :0.009500226093986595 ms\n",
            "time interval for building model:190.3095245361328 ms\n",
            "time interval for indexing data :20.433902740478516 ms\n",
            "average time interval for indexing data :0.0009960954831080488 ms\n",
            "time interval for error correction :199.75972175598145 ms\n",
            "average time interval for error correction :0.009737726516329407 ms\n",
            "time interval for building model:196.4728832244873 ms\n",
            "time interval for indexing data :32.90700912475586 ms\n",
            "average time interval for indexing data :0.0016041244576755318 ms\n",
            "time interval for error correction :200.87885856628418 ms\n",
            "average time interval for error correction :0.009792281298931666 ms\n",
            "time interval for building model:189.59879875183105 ms\n",
            "time interval for indexing data :27.544498443603516 ms\n",
            "average time interval for indexing data :0.0013427170928928301 ms\n",
            "time interval for error correction :201.68542861938477 ms\n",
            "average time interval for error correction :0.009831599328233635 ms\n",
            "time interval for building model:186.10215187072754 ms\n",
            "time interval for indexing data :32.76705741882324 ms\n",
            "average time interval for indexing data :0.0015973022042908862 ms\n",
            "time interval for error correction :199.63812828063965 ms\n",
            "average time interval for error correction :0.009731799175228607 ms\n",
            "average times (ms): 189.49918746948242 26.043415069580078 0.0012695434858915895 205.49156665802002 0.01001713788914985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MAGOIjhB_iT"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "w7TfihqYBBqm",
        "outputId": "c767b028-0563-477c-eba5-960fbf546f29"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  NB = GaussianNB()\n",
        "  NB.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=NB.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=NB.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:249.15695190429688 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-ae12a006f07d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mcounting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0mavg_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0mavg_b\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-ae12a006f07d>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mret1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_interval\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mtestpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mtime_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mjointi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_prior_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0mn_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) /\n\u001b[0m\u001b[1;32m    452\u001b[0m                                  (self.sigma_[i, :]), 1)\n\u001b[1;32m    453\u001b[0m             \u001b[0mjoint_log_likelihood\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjointi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_ij\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btfk3Zm8C3bs"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "u8desQlyC65A",
        "outputId": "dc73e5e8-1ff6-4a91-b42e-e56f520847ee"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  neigh = KNeighborsClassifier(n_neighbors=9)\n",
        "  neigh.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=neigh.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=neigh.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  # print(testpre)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:120.47624588012695 ms\n",
            "time interval for indexing data :2661.1578464508057 ms\n",
            "average time interval for indexing data :1.914502047806335 ms\n",
            "time interval for error correction :8.164405822753906 ms\n",
            "average time interval for error correction :0.005882136759909154 ms\n",
            "time interval for building model:124.75013732910156 ms\n",
            "time interval for indexing data :2641.106605529785 ms\n",
            "average time interval for indexing data :1.9000766946257446 ms\n",
            "time interval for error correction :7.997274398803711 ms\n",
            "average time interval for error correction :0.00576172507118423 ms\n",
            "time interval for building model:117.65050888061523 ms\n",
            "time interval for indexing data :2642.423391342163 ms\n",
            "average time interval for indexing data :1.9010240225483188 ms\n",
            "time interval for error correction :7.230043411254883 ms\n",
            "average time interval for error correction :0.005208964993699483 ms\n",
            "time interval for building model:118.5910701751709 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-0d27f6618cd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mcounting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m   \u001b[0mavg_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   \u001b[0mavg_b\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-0d27f6618cd8>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mret1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_interval\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mtestpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0;31m# print(testpre)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    662\u001b[0m                 delayed_query(\n\u001b[1;32m    663\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             )\n\u001b[1;32m    666\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[0;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQI1WADWDHj2"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "UEwRGFYyDJTI",
        "outputId": "0dd45d4f-01f2-46b1-ea2e-582d2ed7579d"
      },
      "source": [
        "from sklearn import tree\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  dtree = tree.DecisionTreeClassifier(max_depth=3)\n",
        "  dtree.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=tree.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=dtree.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:1429.3057918548584 ms\n",
            "time interval for indexing data :0.9002685546875 ms\n",
            "average time interval for indexing data :0.0006476752191996403 ms\n",
            "time interval for error correction :6.561517715454102 ms\n",
            "average time interval for error correction :0.004727318238799785 ms\n",
            "time interval for building model:1445.88303565979 ms\n",
            "time interval for indexing data :0.9086132049560547 ms\n",
            "average time interval for indexing data :0.0006536785647165861 ms\n",
            "time interval for error correction :6.637334823608398 ms\n",
            "average time interval for error correction :0.004781941515568011 ms\n",
            "time interval for building model:1433.3953857421875 ms\n",
            "time interval for indexing data :0.8835792541503906 ms\n",
            "average time interval for indexing data :0.0006356685281657487 ms\n",
            "time interval for error correction :6.5517425537109375 ms\n",
            "average time interval for error correction :0.004720275615065517 ms\n",
            "time interval for building model:1433.8998794555664 ms\n",
            "time interval for indexing data :1.5680789947509766 ms\n",
            "average time interval for indexing data :0.0011281143847129327 ms\n",
            "time interval for error correction :6.677150726318359 ms\n",
            "average time interval for error correction :0.004810627324436859 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6885061e282b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mcounting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0mavg_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0mavg_b\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-6885061e282b>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mt1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mtime_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGZRAXh03Qdb"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5ebAmbQ3dYa",
        "outputId": "519d5da4-2c89-45f7-d8aa-13816d6f8803"
      },
      "source": [
        "import numpy as np\n",
        "temp=Z_train.reshape(1,-1)\n",
        "T_train=np.zeros((temp.size, temp.max()+1))\n",
        "T_train[np.arange(temp.size),temp] = 1\n",
        "print(T_train)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkrBRYoa4PDN",
        "outputId": "aac41141-65fc-4154-9e36-41870eb74576"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(61543, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yjP1SdTi3Swx",
        "outputId": "abe2bd3c-cdb4-4773-9a99-714e2dc15ce6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api\n",
        "from keras import models as md\n",
        "from keras import layers as lr\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  model = md.Sequential()\n",
        "  model.add(lr.Dense(300,activation=\"relu\"))\n",
        "  # model.add(lr.Dense(4,activation=\"relu\"))\n",
        "  model.add(lr.Dense(128,activation=\"relu\"))\n",
        "  # model.add(lr.Dropout(0.2))\n",
        "  model.add(lr.Dense(temp.max()+1,activation=\"softmax\"))\n",
        "  model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])#compile the model\n",
        "  model.fit(X_train, T_train, epochs=16, batch_size=32)#fit the model\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=tree.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=model.predict(X_test)#.reshape(1,-1).tolist()[0]\n",
        "  testpre=np.argmax(testpre,axis=1)\n",
        "  # print(testpre)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  # return\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 6.0286 - accuracy: 0.0079\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2160 - accuracy: 0.0278\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.9814 - accuracy: 0.0373\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8317 - accuracy: 0.0452\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7228 - accuracy: 0.0539\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6325 - accuracy: 0.0606\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5562 - accuracy: 0.0683\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4836 - accuracy: 0.0754\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4277 - accuracy: 0.0826\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3775 - accuracy: 0.0888\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3023 - accuracy: 0.0971\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2500 - accuracy: 0.1039\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1987 - accuracy: 0.1107\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1470 - accuracy: 0.1144\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1141 - accuracy: 0.1221\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.0713 - accuracy: 0.1244\n",
            "time interval for building model:96929.91304397583 ms\n",
            "time interval for indexing data :829.397439956665 ms\n",
            "average time interval for indexing data :0.040430800426862874 ms\n",
            "time interval for error correction :387.59303092956543 ms\n",
            "average time interval for error correction :0.018916204535361903 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 6.0874 - accuracy: 0.0069\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2788 - accuracy: 0.0239\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.0293 - accuracy: 0.0346\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8682 - accuracy: 0.0434\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7734 - accuracy: 0.0502\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6756 - accuracy: 0.0589\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6112 - accuracy: 0.0625\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5268 - accuracy: 0.0702\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4636 - accuracy: 0.0788\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4292 - accuracy: 0.0821\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3563 - accuracy: 0.0871\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3179 - accuracy: 0.0936\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2621 - accuracy: 0.0982\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2225 - accuracy: 0.1037\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1811 - accuracy: 0.1089\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1398 - accuracy: 0.1164\n",
            "time interval for building model:96932.57331848145 ms\n",
            "time interval for indexing data :793.6861515045166 ms\n",
            "average time interval for indexing data :0.03868997521227048 ms\n",
            "time interval for error correction :378.3304691314697 ms\n",
            "average time interval for error correction :0.01846595417471055 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 7s 3ms/step - loss: 6.0572 - accuracy: 0.0071\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2310 - accuracy: 0.0256\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.0013 - accuracy: 0.0368\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8495 - accuracy: 0.0452\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7374 - accuracy: 0.0548\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6378 - accuracy: 0.0577\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5759 - accuracy: 0.0664\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5008 - accuracy: 0.0741\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4418 - accuracy: 0.0807\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3720 - accuracy: 0.0897\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3160 - accuracy: 0.0948\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2628 - accuracy: 0.0994\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2057 - accuracy: 0.1065\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1491 - accuracy: 0.1131\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1127 - accuracy: 0.1220\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.0756 - accuracy: 0.1246\n",
            "time interval for building model:96997.92385101318 ms\n",
            "time interval for indexing data :661.5126132965088 ms\n",
            "average time interval for indexing data :0.03224688570227693 ms\n",
            "time interval for error correction :386.1861228942871 ms\n",
            "average time interval for error correction :0.0188484612667425 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 6.0625 - accuracy: 0.0075\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2507 - accuracy: 0.0256\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.0018 - accuracy: 0.0371\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8635 - accuracy: 0.0437\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7387 - accuracy: 0.0530\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6438 - accuracy: 0.0589\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5624 - accuracy: 0.0667\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5047 - accuracy: 0.0734\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4304 - accuracy: 0.0816\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3762 - accuracy: 0.0857\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3182 - accuracy: 0.0935\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2634 - accuracy: 0.1030\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2257 - accuracy: 0.1039\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1646 - accuracy: 0.1139\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1201 - accuracy: 0.1160\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.0785 - accuracy: 0.1241\n",
            "time interval for building model:97317.50869750977 ms\n",
            "time interval for indexing data :668.7302589416504 ms\n",
            "average time interval for indexing data :0.0325987256966779 ms\n",
            "time interval for error correction :397.8865146636963 ms\n",
            "average time interval for error correction :0.019420466354143708 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 7s 3ms/step - loss: 6.0807 - accuracy: 0.0070\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.3052 - accuracy: 0.0224\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.0516 - accuracy: 0.0316\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8885 - accuracy: 0.0404\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7899 - accuracy: 0.0499\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7018 - accuracy: 0.0548\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6379 - accuracy: 0.0616\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5696 - accuracy: 0.0666\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5034 - accuracy: 0.0741\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4553 - accuracy: 0.0776\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3987 - accuracy: 0.0852\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3554 - accuracy: 0.0890\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3153 - accuracy: 0.0951\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2608 - accuracy: 0.1002\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2221 - accuracy: 0.1035\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1771 - accuracy: 0.1122\n",
            "time interval for building model:98236.64879798889 ms\n",
            "time interval for indexing data :662.7018451690674 ms\n",
            "average time interval for indexing data :0.03230485742269023 ms\n",
            "time interval for error correction :370.9113597869873 ms\n",
            "average time interval for error correction :0.01810206733953086 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 7s 3ms/step - loss: 6.0323 - accuracy: 0.0070\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2449 - accuracy: 0.0257\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.0144 - accuracy: 0.0352\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8559 - accuracy: 0.0444\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7461 - accuracy: 0.0516\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6565 - accuracy: 0.0578\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5707 - accuracy: 0.0689\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5110 - accuracy: 0.0721\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4496 - accuracy: 0.0808\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3851 - accuracy: 0.0879\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3366 - accuracy: 0.0934\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2775 - accuracy: 0.0982\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2222 - accuracy: 0.1042\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1847 - accuracy: 0.1096\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1367 - accuracy: 0.1174\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.0675 - accuracy: 0.1272\n",
            "time interval for building model:98548.88606071472 ms\n",
            "time interval for indexing data :669.2264080047607 ms\n",
            "average time interval for indexing data :0.032622911572816646 ms\n",
            "time interval for error correction :377.72393226623535 ms\n",
            "average time interval for error correction :0.01844085008378828 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 6.0558 - accuracy: 0.0072\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2619 - accuracy: 0.0252\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.0011 - accuracy: 0.0380\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8498 - accuracy: 0.0444\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7269 - accuracy: 0.0527\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6416 - accuracy: 0.0593\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5707 - accuracy: 0.0669\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4937 - accuracy: 0.0741\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4369 - accuracy: 0.0792\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3720 - accuracy: 0.0898\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3029 - accuracy: 0.0936\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2604 - accuracy: 0.1008\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2081 - accuracy: 0.1095\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1626 - accuracy: 0.1106\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1122 - accuracy: 0.1198\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.0758 - accuracy: 0.1251\n",
            "time interval for building model:98975.741147995 ms\n",
            "time interval for indexing data :682.7046871185303 ms\n",
            "average time interval for indexing data :0.03327993990048407 ms\n",
            "time interval for error correction :370.6991672515869 ms\n",
            "average time interval for error correction :0.01809347751130354 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 7s 3ms/step - loss: 6.0524 - accuracy: 0.0077\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2571 - accuracy: 0.0249\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.9901 - accuracy: 0.0364\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8548 - accuracy: 0.0443\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7408 - accuracy: 0.0531\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6615 - accuracy: 0.0557\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5894 - accuracy: 0.0661\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5160 - accuracy: 0.0751\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4485 - accuracy: 0.0782\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3899 - accuracy: 0.0881\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3325 - accuracy: 0.0918\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2870 - accuracy: 0.0961\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2386 - accuracy: 0.1030\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1962 - accuracy: 0.1091\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1362 - accuracy: 0.1179\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1020 - accuracy: 0.1205\n",
            "time interval for building model:99771.8141078949 ms\n",
            "time interval for indexing data :688.3296966552734 ms\n",
            "average time interval for indexing data :0.03355414334870203 ms\n",
            "time interval for error correction :381.21962547302246 ms\n",
            "average time interval for error correction :0.018607879410017205 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 7s 3ms/step - loss: 6.0703 - accuracy: 0.0069\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2563 - accuracy: 0.0236\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.0048 - accuracy: 0.0354\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8482 - accuracy: 0.0451\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7557 - accuracy: 0.0539\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6595 - accuracy: 0.0614\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5780 - accuracy: 0.0668\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5194 - accuracy: 0.0733\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4514 - accuracy: 0.0785\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3938 - accuracy: 0.0872\n",
            "Epoch 11/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3575 - accuracy: 0.0894\n",
            "Epoch 12/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3008 - accuracy: 0.0959\n",
            "Epoch 13/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2651 - accuracy: 0.0987\n",
            "Epoch 14/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.2109 - accuracy: 0.1077\n",
            "Epoch 15/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1604 - accuracy: 0.1126\n",
            "Epoch 16/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.1292 - accuracy: 0.1198\n",
            "time interval for building model:100230.15880584717 ms\n",
            "time interval for indexing data :689.8446083068848 ms\n",
            "average time interval for indexing data :0.033627991045475515 ms\n",
            "time interval for error correction :388.0894184112549 ms\n",
            "average time interval for error correction :0.018937657659261937 ms\n",
            "Epoch 1/16\n",
            "1924/1924 [==============================] - 7s 3ms/step - loss: 6.0533 - accuracy: 0.0079\n",
            "Epoch 2/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 5.2336 - accuracy: 0.0264\n",
            "Epoch 3/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.9873 - accuracy: 0.0353\n",
            "Epoch 4/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.8371 - accuracy: 0.0458\n",
            "Epoch 5/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.7231 - accuracy: 0.0562\n",
            "Epoch 6/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.6367 - accuracy: 0.0593\n",
            "Epoch 7/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.5579 - accuracy: 0.0671\n",
            "Epoch 8/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4983 - accuracy: 0.0747\n",
            "Epoch 9/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.4221 - accuracy: 0.0815\n",
            "Epoch 10/16\n",
            "1924/1924 [==============================] - 6s 3ms/step - loss: 4.3656 - accuracy: 0.0901\n",
            "Epoch 11/16\n",
            " 954/1924 [=============>................] - ETA: 3s - loss: 4.2781 - accuracy: 0.0948"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-6d8acea6ce9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mcounting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0mavg_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mavg_b\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-6d8acea6ce9f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mtime_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}