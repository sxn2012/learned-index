{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learned_index_1dint.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubpop74Vjadu"
      },
      "source": [
        "# Read dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELdWbUaFmDx3"
      },
      "source": [
        "## read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZWrg7fzjWHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be726b6-0942-4421-f341-83b5b0464bbe"
      },
      "source": [
        "import codecs\n",
        "import os\n",
        "minkey=1000\n",
        "maxkey=9999\n",
        "keynum=3000\n",
        "current_path=os.path.abspath(os.curdir)\n",
        "f=codecs.open(os.path.join(current_path,\"data.csv\"), \"r\", \"utf-8\")\n",
        "strlist=f.read().split(\"\\n\")\n",
        "f.close()\n",
        "trainkeys=[]\n",
        "trainres=[]\n",
        "for ele in strlist:\n",
        "    temp=ele.split(\",\")\n",
        "    if len(temp)!=2:\n",
        "        continue\n",
        "    trainkeys.append(float(temp[0]))\n",
        "    trainres.append(int(temp[1]))\n",
        "# f=codecs.open(os.path.join(current_path,\"data_dev.csv\"), \"r\", \"utf-8\")\n",
        "# strlist=f.read().split(\"\\n\")\n",
        "# f.close()\n",
        "# devkeys=[]\n",
        "# devres=[]\n",
        "# for ele in strlist:\n",
        "#     temp=ele.split(\",\")\n",
        "#     if len(temp)!=2:\n",
        "#         continue\n",
        "#     devkeys.append(int(temp[0]))\n",
        "#     devres.append(int(temp[1]))\n",
        "f=codecs.open(os.path.join(current_path,\"data_test.csv\"), \"r\", \"utf-8\")\n",
        "strlist=f.read().split(\"\\n\")\n",
        "f.close()\n",
        "testkeys=[]\n",
        "testres=[]\n",
        "for ele in strlist:\n",
        "    temp=ele.split(\",\")\n",
        "    if len(temp)!=2:\n",
        "        continue\n",
        "    testkeys.append(float(temp[0]))\n",
        "    testres.append(int(temp[1]))\n",
        "\n",
        "# It is very time and space consuming to build models based on the entire dataset\n",
        "# Instead, we divide the dataset into 3 parts (training, dev, testing)\n",
        "# We build and train models based on training set, and give index predictions based on testing set\n",
        "\n",
        "# trainkeys.extend(devkeys)\n",
        "# trainres.extend(devres)\n",
        "# trainkeys.extend(testkeys)\n",
        "# trainres.extend(testres)\n",
        "\n",
        "print(\"training data size:\",len(trainkeys))\n",
        "# print(\"development data size:\",len(devkeys))\n",
        "print(\"testing data size:\",len(testkeys))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data size: 90\n",
            "testing data size: 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaNTDcG8jiI1"
      },
      "source": [
        "# Build Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5GYgSre2dFn"
      },
      "source": [
        "trainpages=[]\n",
        "for ele in trainres:\n",
        "  trainpages.append(int(ele)//100)\n",
        "testpages=[]\n",
        "for ele in testres:\n",
        "  testpages.append(int(ele)//100)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVoIVHv3xeUN"
      },
      "source": [
        "import numpy as np\n",
        "X_train=np.array(trainkeys).reshape(-1,1)\n",
        "Y_train=np.array(trainres).reshape(-1,1)\n",
        "Z_train=np.array(trainpages).reshape(-1,1)\n",
        "X_test=np.array(testkeys).reshape(-1,1)\n",
        "Y_test=np.array(testres).reshape(-1,1)\n",
        "Z_test=np.array(testpages).reshape(-1,1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl4S7HF12Fvh"
      },
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od-MTZcV9Mig"
      },
      "source": [
        "## B-Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSdw2YV99POa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "433f35d6-3e5f-453d-96db-ac085ccfb285"
      },
      "source": [
        "# #This is a B-Tree model\n",
        "# #reference: https://www.jianshu.com/p/c625a009e488\n",
        "# from random import shuffle\n",
        "# import random\n",
        "# import os\n",
        "# import codecs\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import mean_squared_error \n",
        "# mse_BTree=0.0\n",
        "# root_node = None\n",
        "# # trainkeys=[]\n",
        "# # trainres=[]\n",
        "# # devkeys=[]\n",
        "# # devres=[]\n",
        "# # testkeys=[]\n",
        "# # testres=[]\n",
        "# class Logger(object):\n",
        "#     @classmethod\n",
        "#     def tree(cls, node, child_name, dsc, depth):\n",
        "#         if depth == 0:\n",
        "#             head = \"|   \" * depth\n",
        "#             print(head + \"+--\" + dsc(node))\n",
        "#             depth = depth + 1\n",
        "#         for child in getattr(node, child_name):\n",
        "#             head = \"|   \" * depth\n",
        "#             print(head + \"+--\" + dsc(child))\n",
        "#             cls.tree(child, child_name, dsc, depth + 1)\n",
        "# class BKeyword(object):\n",
        "#     def __init__(self, key, loc):\n",
        "#         self.key = key\n",
        "#         self.loc = loc\n",
        "# class BNode(object):\n",
        "#     def __init__(self,M):\n",
        "#         self._parent: BNode = None\n",
        "#         self.keywords = []\n",
        "#         self.child_nodes = []\n",
        "#         self.M=M\n",
        "#     # set parent node\n",
        "#     def set_parent(self, node):\n",
        "#         self._parent = node\n",
        "#         if node.get_parent() is None:\n",
        "#             global root_node\n",
        "#             root_node = node.get_parent()\n",
        "#     # get parent node\n",
        "#     def get_parent(self):\n",
        "#         return self._parent\n",
        "#     # add child node to right location\n",
        "#     def insert_child_node(self, index, add_node):\n",
        "#         add_node.set_parent(self)\n",
        "#         self.child_nodes.insert(index, add_node)\n",
        "#     # add child node\n",
        "#     def append_child_node(self, add_node):\n",
        "#         add_node.set_parent(self)\n",
        "#         self.child_nodes.append(add_node)\n",
        "#     # find right insertion location\n",
        "#     def find_add_index(self, add_word):\n",
        "#         if len(self.keywords) == 0:\n",
        "#             return 0\n",
        "#         index = 0\n",
        "#         while True:\n",
        "#             if index >= len(self.keywords):\n",
        "#                 break\n",
        "#             key = self.keywords[index].key\n",
        "#             if add_word.key < key:\n",
        "#                 break\n",
        "#             index = index + 1\n",
        "#         return index\n",
        "# \t#find the location of given keyword\n",
        "#     def find_loc(self,word):\n",
        "#         if len(self.keywords) == 0:\n",
        "#             return -1\n",
        "#         index = 0\n",
        "#         key=-1\n",
        "#         while True:\n",
        "#             if index >= len(self.keywords):\n",
        "#                 break\n",
        "#             key = self.keywords[index].key\n",
        "#             if word < key:\n",
        "#                 break\n",
        "#             index = index + 1\n",
        "#         if index==0:\n",
        "#             index=1\n",
        "#         index=index-1\n",
        "#         #print(index)\n",
        "#         if index+1>=len(self.keywords):\n",
        "#             return int(self.keywords[index].loc)\n",
        "#         if self.keywords[index].key==word or abs(int(word)-int(self.keywords[index].key))<abs(int(word)-int(self.keywords[index+1].key)):\n",
        "#             return int(self.keywords[index].loc)\n",
        "#         else:\n",
        "#             return int(self.keywords[index+1].loc)\n",
        "#     # insert data to right location (regardless of M)\n",
        "#     def blind_add(self, word: BKeyword) -> int:\n",
        "#         index = self.find_add_index(word)\n",
        "#         self.keywords.insert(index, word)\n",
        "#     def split(self):\n",
        "#         # split node\n",
        "#         parent, center_keyword, left_node, right_node = self.split_to_piece()\n",
        "#         # add two new nodes as parent, build relationship\n",
        "#         parent_add_index = parent.find_add_index(center_keyword)\n",
        "#         parent.insert_child_node(parent_add_index, right_node)\n",
        "#         parent.insert_child_node(parent_add_index, left_node)\n",
        "#         # remove itself\n",
        "#         if self in parent.child_nodes:\n",
        "#             parent.child_nodes.remove(self)\n",
        "#         parent.add_word(center_keyword, force=True)\n",
        "#         # redefine root\n",
        "#         root = self\n",
        "#         while root.get_parent() is not None:\n",
        "#             root = root.get_parent()\n",
        "#         global root_node\n",
        "#         root_node = root\n",
        "#     def split_to_piece(self):\n",
        "#         center_keyword = self.keywords[int((self.M-1)/2)]\n",
        "#         if self.get_parent() is None:\n",
        "#             self.set_parent(BNode(self.M))\n",
        "#         left_node = BNode(self.M)\n",
        "#         right_node = BNode(self.M)\n",
        "#         for keyword in self.keywords:\n",
        "#             if keyword.key < center_keyword.key:\n",
        "#                 left_node.keywords.append(keyword)\n",
        "#             elif keyword.key > center_keyword.key:\n",
        "#                 right_node.keywords.append(keyword)\n",
        "#         for i in range(len(self.child_nodes)):\n",
        "#             if i <= int((len(self.child_nodes) - 1)/2):\n",
        "#                 left_node.append_child_node(self.child_nodes[i])\n",
        "#             else:\n",
        "#                 right_node.append_child_node(self.child_nodes[i])\n",
        "#         return self.get_parent(), center_keyword, left_node, right_node\n",
        "#     def add_word(self, keyword, force=False):\n",
        "#         if len(self.child_nodes) == 0 or force:\n",
        "#             self.blind_add(keyword)\n",
        "#             if len(self.keywords) == self.M:\n",
        "#                 self.split()\n",
        "#         else:\n",
        "\n",
        "#             index = self.find_add_index(keyword)\n",
        "#             if index >= len(self.child_nodes):\n",
        "#                 index = index - 1\n",
        "#             self.child_nodes[index].add_word(keyword)\n",
        "# def B_Tree_Model():\n",
        "#     # print(\"Simple B-Tree Model\")\n",
        "#     t1=time.time()\n",
        "#     root_node=BNode(4)\n",
        "#     for i in range(0,len(trainkeys)):\n",
        "#         keyword=BKeyword(trainkeys[i],trainres[i])\n",
        "#         root_node.add_word(keyword)\n",
        "#     t2=time.time()\n",
        "#     time_interval=t2-t1\n",
        "#     print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "#     # devpre=[]\n",
        "#     # for i in range(0,len(devkeys)):\n",
        "#     #     devpre.append(root_node.find_loc(devkeys[i]))\n",
        "#     # global mse_BTree\n",
        "#     # mse_BTree=mean_squared_error(devres,devpre)\n",
        "#     # print(\"log MSE dev: \",round(math.log(1+mse_BTree,2),3))\n",
        "#     t1=time.time()\n",
        "#     testpre=[]\n",
        "#     for i in range(0,len(testkeys)):\n",
        "#         testpre.append(root_node.find_loc(testkeys[i]))\n",
        "#     t2=time.time()\n",
        "#     time_interval=t2-t1\n",
        "#     print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "#     print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "#     # print(\"log MSE test: \",round(math.log(1+mean_squared_error(testres,testpre),2),3))\n",
        "#     return\n",
        "# if __name__ == '__main__':\n",
        "#     # f=codecs.open(os.path.join(current_path,\"data_train.csv\"), \"r\", \"utf-8\")\n",
        "#     # strlist=f.read().split(\"\\n\")\n",
        "#     # f.close()\n",
        "#     # trainkeys=[]\n",
        "#     # trainres=[]\n",
        "#     # for ele in strlist:\n",
        "#     #     temp=ele.split(\",\")\n",
        "#     #     if len(temp)!=2:\n",
        "#     #         continue\n",
        "#     #     trainkeys.append(int(temp[0]))\n",
        "#     #     trainres.append(int(temp[1]))\n",
        "#     # f=codecs.open(os.path.join(current_path,\"data_dev.csv\"), \"r\", \"utf-8\")\n",
        "#     # strlist=f.read().split(\"\\n\")\n",
        "#     # f.close()\n",
        "#     # devkeys=[]\n",
        "#     # devres=[]\n",
        "#     # for ele in strlist:\n",
        "#     #     temp=ele.split(\",\")\n",
        "#     #     if len(temp)!=2:\n",
        "#     #         continue\n",
        "#     #     devkeys.append(int(temp[0]))\n",
        "#     #     devres.append(int(temp[1]))\n",
        "#     # f=codecs.open(os.path.join(current_path,\"data_test.csv\"), \"r\", \"utf-8\")\n",
        "#     # strlist=f.read().split(\"\\n\")\n",
        "#     # f.close()\n",
        "#     # testkeys=[]\n",
        "#     # testres=[]\n",
        "#     # for ele in strlist:\n",
        "#     #     temp=ele.split(\",\")\n",
        "#     #     if len(temp)!=2:\n",
        "#     #         continue\n",
        "#     #     testkeys.append(int(temp[0]))\n",
        "#     #     testres.append(int(temp[1]))\n",
        "#     B_Tree_Model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:10966296.08297348 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7466915450f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;31m#     testkeys.append(int(temp[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m#     testres.append(int(temp[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mB_Tree_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-7466915450f7>\u001b[0m in \u001b[0;36mB_Tree_Model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mtestpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mtestpre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mtime_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7466915450f7>\u001b[0m in \u001b[0;36mfind_loc\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V910bU3pYspg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca4b09f-da64-43d7-f073-2c7fa264baf3"
      },
      "source": [
        "import time\n",
        "# ref: https://peefy.github.io/blog/2018/06/10/Python-BTree/\n",
        "class BTreeNode:\n",
        "    '''\n",
        "    B树结点\n",
        "    '''\n",
        "    def __init__(self, n = 0, isleaf = True):\n",
        "        '''\n",
        "        B树结点\n",
        "\n",
        "        Args\n",
        "        ===\n",
        "        `n` : 结点包含关键字的数量\n",
        "\n",
        "        `isleaf` : 是否是叶子节点\n",
        "\n",
        "        '''\n",
        "        # 结点包含关键字的数量\n",
        "        self.n = n\n",
        "        # 关键字的值数组\n",
        "        self.keys = []\n",
        "        # 子结点数组\n",
        "        self.children = []\n",
        "        # 是否是叶子节点\n",
        "        self.isleaf = isleaf\n",
        "\n",
        "    def __str__(self):\n",
        "\n",
        "        returnStr = 'keys:['\n",
        "        for i in range(self.n):\n",
        "            returnStr += str(self.keys[i]) + ' '\n",
        "        returnStr += '];childrens:['\n",
        "        for child in self.children:\n",
        "            returnStr += str(child) + ';'\n",
        "        returnStr += ']\\r\\n'\n",
        "        return returnStr\n",
        "\n",
        "    def diskread(self):\n",
        "        '''\n",
        "        磁盘读\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def diskwrite(self):\n",
        "        '''\n",
        "        磁盘写\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def allocate_node(self, key_max):\n",
        "        '''\n",
        "        在O(1)时间内为一个新结点分配一个磁盘页\n",
        "\n",
        "        假定由ALLOCATE-NODE所创建的结点无需做DISK-READ，因为磁盘上还没有关于该结点的有用信息\n",
        "\n",
        "        Return\n",
        "        ===\n",
        "        `btreenode` : 分配的B树结点\n",
        "\n",
        "        Example\n",
        "        ===\n",
        "        ```python\n",
        "        btreenode = BTreeNode.allocate_node()\n",
        "        ```\n",
        "        '''\n",
        "        node = BTreeNode()\n",
        "        child_max = key_max + 1\n",
        "        for i in range(key_max):\n",
        "            node.keys.append(None)\n",
        "        for i in range(child_max):\n",
        "            node.children.append(None)\n",
        "        return node\n",
        "\n",
        "class BTree:\n",
        "    '''\n",
        "    B树\n",
        "    '''\n",
        "    def __init__(self, m = 3):\n",
        "        '''\n",
        "        B树的定义\n",
        "        '''\n",
        "        # B树的最小度数\n",
        "        self.M = m\n",
        "        # 节点包含关键字的最大个数\n",
        "        self.KEY_MAX = 2 * self.M - 1\n",
        "        # 非根结点包含关键字的最小个数\n",
        "        self.KEY_MIN = self.M - 1\n",
        "        # 子结点的最大个数\n",
        "        self.CHILD_MAX = self.KEY_MAX + 1\n",
        "        # 子结点的最小个数\n",
        "        self.CHILD_MIN = self.KEY_MIN + 1\n",
        "        # 根结点\n",
        "        self.root: BTreeNode = None\n",
        "\n",
        "    def __new_node(self):\n",
        "        '''\n",
        "        创建新的B树结点\n",
        "        '''\n",
        "        return BTreeNode.allocate_node(self.KEY_MAX)\n",
        "\n",
        "    def insert(self, key):\n",
        "        '''\n",
        "        向B树中插入新结点`key`  \n",
        "        '''\n",
        "        # 检查关键字是否存在\n",
        "        if self.contain(key) == True:\n",
        "            return False\n",
        "        else:\n",
        "            # 检查是否为空树\n",
        "            if self.root is None:\n",
        "                node = self.__new_node()\n",
        "                node.diskwrite()\n",
        "                self.root = node    \n",
        "            # 检查根结点是否已满      \n",
        "            if self.root.n == self.KEY_MAX:\n",
        "                # 创建新的根结点\n",
        "                pNode = self.__new_node()\n",
        "                pNode.isleaf = False\n",
        "                pNode.children[0] = self.root\n",
        "                self.__split_child(pNode, 0, self.root)\n",
        "                # 更新结点指针\n",
        "                self.root = pNode\n",
        "            self.__insert_non_full(self.root, key)\n",
        "            return True\n",
        "\n",
        "    def remove(self, key): \n",
        "        '''\n",
        "        从B中删除结点`key`\n",
        "        '''      \n",
        "        # 如果关键字不存在\n",
        "        if not self.search(self.root, key):\n",
        "            return False\n",
        "        # 特殊情况处理\n",
        "        if self.root.n == 1:\n",
        "            if self.root.isleaf == True:\n",
        "                self.clear()\n",
        "            else:\n",
        "                pChild1 = self.root.children[0]\n",
        "                pChild2 = self.root.children[1]\n",
        "                if pChild1.n == self.KEY_MIN and pChild2.n == self.KEY_MIN:\n",
        "                    self.__merge_child(self.root, 0)\n",
        "                    self.__delete_node(self.root)\n",
        "                    self.root = pChild1\n",
        "        self.__recursive_remove(self.root, key)\n",
        "        return True\n",
        "    \n",
        "    def display(self):\n",
        "        '''\n",
        "        打印树的关键字  \n",
        "        '''\n",
        "        self.__display_in_concavo(self.root, self.KEY_MAX * 10)\n",
        "\n",
        "    def contain(self, key):\n",
        "        '''\n",
        "        检查该`key`是否存在于B树中  \n",
        "        '''\n",
        "        self.__search(self.root, key)\n",
        "\n",
        "    def clear(self):\n",
        "        '''\n",
        "        清空B树  \n",
        "        '''\n",
        "        self.__recursive_clear(self.root)\n",
        "        self.root = None\n",
        "\n",
        "    def __recursive_clear(self, pNode : BTreeNode):\n",
        "        '''\n",
        "        删除树  \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            if not pNode.isleaf:\n",
        "                for i in range(pNode.n):\n",
        "                    self.__recursive_clear(pNode.children[i])\n",
        "            self.__delete_node(pNode)\n",
        "\n",
        "    def __delete_node(self, pNode : BTreeNode):\n",
        "        '''\n",
        "        删除节点 \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            pNode = None\n",
        "    \n",
        "    def __search(self, pNode : BTreeNode, key):\n",
        "        '''\n",
        "        查找关键字  \n",
        "        '''\n",
        "        # 检测结点是否为空，或者该结点是否为叶子节点\n",
        "        if pNode is None:\n",
        "            return False\n",
        "        else:\n",
        "            i = 0\n",
        "            # 找到使key < pNode.keys[i]成立的最小下标\n",
        "            while i < pNode.n and key > pNode.keys[i]:\n",
        "                i += 1\n",
        "            if i < pNode.n and key == pNode.keys[i]:\n",
        "                return True\n",
        "            else:\n",
        "                # 检查该结点是否为叶子节点\n",
        "                if pNode.isleaf == True:\n",
        "                    return False\n",
        "                else:\n",
        "                    return self.__search(pNode.children[i], key)\n",
        "\n",
        "    def __split_child(self, pParent : BTreeNode, nChildIndex, pChild : BTreeNode):\n",
        "        '''\n",
        "        分裂子节点\n",
        "        '''\n",
        "        # 将pChild分裂成pLeftChild和pChild两个结点\n",
        "        pRightNode = self.__new_node()  # 分裂后的右结点\n",
        "        pRightNode.isleaf = pChild.isleaf\n",
        "        pRightNode.n = self.KEY_MIN\n",
        "        # 拷贝关键字的值\n",
        "        for i in range(self.KEY_MIN):\n",
        "            pRightNode.keys[i] = pChild.keys[i + self.CHILD_MIN]\n",
        "        # 如果不是叶子结点，就拷贝孩子结点指针\n",
        "        if not pChild.isleaf:\n",
        "            for i in range(self.CHILD_MIN):\n",
        "                pRightNode.children[i] = pChild.children[i + self.CHILD_MIN]\n",
        "        # 更新左子树的关键字个数\n",
        "        pChild.n = self.KEY_MIN\n",
        "        # 将父结点中的pChildIndex后的所有关键字的值和子树指针向后移动一位\n",
        "        for i in range(nChildIndex, pParent.n):\n",
        "            j = pParent.n + nChildIndex - i\n",
        "            pParent.children[j + 1] = pParent.children[j]\n",
        "            pParent.keys[j] = pParent.keys[j - 1]\n",
        "        # 更新父结点的关键字个数\n",
        "        pParent.n += 1\n",
        "        # 存储右子树指针\n",
        "        pParent.children[nChildIndex + 1] = pRightNode\n",
        "        # 把结点的中间值提到父结点\n",
        "        pParent.keys[nChildIndex] = pChild.keys[self.KEY_MIN]\n",
        "        pChild.diskwrite()\n",
        "        pRightNode.diskwrite()\n",
        "        pParent.diskwrite()\n",
        "    \n",
        "    def __insert_non_full(self, pNode: BTreeNode, key):\n",
        "        '''\n",
        "        在非满节点中插入关键字\n",
        "        '''\n",
        "        # 获取结点内关键字个数\n",
        "        i = pNode.n\n",
        "        # 如果pNode是叶子结点\n",
        "        if pNode.isleaf == True:\n",
        "            # 从后往前 查找关键字的插入位置\n",
        "            while i > 0 and key < pNode.keys[i - 1]:\n",
        "                # 向后移位\n",
        "                pNode.keys[i] = pNode.keys[i - 1]\n",
        "                i -= 1\n",
        "            # 插入关键字的值\n",
        "            pNode.keys[i] = key\n",
        "            # 更新结点关键字的个数\n",
        "            pNode.n += 1\n",
        "            pNode.diskwrite()\n",
        "        # pnode是内结点\n",
        "        else:\n",
        "            # 从后往前 查找关键字的插入的子树\n",
        "            while i > 0 and key < pNode.keys[i - 1]:\n",
        "                i -= 1\n",
        "            # 目标子树结点指针\n",
        "            pChild = pNode.children[i]\n",
        "            pNode.children[i].diskread()\n",
        "            # 子树结点已经满了\n",
        "            if pChild.n == self.KEY_MAX:\n",
        "                # 分裂子树结点\n",
        "                self.__split_child(pNode, i, pChild)\n",
        "                # 确定目标子树\n",
        "                if key > pNode.keys[i]:\n",
        "                    pChild = pNode.children[i + 1]\n",
        "            # 插入关键字到目标子树结点\n",
        "            self.__insert_non_full(pChild, key)\n",
        "\n",
        "    def __display_in_concavo(self, pNode: BTreeNode, count):\n",
        "        '''\n",
        "        用括号打印树 \n",
        "        '''\n",
        "        if pNode is not None:\n",
        "            i = 0\n",
        "            j = 0\n",
        "            for i in range(pNode.n):\n",
        "                if not pNode.isleaf:\n",
        "                    self.__display_in_concavo(pNode.children[i], count - 2)\n",
        "                for j in range(-1, count):\n",
        "                    k = count - j - 1\n",
        "                    print('-', end='')\n",
        "                print(pNode.keys[i])\n",
        "            if not pNode.isleaf:\n",
        "                self.__display_in_concavo(pNode.children[i], count - 2)\n",
        "\n",
        "    def __merge_child(self, pParent: BTreeNode, index):\n",
        "        '''\n",
        "        合并两个子结点\n",
        "        '''\n",
        "        pChild1 = pParent.children[index]\n",
        "        pChild2 = pParent.children[index + 1]\n",
        "        # 将pChild2数据合并到pChild1\n",
        "        pChild1.n = self.KEY_MAX\n",
        "        # 将父结点index的值下移\n",
        "        pChild1.keys[self.KEY_MIN] = pParent.keys[index]\n",
        "        for i in range(self.KEY_MIN):\n",
        "            pChild1.keys[i + self.KEY_MIN + 1] = pChild2.keys[i]\n",
        "        if not pChild1.isleaf:\n",
        "            for i in range(self.CHILD_MIN):\n",
        "                pChild1.children[i + self.CHILD_MIN] = pChild2.children[i]\n",
        "        # 父结点删除index的key，index后的往前移一位\n",
        "        pParent.n -= 1\n",
        "        for i in range(index, pParent.n):\n",
        "            pParent.keys[i] = pParent.keys[i + 1]\n",
        "            pParent.children[i + 1] = pParent.children[i + 2]\n",
        "        # 删除pChild2\n",
        "        self.__delete_node(pChild2)\n",
        "\n",
        "    def __recursive_remove(self, pNode: BTreeNode, key):\n",
        "        '''\n",
        "        递归的删除关键字`key`  \n",
        "        '''\n",
        "        i = 0\n",
        "        while i < pNode.n and key > pNode.keys[i]:\n",
        "            i += 1\n",
        "        # 关键字key在结点pNode\n",
        "        if i < pNode.n and key == pNode.keys[i]:\n",
        "            # pNode是个叶结点\n",
        "            if pNode.isleaf == True:\n",
        "                # 从pNode中删除k\n",
        "                for j in range(i, pNode.n):\n",
        "                    pNode.keys[j] = pNode.keys[j + 1]\n",
        "                return\n",
        "            # pNode是个内结点\n",
        "            else:\n",
        "                # 结点pNode中前于key的子结点\n",
        "                pChildPrev = pNode.children[i]\n",
        "                # 结点pNode中后于key的子结点\n",
        "                pChildNext = pNode.children[i + 1]\n",
        "                if pChildPrev.n >= self.CHILD_MIN:\n",
        "                    # 获取key的前驱关键字\n",
        "                    prevKey = self.predecessor(pChildPrev)\n",
        "                    self.__recursive_remove(pChildPrev, prevKey)\n",
        "                    # 替换成key的前驱关键字\n",
        "                    pNode.keys[i] = prevKey\n",
        "                    return\n",
        "                # 结点pChildNext中至少包含CHILD_MIN个关键字\n",
        "                elif pChildNext.n >= self.CHILD_MIN:\n",
        "                    # 获取key的后继关键字\n",
        "                    nextKey = self.successor(pChildNext)\n",
        "                    self.__recursive_remove(pChildNext, nextKey)\n",
        "                    # 替换成key的后继关键字\n",
        "                    pNode.keys[i] = nextKey\n",
        "                    return\n",
        "                # 结点pChildPrev和pChildNext中都只包含CHILD_MIN-1个关键字\n",
        "                else:\n",
        "                    self.__merge_child(pNode, i)\n",
        "                    self.__recursive_remove(pChildPrev, key)\n",
        "        # 关键字key不在结点pNode中\n",
        "        else:\n",
        "            # 包含key的子树根结点\n",
        "            pChildNode = pNode.children[i]\n",
        "            # 只有t-1个关键字\n",
        "            if pChildNode.n == self.KEY_MAX:\n",
        "                # 左兄弟结点\n",
        "                pLeft = None\n",
        "                # 右兄弟结点\n",
        "                pRight = None\n",
        "                # 左兄弟结点\n",
        "                if i > 0:\n",
        "                    pLeft = pNode.children[i - 1]\n",
        "                # 右兄弟结点\n",
        "                if i < pNode.n:\n",
        "                    pRight = pNode.children[i + 1]\n",
        "                j = 0\n",
        "                if pLeft is not None and pLeft.n >= self.CHILD_MIN:\n",
        "                    # 父结点中i-1的关键字下移至pChildNode中\n",
        "                    for j in range(pChildNode.n):\n",
        "                        k = pChildNode.n - j\n",
        "                        pChildNode.keys[k] = pChildNode.keys[k - 1]\n",
        "                    pChildNode.keys[0] = pNode.keys[i - 1]\n",
        "                    if not pLeft.isleaf:\n",
        "                        # pLeft结点中合适的子女指针移到pChildNode中\n",
        "                        for j in range(pChildNode.n + 1):\n",
        "                            k = pChildNode.n + 1 - j\n",
        "                            pChildNode.children[k] = pChildNode.children[k - 1]\n",
        "                        pChildNode.children[0] = pLeft.children[pLeft.n]\n",
        "                    pChildNode.n += 1\n",
        "                    pNode.keys[i] = pLeft.keys[pLeft.n - 1]\n",
        "                    pLeft.n -= 1\n",
        "                # 右兄弟结点至少有CHILD_MIN个关键字\n",
        "                elif pRight is not None and pRight.n >= self.CHILD_MIN:\n",
        "                    # 父结点中i的关键字下移至pChildNode中\n",
        "                    pChildNode.keys[pChildNode.n] = pNode.keys[i]\n",
        "                    pChildNode.n += 1\n",
        "                    # pRight结点中的最小关键字上升到pNode中\n",
        "                    pNode.keys[i] = pRight.keys[0]\n",
        "                    pRight.n -= 1\n",
        "                    for j in range(pRight.n):\n",
        "                        pRight.keys[j] = pRight.keys[j + 1]\n",
        "                    if not pRight.isleaf:\n",
        "                        # pRight结点中合适的子女指针移动到pChildNode中\n",
        "                        pChildNode.children[pChildNode.n] = pRight.children[0]\n",
        "                        for j in range(pRight.n):\n",
        "                            pRight.children[j] = pRight.children[j + 1]\n",
        "                # 左右兄弟结点都只包含CHILD_MIN-1个结点\n",
        "                elif pLeft is not None:\n",
        "                    self.__merge_child(pNode, i - 1)\n",
        "                    pChildNode = pLeft\n",
        "                # 与右兄弟合并\n",
        "                elif pRight is not None:\n",
        "                    self.__merge_child(pNode, i)\n",
        "            self.__recursive_remove(pChildNode, key)\n",
        "\n",
        "    def predecessor(self, pNode: BTreeNode):\n",
        "        '''\n",
        "        前驱关键字\n",
        "        '''\n",
        "        while not pNode.isleaf:\n",
        "            pNode = pNode.children[pNode.n]\n",
        "        return pNode.keys[pNode.n - 1]\n",
        "\n",
        "    def successor(self, pNode: BTreeNode):\n",
        "        '''\n",
        "        后继关键字\n",
        "        '''\n",
        "        while not pNode.isleaf:\n",
        "            pNode = pNode.children[0]\n",
        "        return pNode.keys[0]\n",
        "\n",
        "def test():\n",
        "    '''\n",
        "    test class `BTree` and class `BTreeNode`\n",
        "    '''\n",
        "    tree = BTree(10)\n",
        "    # tree.insert(11)\n",
        "    # tree.insert(3)\n",
        "    # tree.insert(1)\n",
        "    # tree.insert(4)\n",
        "    # tree.insert(33)\n",
        "    # tree.insert(13)\n",
        "    # tree.insert(63)\n",
        "    # tree.insert(43)\n",
        "    # tree.insert(2)\n",
        "    # print(tree.root)\n",
        "    # tree.display()\n",
        "    # tree.clear()\n",
        "    # tree = BTree(2)\n",
        "    # tree.insert(11)\n",
        "    # tree.insert(3)\n",
        "    # tree.insert(1)\n",
        "    # tree.insert(4)\n",
        "    # tree.insert(33)\n",
        "    # tree.insert(13)\n",
        "    # tree.insert(63)\n",
        "    # tree.insert(43)\n",
        "    # tree.insert(2)\n",
        "    # print(tree.root)\n",
        "    # tree.display()\n",
        "    t1=time.time()\n",
        "    for i in range(0,len(trainkeys)):\n",
        "        tree.insert(trainkeys[i])\n",
        "    t2=time.time()\n",
        "    time_interval=t2-t1\n",
        "    print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "    ret1=time_interval*1000\n",
        "    t1=time.time()\n",
        "    # testpre=[]\n",
        "    for i in range(0,len(testkeys)):\n",
        "        tree.contain(testkeys[i])\n",
        "    t2=time.time()\n",
        "    time_interval=t2-t1\n",
        "    print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "    print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "    ret2=time_interval*1000\n",
        "    ret3=time_interval/len(testkeys)*1000\n",
        "    return (ret1,ret2,ret3)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    avg_a=0.0\n",
        "    avg_b=0.0\n",
        "    avg_c=0.0\n",
        "    counting=20\n",
        "    for i in range(0,20):\n",
        "        (a,b,c)=test()\n",
        "        avg_a+=a\n",
        "        avg_b+=b\n",
        "        avg_c+=c\n",
        "    avg_a=avg_a/counting\n",
        "    avg_b=avg_b/counting\n",
        "    avg_c=avg_c/counting\n",
        "    print(\"average times (ms):\",avg_a,avg_b,avg_c)\n",
        "else:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:635.9512805938721 ms\n",
            "time interval for indexing data :114.79973793029785 ms\n",
            "average time interval for indexing data :0.006559985024588448 ms\n",
            "time interval for building model:718.303918838501 ms\n",
            "time interval for indexing data :121.3841438293457 ms\n",
            "average time interval for indexing data :0.006936236790248326 ms\n",
            "time interval for building model:647.3269462585449 ms\n",
            "time interval for indexing data :118.51620674133301 ms\n",
            "average time interval for indexing data :0.006772354670933315 ms\n",
            "time interval for building model:680.4103851318359 ms\n",
            "time interval for indexing data :115.46754837036133 ms\n",
            "average time interval for indexing data :0.006598145621163504 ms\n",
            "time interval for building model:644.0925598144531 ms\n",
            "time interval for indexing data :115.57221412658691 ms\n",
            "average time interval for indexing data :0.006604126521519252 ms\n",
            "time interval for building model:728.374719619751 ms\n",
            "time interval for indexing data :116.04833602905273 ms\n",
            "average time interval for indexing data :0.0066313334873744426 ms\n",
            "time interval for building model:644.0753936767578 ms\n",
            "time interval for indexing data :137.50791549682617 ms\n",
            "average time interval for indexing data :0.00785759517124721 ms\n",
            "time interval for building model:640.0291919708252 ms\n",
            "time interval for indexing data :116.7304515838623 ms\n",
            "average time interval for indexing data :0.006670311519077846 ms\n",
            "time interval for building model:643.5604095458984 ms\n",
            "time interval for indexing data :115.77486991882324 ms\n",
            "average time interval for indexing data :0.006615706852504185 ms\n",
            "time interval for building model:645.8711624145508 ms\n",
            "time interval for indexing data :117.49410629272461 ms\n",
            "average time interval for indexing data :0.006713948931012835 ms\n",
            "time interval for building model:716.0029411315918 ms\n",
            "time interval for indexing data :121.0172176361084 ms\n",
            "average time interval for indexing data :0.006915269579206194 ms\n",
            "time interval for building model:803.5662174224854 ms\n",
            "time interval for indexing data :206.4354419708252 ms\n",
            "average time interval for indexing data :0.01179631096976144 ms\n",
            "time interval for building model:742.7310943603516 ms\n",
            "time interval for indexing data :183.08424949645996 ms\n",
            "average time interval for indexing data :0.010461957114083428 ms\n",
            "time interval for building model:705.5222988128662 ms\n",
            "time interval for indexing data :115.49663543701172 ms\n",
            "average time interval for indexing data :0.006599807739257812 ms\n",
            "time interval for building model:721.5437889099121 ms\n",
            "time interval for indexing data :197.80445098876953 ms\n",
            "average time interval for indexing data :0.011303111485072546 ms\n",
            "time interval for building model:647.8803157806396 ms\n",
            "time interval for indexing data :114.14337158203125 ms\n",
            "average time interval for indexing data :0.006522478376116071 ms\n",
            "time interval for building model:641.6399478912354 ms\n",
            "time interval for indexing data :199.42712783813477 ms\n",
            "average time interval for indexing data :0.011395835876464845 ms\n",
            "time interval for building model:637.6092433929443 ms\n",
            "time interval for indexing data :121.03986740112305 ms\n",
            "average time interval for indexing data :0.006916563851492746 ms\n",
            "time interval for building model:719.9387550354004 ms\n",
            "time interval for indexing data :115.96989631652832 ms\n",
            "average time interval for indexing data :0.0066268512180873325 ms\n",
            "time interval for building model:646.2714672088623 ms\n",
            "time interval for indexing data :197.17025756835938 ms\n",
            "average time interval for indexing data :0.011266871861049108 ms\n",
            "average times (ms): 680.535101890564 138.04420232772827 0.007888240133013046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFozfUYVjs1N"
      },
      "source": [
        "## Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iGwMYPPjk-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c69e4be-7aa5-49e6-8664-85e6dfa53efc"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error \n",
        "import math\n",
        "import time\n",
        "# print(\"Linear Regression Model\")\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  reg = LinearRegression()\n",
        "  reg.fit(X_train,Y_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  # devpre=reg.predict(np.array(devkeys).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
        "  # for i in range(0,len(devpre)):\n",
        "  #     devpre[i]=abs(int(devpre[i]))\n",
        "  # mse_LR=mean_squared_error(devres,devpre)\n",
        "  # print(\"MSE dev: \",mse_LR)\n",
        "  t1=time.time()\n",
        "  testpre=reg.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  for i in range(0,len(testpre)):\n",
        "    testpre[i]=abs(int(testpre[i]))\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  # print(\"log MSE test: \",round(math.log(1+mean_squared_error(testres,testpre),2),3))\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_loc=testpre[i]\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "      finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "      finding_res=trainres[0]\n",
        "    else:\n",
        "      finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "    # i=begin\n",
        "    # while i<=end:\n",
        "    #   # print(i,end)\n",
        "    #   if finding_res==trainkeys[i]:\n",
        "    #     break\n",
        "    #   else:\n",
        "    #     i=i+1\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:28.528928756713867 ms\n",
            "time interval for indexing data :0.34809112548828125 ms\n",
            "average time interval for indexing data :0.012003142258216595 ms\n",
            "time interval for error correction :0.07843971252441406 ms\n",
            "average time interval for error correction :0.0029051745379412614 ms\n",
            "time interval for building model:0.6852149963378906 ms\n",
            "time interval for indexing data :0.12826919555664062 ms\n",
            "average time interval for indexing data :0.004423075708849677 ms\n",
            "time interval for error correction :0.07367134094238281 ms\n",
            "average time interval for error correction :0.0027285681830512155 ms\n",
            "time interval for building model:0.5140304565429688 ms\n",
            "time interval for indexing data :0.12683868408203125 ms\n",
            "average time interval for indexing data :0.004373747726966595 ms\n",
            "time interval for error correction :0.07772445678710938 ms\n",
            "average time interval for error correction :0.002878683584707755 ms\n",
            "time interval for building model:0.5998611450195312 ms\n",
            "time interval for indexing data :0.13518333435058594 ms\n",
            "average time interval for indexing data :0.00466149428795124 ms\n",
            "time interval for error correction :0.11849403381347656 ms\n",
            "average time interval for error correction :0.004388667919017651 ms\n",
            "time interval for building model:0.6847381591796875 ms\n",
            "time interval for indexing data :0.1327991485595703 ms\n",
            "average time interval for indexing data :0.004579280984812769 ms\n",
            "time interval for error correction :0.07414817810058594 ms\n",
            "average time interval for error correction :0.00274622881854022 ms\n",
            "time interval for building model:0.5137920379638672 ms\n",
            "time interval for indexing data :0.11706352233886719 ms\n",
            "average time interval for indexing data :0.004036673184098868 ms\n",
            "time interval for error correction :0.07867813110351562 ms\n",
            "average time interval for error correction :0.0029140048556857636 ms\n",
            "time interval for building model:0.8475780487060547 ms\n",
            "time interval for indexing data :0.14710426330566406 ms\n",
            "average time interval for indexing data :0.005072560803643588 ms\n",
            "time interval for error correction :0.07843971252441406 ms\n",
            "average time interval for error correction :0.0029051745379412614 ms\n",
            "time interval for building model:0.5347728729248047 ms\n",
            "time interval for indexing data :0.1285076141357422 ms\n",
            "average time interval for indexing data :0.004431297039163523 ms\n",
            "time interval for error correction :0.0820159912109375 ms\n",
            "average time interval for error correction :0.0030376293041087963 ms\n",
            "time interval for building model:0.4894733428955078 ms\n",
            "time interval for indexing data :0.171661376953125 ms\n",
            "average time interval for indexing data :0.005919357825969827 ms\n",
            "time interval for error correction :0.06794929504394531 ms\n",
            "average time interval for error correction :0.0025166405571831595 ms\n",
            "time interval for building model:0.8215904235839844 ms\n",
            "time interval for indexing data :0.12874603271484375 ms\n",
            "average time interval for indexing data :0.0044395183694773705 ms\n",
            "time interval for error correction :0.09250640869140625 ms\n",
            "average time interval for error correction :0.003426163284866898 ms\n",
            "time interval for building model:0.6496906280517578 ms\n",
            "time interval for indexing data :0.11992454528808594 ms\n",
            "average time interval for indexing data :0.004135329147865033 ms\n",
            "time interval for error correction :0.08535385131835938 ms\n",
            "average time interval for error correction :0.0031612537525318287 ms\n",
            "time interval for building model:0.7259845733642578 ms\n",
            "time interval for indexing data :0.1671314239501953 ms\n",
            "average time interval for indexing data :0.005763152550006735 ms\n",
            "time interval for error correction :0.07510185241699219 ms\n",
            "average time interval for error correction :0.002781550089518229 ms\n",
            "time interval for building model:0.5266666412353516 ms\n",
            "time interval for indexing data :0.14925003051757812 ms\n",
            "average time interval for indexing data :0.0051465527764682105 ms\n",
            "time interval for error correction :0.08082389831542969 ms\n",
            "average time interval for error correction :0.0029934777153862845 ms\n",
            "time interval for building model:0.5209445953369141 ms\n",
            "time interval for indexing data :0.11897087097167969 ms\n",
            "average time interval for indexing data :0.004102443826609644 ms\n",
            "time interval for error correction :0.07891654968261719 ms\n",
            "average time interval for error correction :0.002922835173430266 ms\n",
            "time interval for building model:0.5023479461669922 ms\n",
            "time interval for indexing data :0.17023086547851562 ms\n",
            "average time interval for indexing data :0.0058700298440867455 ms\n",
            "time interval for error correction :0.05650520324707031 ms\n",
            "average time interval for error correction :0.002092785305447049 ms\n",
            "time interval for building model:0.48995018005371094 ms\n",
            "time interval for indexing data :0.13327598571777344 ms\n",
            "average time interval for indexing data :0.004595723645440463 ms\n",
            "time interval for error correction :0.08535385131835938 ms\n",
            "average time interval for error correction :0.0031612537525318287 ms\n",
            "time interval for building model:0.4913806915283203 ms\n",
            "time interval for indexing data :0.12421607971191406 ms\n",
            "average time interval for indexing data :0.0042833130935142774 ms\n",
            "time interval for error correction :0.07867813110351562 ms\n",
            "average time interval for error correction :0.0029140048556857636 ms\n",
            "time interval for building model:0.4534721374511719 ms\n",
            "time interval for indexing data :0.12540817260742188 ms\n",
            "average time interval for indexing data :0.004324419745083513 ms\n",
            "time interval for error correction :0.08368492126464844 ms\n",
            "average time interval for error correction :0.0030994415283203125 ms\n",
            "time interval for building model:0.4696846008300781 ms\n",
            "time interval for indexing data :0.17380714416503906 ms\n",
            "average time interval for indexing data :0.00599334979879445 ms\n",
            "time interval for error correction :0.05650520324707031 ms\n",
            "average time interval for error correction :0.002092785305447049 ms\n",
            "time interval for building model:0.5283355712890625 ms\n",
            "time interval for indexing data :0.27489662170410156 ms\n",
            "average time interval for indexing data :0.009479193851865571 ms\n",
            "time interval for error correction :0.06580352783203125 ms\n",
            "average time interval for error correction :0.0024371676974826386 ms\n",
            "average times (ms): 1.978921890258789 0.1560688018798828 0.005381682823444235 0.07843971252441406 0.002704817673255657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57UvrCeeoj3K"
      },
      "source": [
        "## Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pJF18ckom0C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "d5ebf126-a4b2-40e5-a75a-52ce011f95c8"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error \n",
        "import math\n",
        "import time\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  reg = Ridge(alpha=0.1)\n",
        "  reg.fit(X_train,Y_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  # devpre=reg.predict(np.array(devkeys).reshape(-1,1)).reshape(1,-1).tolist()[0]\n",
        "  # for i in range(0,len(devpre)):\n",
        "  #     devpre[i]=abs(int(devpre[i]))\n",
        "  # mse_LR=mean_squared_error(devres,devpre)\n",
        "  # print(\"MSE dev: \",mse_LR)\n",
        "  t1=time.time()\n",
        "  testpre=reg.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  for i in range(0,len(testpre)):\n",
        "    testpre[i]=abs(int(testpre[i]))\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  # print(\"log MSE test: \",round(math.log(1+mean_squared_error(testres,testpre),2),3))\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_loc=testpre[i]\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "      finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "      finding_res=trainres[0]\n",
        "    else:\n",
        "      finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "    # i=begin\n",
        "    # while i<=end:\n",
        "    #   # print(i,end)\n",
        "    #   if finding_res==trainkeys[i]:\n",
        "    #     break\n",
        "    #   else:\n",
        "    #     i=i+1\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/count_error*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:5.962848663330078 ms\n",
            "time interval for indexing data :0.2779960632324219 ms\n",
            "average time interval for indexing data :0.0010775041210558988 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-903d09397362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mcounting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0mavg_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mavg_b\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-903d09397362>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mestimated_loc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mestimated_loc\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mestimated_loc\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m           \u001b[0mfinding_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimated_loc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mestimated_loc\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           \u001b[0mfinding_res\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqnt4MnH1sII"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyWGYLaG1wXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f7f03ed-65ae-49e5-e8c1-49fd41ed5817"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  neigh = KNeighborsClassifier(n_neighbors=9)\n",
        "  neigh.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=neigh.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  # print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=neigh.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  # print(testpre)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for indexing data :465.6825065612793 ms\n",
            "average time interval for indexing data :0.026610428946358816 ms\n",
            "time interval for error correction :25.13861656188965 ms\n",
            "average time interval for error correction :0.0014364923749651227 ms\n",
            "time interval for indexing data :485.3668212890625 ms\n",
            "average time interval for indexing data :0.02773524693080357 ms\n",
            "time interval for error correction :27.59552001953125 ms\n",
            "average time interval for error correction :0.0015768868582589286 ms\n",
            "time interval for indexing data :468.9135551452637 ms\n",
            "average time interval for indexing data :0.026795060294015068 ms\n",
            "time interval for error correction :25.007009506225586 ms\n",
            "average time interval for error correction :0.001428971971784319 ms\n",
            "time interval for indexing data :463.7460708618164 ms\n",
            "average time interval for indexing data :0.02649977547781808 ms\n",
            "time interval for error correction :24.80006217956543 ms\n",
            "average time interval for error correction :0.0014171464102608817 ms\n",
            "time interval for indexing data :471.39549255371094 ms\n",
            "average time interval for indexing data :0.02693688528878348 ms\n",
            "time interval for error correction :25.429964065551758 ms\n",
            "average time interval for error correction :0.0014531408037458146 ms\n",
            "time interval for indexing data :469.8824882507324 ms\n",
            "average time interval for indexing data :0.026850427900041853 ms\n",
            "time interval for error correction :25.040626525878906 ms\n",
            "average time interval for error correction :0.0014308929443359374 ms\n",
            "time interval for indexing data :548.5265254974365 ms\n",
            "average time interval for indexing data :0.0313443728855678 ms\n",
            "time interval for error correction :24.82438087463379 ms\n",
            "average time interval for error correction :0.0014185360499790736 ms\n",
            "time interval for indexing data :457.60607719421387 ms\n",
            "average time interval for indexing data :0.026148918696812223 ms\n",
            "time interval for error correction :25.66671371459961 ms\n",
            "average time interval for error correction :0.0014666693551199778 ms\n",
            "time interval for indexing data :485.7966899871826 ms\n",
            "average time interval for indexing data :0.027759810856410435 ms\n",
            "time interval for error correction :25.87151527404785 ms\n",
            "average time interval for error correction :0.001478372301374163 ms\n",
            "time interval for indexing data :475.9659767150879 ms\n",
            "average time interval for indexing data :0.027198055812290737 ms\n",
            "time interval for error correction :26.203632354736328 ms\n",
            "average time interval for error correction :0.0014973504202706474 ms\n",
            "time interval for indexing data :465.66104888916016 ms\n",
            "average time interval for indexing data :0.026609202793666294 ms\n",
            "time interval for error correction :25.117874145507812 ms\n",
            "average time interval for error correction :0.001435307094029018 ms\n",
            "time interval for indexing data :469.1202640533447 ms\n",
            "average time interval for indexing data :0.026806872231619698 ms\n",
            "time interval for error correction :26.106595993041992 ms\n",
            "average time interval for error correction :0.0014918054853166852 ms\n",
            "time interval for indexing data :484.77745056152344 ms\n",
            "average time interval for indexing data :0.027701568603515626 ms\n",
            "time interval for error correction :26.555776596069336 ms\n",
            "average time interval for error correction :0.0015174729483468192 ms\n",
            "time interval for indexing data :463.49358558654785 ms\n",
            "average time interval for indexing data :0.026485347747802732 ms\n",
            "time interval for error correction :25.01821517944336 ms\n",
            "average time interval for error correction :0.001429612295968192 ms\n",
            "time interval for indexing data :473.51527214050293 ms\n",
            "average time interval for indexing data :0.02705801555088588 ms\n",
            "time interval for error correction :26.009082794189453 ms\n",
            "average time interval for error correction :0.0014862333025251117 ms\n",
            "time interval for indexing data :541.4488315582275 ms\n",
            "average time interval for indexing data :0.03093993323189872 ms\n",
            "time interval for error correction :25.152206420898438 ms\n",
            "average time interval for error correction :0.0014372689383370537 ms\n",
            "time interval for indexing data :477.64086723327637 ms\n",
            "average time interval for indexing data :0.02729376384190151 ms\n",
            "time interval for error correction :26.58820152282715 ms\n",
            "average time interval for error correction :0.0015193258013044084 ms\n",
            "time interval for indexing data :483.5538864135742 ms\n",
            "average time interval for indexing data :0.027631650652204243 ms\n",
            "time interval for error correction :26.37791633605957 ms\n",
            "average time interval for error correction :0.0015073095049176898 ms\n",
            "time interval for indexing data :480.53836822509766 ms\n",
            "average time interval for indexing data :0.027459335327148435 ms\n",
            "time interval for error correction :25.106430053710938 ms\n",
            "average time interval for error correction :0.0014346531459263393 ms\n",
            "time interval for indexing data :467.61131286621094 ms\n",
            "average time interval for indexing data :0.02672064644949777 ms\n",
            "time interval for error correction :31.827688217163086 ms\n",
            "average time interval for error correction :0.0018187250409807476 ms\n",
            "average times (ms): 3495.4586386680603 480.0121545791626 0.02742926597595215 25.971901416778564 0.0014841086523873464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFiz9zKE8B6q"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL1JcWyN8F1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b88dc611-d563-4455-a204-4af8e1b49ae9"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  NB = GaussianNB()\n",
        "  NB.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=NB.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=NB.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:42.84238815307617 ms\n",
            "time interval for indexing data :73.23312759399414 ms\n",
            "average time interval for indexing data :0.006974583580380394 ms\n",
            "time interval for error correction :15.73324203491211 ms\n",
            "average time interval for error correction :0.0014984040033249628 ms\n",
            "time interval for building model:42.938232421875 ms\n",
            "time interval for indexing data :49.68714714050293 ms\n",
            "average time interval for indexing data :0.004732109251476469 ms\n",
            "time interval for error correction :15.28024673461914 ms\n",
            "average time interval for error correction :0.0014552615937732515 ms\n",
            "time interval for building model:44.3568229675293 ms\n",
            "time interval for indexing data :49.918174743652344 ms\n",
            "average time interval for indexing data :0.0047541118803478425 ms\n",
            "time interval for error correction :16.353130340576172 ms\n",
            "average time interval for error correction :0.0015574409848167783 ms\n",
            "time interval for building model:41.79978370666504 ms\n",
            "time interval for indexing data :49.994468688964844 ms\n",
            "average time interval for indexing data :0.0047613779703776045 ms\n",
            "time interval for error correction :15.99264144897461 ms\n",
            "average time interval for error correction :0.0015231087094261533 ms\n",
            "time interval for building model:46.69594764709473 ms\n",
            "time interval for indexing data :49.26013946533203 ms\n",
            "average time interval for indexing data :0.0046914418538411455 ms\n",
            "time interval for error correction :15.978097915649414 ms\n",
            "average time interval for error correction :0.0015217236110142299 ms\n",
            "time interval for building model:42.77920722961426 ms\n",
            "time interval for indexing data :54.93617057800293 ms\n",
            "average time interval for indexing data :0.005232016245524089 ms\n",
            "time interval for error correction :19.075632095336914 ms\n",
            "average time interval for error correction :0.0018167268662225631 ms\n",
            "time interval for building model:46.58985137939453 ms\n",
            "time interval for indexing data :49.54266548156738 ms\n",
            "average time interval for indexing data :0.004718349093482607 ms\n",
            "time interval for error correction :16.312599182128906 ms\n",
            "average time interval for error correction :0.0015535808744884673 ms\n",
            "time interval for building model:41.907548904418945 ms\n",
            "time interval for indexing data :49.08275604248047 ms\n",
            "average time interval for indexing data :0.0046745481945219495 ms\n",
            "time interval for error correction :16.93558692932129 ms\n",
            "average time interval for error correction :0.0016129130408877419 ms\n",
            "time interval for building model:47.263145446777344 ms\n",
            "time interval for indexing data :52.13356018066406 ms\n",
            "average time interval for indexing data :0.004965100969587054 ms\n",
            "time interval for error correction :16.30997657775879 ms\n",
            "average time interval for error correction :0.0015533311026436941 ms\n",
            "time interval for building model:40.79031944274902 ms\n",
            "time interval for indexing data :49.262285232543945 ms\n",
            "average time interval for indexing data :0.004691646212623233 ms\n",
            "time interval for error correction :15.868902206420898 ms\n",
            "average time interval for error correction :0.0015113240196591331 ms\n",
            "time interval for building model:54.0919303894043 ms\n",
            "time interval for indexing data :51.989078521728516 ms\n",
            "average time interval for indexing data :0.004951340811593192 ms\n",
            "time interval for error correction :16.36958122253418 ms\n",
            "average time interval for error correction :0.0015590077354794456 ms\n",
            "time interval for building model:43.88689994812012 ms\n",
            "time interval for indexing data :51.65696144104004 ms\n",
            "average time interval for indexing data :0.004919710613432385 ms\n",
            "time interval for error correction :16.559123992919922 ms\n",
            "average time interval for error correction :0.0015770594278971353 ms\n",
            "time interval for building model:46.5695858001709 ms\n",
            "time interval for indexing data :47.97935485839844 ms\n",
            "average time interval for indexing data :0.004569462367466518 ms\n",
            "time interval for error correction :15.45405387878418 ms\n",
            "average time interval for error correction :0.0014718146551223029 ms\n",
            "time interval for building model:50.31561851501465 ms\n",
            "time interval for indexing data :49.03125762939453 ms\n",
            "average time interval for indexing data :0.00466964358375186 ms\n",
            "time interval for error correction :16.83354377746582 ms\n",
            "average time interval for error correction :0.0016031946454729351 ms\n",
            "time interval for building model:50.61030387878418 ms\n",
            "time interval for indexing data :53.771018981933594 ms\n",
            "average time interval for indexing data :0.0051210494268508185 ms\n",
            "time interval for error correction :15.457391738891602 ms\n",
            "average time interval for error correction :0.0014721325465611049 ms\n",
            "time interval for building model:40.522098541259766 ms\n",
            "time interval for indexing data :47.276973724365234 ms\n",
            "average time interval for indexing data :0.004502568926130022 ms\n",
            "time interval for error correction :14.986991882324219 ms\n",
            "average time interval for error correction :0.001427332560221354 ms\n",
            "time interval for building model:44.891357421875 ms\n",
            "time interval for indexing data :51.010847091674805 ms\n",
            "average time interval for indexing data :0.004858175913492838 ms\n",
            "time interval for error correction :17.222881317138672 ms\n",
            "average time interval for error correction :0.001640274411156064 ms\n",
            "time interval for building model:42.296648025512695 ms\n",
            "time interval for indexing data :48.08306694030762 ms\n",
            "average time interval for indexing data :0.004579339708600725 ms\n",
            "time interval for error correction :15.95163345336914 ms\n",
            "average time interval for error correction :0.0015192031860351562 ms\n",
            "time interval for building model:46.35882377624512 ms\n",
            "time interval for indexing data :48.241376876831055 ms\n",
            "average time interval for indexing data :0.004594416845412482 ms\n",
            "time interval for error correction :16.588926315307617 ms\n",
            "average time interval for error correction :0.0015798977443150111 ms\n",
            "time interval for building model:41.46265983581543 ms\n",
            "time interval for indexing data :50.689697265625 ms\n",
            "average time interval for indexing data :0.004827590215773809 ms\n",
            "time interval for error correction :16.123533248901367 ms\n",
            "average time interval for error correction :0.0015355745951334636 ms\n",
            "average times (ms): 44.948458671569824 51.339006423950195 0.004889429183233351 16.269385814666748 0.0015494653156825477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyKzSl2r8TWl"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9EJXW3W8WcZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67fa80ee-17bc-4da4-e59a-e237358086a6"
      },
      "source": [
        "from sklearn import tree\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  dtree = tree.DecisionTreeClassifier(max_depth=None)\n",
        "  dtree.fit(X_train,Z_train)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=tree.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=dtree.predict(X_test).reshape(1,-1).tolist()[0]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time interval for building model:4286.490201950073 ms\n",
            "time interval for indexing data :16.001462936401367 ms\n",
            "average time interval for indexing data :0.0015239488510858444 ms\n",
            "time interval for error correction :18.3260440826416 ms\n",
            "average time interval for error correction :0.0017453375316801526 ms\n",
            "time interval for building model:3911.2744331359863 ms\n",
            "time interval for indexing data :15.665769577026367 ms\n",
            "average time interval for indexing data :0.0014919780549548921 ms\n",
            "time interval for error correction :18.146753311157227 ms\n",
            "average time interval for error correction :0.0017282622201102121 ms\n",
            "time interval for building model:3882.6494216918945 ms\n",
            "time interval for indexing data :15.812873840332031 ms\n",
            "average time interval for indexing data :0.0015059879847935268 ms\n",
            "time interval for error correction :18.115997314453125 ms\n",
            "average time interval for error correction :0.0017253330775669643 ms\n",
            "time interval for building model:3771.6424465179443 ms\n",
            "time interval for indexing data :20.033597946166992 ms\n",
            "average time interval for indexing data :0.0019079617091587611 ms\n",
            "time interval for error correction :23.20694923400879 ms\n",
            "average time interval for error correction :0.0022101856413341706 ms\n",
            "time interval for building model:3843.7535762786865 ms\n",
            "time interval for indexing data :16.195297241210938 ms\n",
            "average time interval for indexing data :0.0015424092610677083 ms\n",
            "time interval for error correction :17.98272132873535 ms\n",
            "average time interval for error correction :0.001712640126546224 ms\n",
            "time interval for building model:3762.176036834717 ms\n",
            "time interval for indexing data :16.30234718322754 ms\n",
            "average time interval for indexing data :0.0015526044936407181 ms\n",
            "time interval for error correction :19.466400146484375 ms\n",
            "average time interval for error correction :0.00185394287109375 ms\n",
            "time interval for building model:3846.3659286499023 ms\n",
            "time interval for indexing data :16.077041625976562 ms\n",
            "average time interval for indexing data :0.0015311468215215775 ms\n",
            "time interval for error correction :23.90766143798828 ms\n",
            "average time interval for error correction :0.002276920136951265 ms\n",
            "time interval for building model:3763.246536254883 ms\n",
            "time interval for indexing data :15.866994857788086 ms\n",
            "average time interval for indexing data :0.0015111423674083891 ms\n",
            "time interval for error correction :18.327951431274414 ms\n",
            "average time interval for error correction :0.0017455191839308964 ms\n",
            "time interval for building model:3774.3022441864014 ms\n",
            "time interval for indexing data :15.475749969482422 ms\n",
            "average time interval for indexing data :0.0014738809494745163 ms\n",
            "time interval for error correction :17.3952579498291 ms\n",
            "average time interval for error correction :0.0016566912333170574 ms\n",
            "time interval for building model:3772.0890045166016 ms\n",
            "time interval for indexing data :15.625476837158203 ms\n",
            "average time interval for indexing data :0.0014881406511579242 ms\n",
            "time interval for error correction :18.296003341674805 ms\n",
            "average time interval for error correction :0.0017424765087309336 ms\n",
            "time interval for building model:3752.4149417877197 ms\n",
            "time interval for indexing data :18.15938949584961 ms\n",
            "average time interval for indexing data :0.0017294656662713913 ms\n",
            "time interval for error correction :22.08709716796875 ms\n",
            "average time interval for error correction :0.002103533063616071 ms\n",
            "time interval for building model:3751.8575191497803 ms\n",
            "time interval for indexing data :16.304492950439453 ms\n",
            "average time interval for indexing data :0.001552808852422805 ms\n",
            "time interval for error correction :18.91350746154785 ms\n",
            "average time interval for error correction :0.0018012864249093191 ms\n",
            "time interval for building model:3785.2656841278076 ms\n",
            "time interval for indexing data :15.622377395629883 ms\n",
            "average time interval for indexing data :0.0014878454662504651 ms\n",
            "time interval for error correction :17.323970794677734 ms\n",
            "average time interval for error correction :0.0016499019804454985 ms\n",
            "time interval for building model:3762.8798484802246 ms\n",
            "time interval for indexing data :15.878677368164062 ms\n",
            "average time interval for indexing data :0.0015122549874441963 ms\n",
            "time interval for error correction :17.514705657958984 ms\n",
            "average time interval for error correction :0.0016680672055199033 ms\n",
            "time interval for building model:3782.550811767578 ms\n",
            "time interval for indexing data :15.62643051147461 ms\n",
            "average time interval for indexing data :0.001488231477283296 ms\n",
            "time interval for error correction :17.711162567138672 ms\n",
            "average time interval for error correction :0.0016867773873465402 ms\n",
            "time interval for building model:3746.0274696350098 ms\n",
            "time interval for indexing data :16.158580780029297 ms\n",
            "average time interval for indexing data :0.0015389124552408853 ms\n",
            "time interval for error correction :18.405675888061523 ms\n",
            "average time interval for error correction :0.0017529215131487166 ms\n",
            "time interval for building model:4427.257061004639 ms\n",
            "time interval for indexing data :15.95163345336914 ms\n",
            "average time interval for indexing data :0.0015192031860351562 ms\n",
            "time interval for error correction :17.92287826538086 ms\n",
            "average time interval for error correction :0.0017069407871791295 ms\n",
            "time interval for building model:3946.7132091522217 ms\n",
            "time interval for indexing data :16.241788864135742 ms\n",
            "average time interval for indexing data :0.0015468370346795944 ms\n",
            "time interval for error correction :24.447202682495117 ms\n",
            "average time interval for error correction :0.0023283050173804874 ms\n",
            "time interval for building model:3821.319341659546 ms\n",
            "time interval for indexing data :16.715049743652344 ms\n",
            "average time interval for indexing data :0.0015919094993954613 ms\n",
            "time interval for error correction :17.418384552001953 ms\n",
            "average time interval for error correction :0.0016588937668573288 ms\n",
            "time interval for building model:3841.604232788086 ms\n",
            "time interval for indexing data :15.861034393310547 ms\n",
            "average time interval for indexing data :0.001510574704124814 ms\n",
            "time interval for error correction :18.345355987548828 ms\n",
            "average time interval for error correction :0.001747176760718936 ms\n",
            "average times (ms): 3861.593997478485 16.27880334854126 0.0015503622236705964 19.163084030151367 0.0018250556219191773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ubPWG9M8U5n"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmazo3PU_-vM",
        "outputId": "cb55fd8c-9d10-434a-c633-2f84f46613da"
      },
      "source": [
        "import numpy as np\n",
        "temp=Z_train.reshape(1,-1)\n",
        "T_train=np.zeros((temp.size, temp.max()+1))\n",
        "T_train[np.arange(temp.size),temp] = 1\n",
        "print(T_train)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "(90, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E6QSaEAO8UqY",
        "outputId": "f4ad5bc5-b1c0-4fd2-895a-bdf94e20a5d3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api\n",
        "from keras import models as md\n",
        "from keras import layers as lr\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "def test():\n",
        "  t1=time.time()\n",
        "  model = md.Sequential()\n",
        "  model.add(lr.Dense(1,activation=\"relu\"))\n",
        "  # model.add(lr.Dense(4,activation=\"relu\"))\n",
        "  model.add(lr.Dense(128,activation=\"relu\"))\n",
        "  # model.add(lr.Dropout(0.2))\n",
        "  model.add(lr.Dense(temp.max()+1,activation=\"softmax\"))\n",
        "  model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])#compile the model\n",
        "  model.fit(X_train, T_train, epochs=16, batch_size=32)#fit the model\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  # devpre=tree.predict(X_dev)#.reshape(1,-1).tolist()[0]\n",
        "  # print(classification_report(Y_dev,devpre))\n",
        "  print(\"time interval for building model:\"+str(time_interval*1000)+\" ms\")\n",
        "  ret1=time_interval*1000\n",
        "  t1=time.time()\n",
        "  testpre=model.predict(X_test)#.reshape(1,-1).tolist()[0]\n",
        "  testpre=np.argmax(testpre,axis=1)\n",
        "  # print(testpre)\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for indexing data :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for indexing data :\"+str(time_interval/len(testkeys)*1000)+\" ms\")\n",
        "  # return\n",
        "  ret2=time_interval*1000\n",
        "  ret3=time_interval/len(testkeys)*1000\n",
        "  t1=time.time()\n",
        "  count_error=0\n",
        "  for i in range(0,len(testpre)):\n",
        "    estimated_page=testpre[i]\n",
        "    estimated_loc = estimated_page*100+50\n",
        "    correct_res=testres[i]\n",
        "    if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "        finding_res=trainres[estimated_loc]\n",
        "    elif estimated_loc<0:\n",
        "        finding_res=trainres[0]\n",
        "    else:\n",
        "        finding_res=trainres[len(trainkeys)-1]\n",
        "    if finding_res!=correct_res:\n",
        "      count_error+=1\n",
        "    begin=0\n",
        "    end=len(trainkeys)-1\n",
        "    while finding_res!=correct_res and abs(finding_res-correct_res)>1:\n",
        "      \n",
        "      # print(finding_res,correct_res)\n",
        "      # if count_error>30:\n",
        "      #   return\n",
        "      if finding_res<correct_res:\n",
        "        begin=estimated_loc\n",
        "        # end=len(trainkeys)-1\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "      else:\n",
        "        # begin=0\n",
        "        end=estimated_loc\n",
        "        estimated_loc=(begin+end)//2\n",
        "        if estimated_loc>=0 and estimated_loc<len(trainkeys):\n",
        "          finding_res=trainres[estimated_loc]\n",
        "        elif estimated_loc<0:\n",
        "          finding_res=trainres[0]\n",
        "        else:\n",
        "          finding_res=trainres[len(trainkeys)-1]\n",
        "  t2=time.time()\n",
        "  time_interval=t2-t1\n",
        "  print(\"time interval for error correction :\"+str(time_interval*1000)+\" ms\")\n",
        "  print(\"average time interval for error correction :\"+str(time_interval/count_error*1000)+\" ms\")\n",
        "  ret4=time_interval*1000\n",
        "  ret5=time_interval/len(testkeys)*1000\n",
        "  return (ret1,ret2,ret3,ret4,ret5)\n",
        "avg_a=0.0\n",
        "avg_b=0.0\n",
        "avg_c=0.0\n",
        "avg_d=0.0\n",
        "avg_e=0.0\n",
        "counting=20\n",
        "for i in range(0,20):\n",
        "  (a,b,c,d,e)=test()\n",
        "  avg_a+=a\n",
        "  avg_b+=b\n",
        "  avg_c+=c\n",
        "  avg_d+=d\n",
        "  avg_e+=e\n",
        "avg_a=avg_a/counting\n",
        "avg_b=avg_b/counting\n",
        "avg_c=avg_c/counting\n",
        "avg_d=avg_d/counting\n",
        "avg_e=avg_e/counting\n",
        "print(\"average times (ms):\",avg_a,avg_b,avg_c,avg_d,avg_e)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/16\n",
            "3/3 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "time interval for building model:1182.7242374420166 ms\n",
            "time interval for indexing data :116.20378494262695 ms\n",
            "average time interval for indexing data :4.007027066987136 ms\n",
            "time interval for error correction :0.33354759216308594 ms\n",
            "average time interval for error correction :0.011501641109071929 ms\n",
            "Epoch 1/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/16\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "time interval for building model:695.0485706329346 ms\n",
            "time interval for indexing data :81.39538764953613 ms\n",
            "average time interval for indexing data :2.8067375051564185 ms\n",
            "time interval for error correction :0.19788742065429688 ms\n",
            "average time interval for error correction :0.0068237041604929955 ms\n",
            "Epoch 1/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/16\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/16\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/16\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "time interval for building model:693.2485103607178 ms\n",
            "time interval for indexing data :82.14139938354492 ms\n",
            "average time interval for indexing data :2.8324620477084457 ms\n",
            "time interval for error correction :0.20432472229003906 ms\n",
            "average time interval for error correction :0.007045680078966865 ms\n",
            "Epoch 1/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/16\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "time interval for building model:686.7799758911133 ms\n",
            "time interval for indexing data :78.10354232788086 ms\n",
            "average time interval for indexing data :2.693225597513133 ms\n",
            "time interval for error correction :0.24437904357910156 ms\n",
            "average time interval for error correction :0.008426863571693158 ms\n",
            "Epoch 1/16\n",
            "3/3 [==============================] - 1s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 3/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 4/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 5/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 6/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/16\n",
            "3/3 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/16\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/16\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/16\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/16\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "time interval for building model:861.3927364349365 ms\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff7242bc440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "time interval for indexing data :87.02230453491211 ms\n",
            "average time interval for indexing data :3.0007691218935206 ms\n",
            "time interval for error correction :0.2856254577636719 ms\n",
            "average time interval for error correction :0.009849153715988684 ms\n",
            "Epoch 1/16\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 2/16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b541d1bbafdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mcounting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0mavg_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mavg_b\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-b541d1bbafdb>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mt2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mtime_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}